{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jorbnc/MAIA-DL/blob/master/Mini_Proyecto_2_DL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oa_MJEGQ6jTi",
      "metadata": {
        "id": "oa_MJEGQ6jTi"
      },
      "source": [
        "![Universidad_de_los_Andes_30.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sl89pic17iPU",
      "metadata": {
        "id": "sl89pic17iPU"
      },
      "source": [
        "<style>\n",
        "@import url('https://fonts.googleapis.com/css2?family=Latin+Modern+Roman:wght@400;700&display=swap');\n",
        "\n",
        "body, p, h1, h2, h3, h4, h5, h6, li {\n",
        "  font-family: 'Latin Modern Roman', serif;\n",
        "}\n",
        "code, pre {\n",
        "  font-family: 'Fira Mono', monospace;\n",
        "}\n",
        "</style>\n",
        "\n",
        "***\n",
        "\n",
        "# **Mini Proyecto 2, T√©cnicas de *Deep Learning*: Clasificaci√≥n de Sentimientos de Rese√±as de Pel√≠culas en *IMDB* con Redes Neuronales Recurrentes**\n",
        "\n",
        "## **Descripci√≥n del problema:**\n",
        "\n",
        "XXXXXX\n",
        "\n",
        "## **Objetivo:**\n",
        "\n",
        "XXXXX\n",
        "\n",
        "## **Resumen:**\n",
        "\n",
        "XXXX"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SiCS5j-HAbCB",
      "metadata": {
        "id": "SiCS5j-HAbCB"
      },
      "source": [
        "***\n",
        "\n",
        "**Este proyecto es realizado por Andr√©s Felipe √ëungo y Jordan Bryan N√∫√±ez Campos para entrega el 9 de mayo.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tareas\n",
        "\n",
        "* Exploraci√≥n y pre-procesamiento (Jordan)\n",
        "\n",
        "* Introducci√≥n, y explicaci√≥n de las opciones tomadas en el PDF (Andr√©s y Jordan)\n",
        "\n",
        "* Validar cual es mejor Word2vec o Glove (Andr√©s y Jordan)  Busqueda bibliogr√°fica para explicar informe\n",
        "\n",
        "* LSTM o GRU  (Andr√©s)\n",
        "\n",
        "* Pensar en ideas visualizaci√≥n (Andr√©s y Jordan)\n",
        "\n",
        "* Entrenamiento y evaluaci√≥n de modelo (Andr√©s)"
      ],
      "metadata": {
        "id": "aP4T8CvEqYMG"
      },
      "id": "aP4T8CvEqYMG"
    },
    {
      "cell_type": "markdown",
      "id": "8VqTMx7TYgjH",
      "metadata": {
        "id": "8VqTMx7TYgjH"
      },
      "source": [
        "\n",
        "***\n",
        "# **√çndice**\n",
        "\n",
        "El *notebook* abordar√° el proyecto de la siguiente manera:\n",
        "\n",
        "| üîπ | Secci√≥n        |\n",
        "|----|----------------|\n",
        "| 1Ô∏è‚É£ | **Instalaci√≥n y carga de librer√≠as** |\n",
        "| 2Ô∏è‚É£ | **An√°lisis exploratorio y preparaci√≥n de los datos**       |\n",
        "| 3Ô∏è‚É£ | **Definici√≥n de *pipelines* de procesamiento**          |\n",
        "| 3Ô∏è‚É£.1Ô∏è‚É£ | **Pipeline de preprocesamiento ...**   |\n",
        "| 4Ô∏è‚É£ | **Desarrollo del modelo RNN...**   |\n",
        "| 4Ô∏è‚É£.1Ô∏è‚É£ | **Hiperpar√°metros, partici√≥n y Dataloaders**   |\n",
        "| 4Ô∏è‚É£.2Ô∏è‚É£ | **Adaptaci√≥n a partir de la arquitectura ...*   |\n",
        "| 4Ô∏è‚É£.3Ô∏è‚É£ | **Entrenamiento, validaci√≥n y prueba**   |\n",
        "| 5Ô∏è‚É£ | **An√°lisis de resultados y conclusiones**   |\n",
        "| 6Ô∏è‚É£ | **Referencias**   |\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cyVuwlHB_W3",
      "metadata": {
        "id": "2cyVuwlHB_W3"
      },
      "source": [
        "***\n",
        "\n",
        "# 1. Instalaci√≥n y cargue de librer√≠as"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Empezamos por el cargue de las librerias que se usar√°n para efectos de este proyecto. Estas incluyen:\n",
        "\n",
        "* Librer√≠as comunes para la lectura, procesamiento y ploteo b√°sico de las im√°genes.\n",
        "* **`kagglehub`**, para poder descargar el dataset del miniproyecto de forma conveniente\n",
        "* **`pytorch`** (de acuerdo, a la sugerencia del enunciado del proyecto) ...."
      ],
      "metadata": {
        "id": "DkjBiBB5rU6t"
      },
      "id": "DkjBiBB5rU6t"
    },
    {
      "cell_type": "code",
      "source": [
        "pip install kagglehub # Necesario para ejecutarse en Coursera"
      ],
      "metadata": {
        "id": "E406fnSfiL0M",
        "outputId": "e4987321-1d56-4a86-8411-afce0d9396fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "E406fnSfiL0M",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.11/dist-packages (0.3.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from kagglehub) (24.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from kagglehub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kagglehub) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Librer√≠as comunes\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Preprocesamiento\n",
        "from collections import Counter\n",
        "\n",
        "# Librer√≠as NLP\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Modelado\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torch.optim as optim\n",
        "\n",
        "# Evaluaci√≥n\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, confusion_matrix\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Descarga del dataset\n",
        "import kagglehub\n",
        "path = kagglehub.dataset_download(\"yasserh/imdb-movie-ratings-sentiment-analysis\")\n",
        "print(\"Datos descargados en:\", path)"
      ],
      "metadata": {
        "id": "osjmTJMvtxua",
        "outputId": "91af629f-57d9-4f85-e27c-539ac656b711",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "osjmTJMvtxua",
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datos descargados en: /kaggle/input/imdb-movie-ratings-sentiment-analysis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Descarga de palabra vac√≠as\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "pEJ80cY8rlEv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea35741b-cc64-4fa4-e5cc-0013f70deefd"
      },
      "id": "pEJ80cY8rlEv",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "LSwlUgjUjtR_",
      "metadata": {
        "id": "LSwlUgjUjtR_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de653975-543d-4c12-867a-7b5e619f179c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numpy :  2.0.2\n",
            "pandas :  2.2.2\n",
            "torch :  2.6.0+cu124\n",
            "torchvision :  0.21.0+cu124\n",
            "scikit-learn :  1.6.1\n",
            "kagglehub :  0.3.12\n",
            "pillow :  11.2.1\n",
            "matplotlib :  3.10.0\n",
            "seaborn :  0.13.2\n"
          ]
        }
      ],
      "source": [
        "# Ignorar las warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Versiones utilizadas\n",
        "from importlib.metadata import version\n",
        "librerias = ['numpy', 'pandas', 'torch', 'torchvision', 'scikit-learn', 'kagglehub', 'pillow','matplotlib','seaborn']\n",
        "for library in librerias:\n",
        "  print(library, \": \", version(library))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El siguiente bloque de c√≥digo nos permite hacer determinin√≠sticas las funciones tra√≠das de **`pytorch`**, y en general controlar todos los pseudo-aleatorios del *notebook*"
      ],
      "metadata": {
        "id": "ok4F_5E1njTi"
      },
      "id": "ok4F_5E1njTi"
    },
    {
      "cell_type": "code",
      "source": [
        "# Definici√≥n del random state y seeds\n",
        "RANDOM_STATE = 13\n",
        "random.seed(RANDOM_STATE)\n",
        "np.random.seed(RANDOM_STATE)"
      ],
      "metadata": {
        "id": "xdgcOt7gznvJ"
      },
      "id": "xdgcOt7gznvJ",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "qK311OLFzPep",
      "metadata": {
        "id": "qK311OLFzPep"
      },
      "source": [
        "***\n",
        "\n",
        "# 2. An√°lisis exploratorio y preparaci√≥n de los datos\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "## 2.1. Carga y estad√≠sticas generales\n",
        "\n",
        "XXXXXXX   Esto se detalla posteriormente en la secci√≥n **Pipeline de Preprocesamiento**."
      ],
      "metadata": {
        "id": "4KxKy7H1eID-"
      },
      "id": "4KxKy7H1eID-"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "K4yOzyWKJbov",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4yOzyWKJbov",
        "outputId": "facc0b5c-84b1-4a7d-f7bb-9e1df3f5ea4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text  label\n",
            "0  I grew up (b. 1965) watching and loving the Th...      0\n",
            "1  When I put this movie in my DVD player, and sa...      0\n",
            "2  Why do people who do not know what a particula...      0\n",
            "3  Even though I have great interest in Biblical ...      0\n",
            "4  Im a die hard Dads Army fan and nothing will e...      1\n",
            "label\n",
            "0    0.500475\n",
            "1    0.499525\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Descargar el conjunto de datos y almacenar el path en una variable\n",
        "data = pd.read_csv(os.path.join(path, 'movie.csv'))\n",
        "print(data.head())\n",
        "# Frecuencia relativa de cada clase\n",
        "print(data['label'].value_counts(normalize=True))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.columns)"
      ],
      "metadata": {
        "id": "puDNflxIEGAD",
        "outputId": "83f1ec32-a76a-4ef6-bc3a-0a5ad5da0107",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "puDNflxIEGAD",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['text', 'label'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CNfurSnbmf79",
      "metadata": {
        "id": "CNfurSnbmf79"
      },
      "source": [
        "Una vez teniendo esta informaci√≥n pre-cargada, hacemos un breve an√°lisis de nuestro conjunto de datos. Empezando por la distribuci√≥n de las clases:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data_raw.shape"
      ],
      "metadata": {
        "id": "kGK5UaZssixU"
      },
      "id": "kGK5UaZssixU",
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data = data_raw.copy()\n",
        "# data.isna().sum()"
      ],
      "metadata": {
        "id": "2r0P2t_Ysjbq"
      },
      "id": "2r0P2t_Ysjbq",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data.duplicated().sum()"
      ],
      "metadata": {
        "id": "m3IgmRbWskuE"
      },
      "id": "m3IgmRbWskuE",
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Nombres de las clases\n",
        "# ods = np.array([\n",
        "#     \"Fin de la pobreza\", \"Hambre cero\", \"Salud y bienestar\", \"Educaci√≥n de calidad\", \"Igualdad de g√©nero\",\n",
        "#     \"Agua limpia y saneamiento\", \"Energ√≠a asequible y no contaminante\", \"Trabajo decente y crecimiento econ√≥mico\",\n",
        "#     \"Industria, innovaci√≥n e infraestructura\", \"Reducci√≥n de las desigualdades\", \"Ciudades y comunidades sostenibles\",\n",
        "#     \"Producci√≥n y consumo responsables\", \"Acci√≥n por el clima\", \"Vida submarina\", \"Vida de ecosistemas terrestres\",\n",
        "#     \"Paz, justicia e instituciones s√≥lidas\"\n",
        "# ])\n",
        "# counts = data['ODS'].value_counts()\n",
        "# # Plot del n√∫mero de documentos por categor√≠a\n",
        "# fig, ax = plt.subplots(1, 1, figsize=(5,5))\n",
        "# norm = plt.Normalize(vmin=counts.min(), vmax=counts.max())\n",
        "# colors = cm.viridis(norm(counts))\n",
        "# ax.barh(range(0,16), counts,color=colors)\n",
        "# ax.set_yticks(range(0,16), labels=[ods[l-1] + f\" ({l})\" for l in counts.index])\n",
        "# ax.invert_yaxis()\n",
        "# fig.show()"
      ],
      "metadata": {
        "id": "m3zQ2lidsqWS"
      },
      "id": "m3zQ2lidsqWS",
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "xxxxxx"
      ],
      "metadata": {
        "id": "GYikkR-zw4dQ"
      },
      "id": "GYikkR-zw4dQ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Idiomas xxxx"
      ],
      "metadata": {
        "id": "IQ5tDkuys-GR"
      },
      "id": "IQ5tDkuys-GR"
    },
    {
      "cell_type": "code",
      "source": [
        "# #Identifica el Idioma de cada fila\n",
        "# def identificar_idioma(X: pd.DataFrame):\n",
        "#     X[\"idioma\"] = X['textos'].apply(lambda x: detect(x) if isinstance(x, str) and x.strip() else \"desconocido\")\n",
        "#     return X\n",
        "\n",
        "# X_deteccion = identificar_idioma(data)\n",
        "# print(X_deteccion['idioma'].value_counts())"
      ],
      "metadata": {
        "id": "_WQ5tiJps-bO"
      },
      "id": "_WQ5tiJps-bO",
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# indices_a_traducir = data[data['idioma'] != 'es'].index\n",
        "# translator = Translator()\n",
        "\n",
        "# # Traducci√≥n hecha con google translate\n",
        "# def traducir_texto_fila(fila):\n",
        "#     texto = fila['textos']\n",
        "#     idioma_original = fila['idioma']\n",
        "#     if isinstance(texto, str) and texto.strip():\n",
        "#         return translator.translate(texto, src=idioma_original, dest=\"es\").text\n",
        "#     return texto\n",
        "\n",
        "# # Aplicando la traducci√≥n\n",
        "# data.loc[indices_a_traducir, 'textos'] = data.loc[indices_a_traducir].apply(traducir_texto_fila, axis=1)\n",
        "\n",
        "# # Ahora los textos han sido traducios al espa√±ol\n",
        "# for texto in data.loc[indices_a_traducir, 'textos']:\n",
        "#     print(texto, \"\\n\")"
      ],
      "metadata": {
        "id": "-tLxVOSwtN02"
      },
      "id": "-tLxVOSwtN02",
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# nltk_stopwords_set = set(stopwords.words(\"spanish\"))"
      ],
      "metadata": {
        "id": "XWPuyoWdtdJB"
      },
      "id": "XWPuyoWdtdJB",
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def preprocesamiento_exploratorio(X: pd.DataFrame):\n",
        "#     # Tokenizar a nivel de palabra y pasar a min√∫sculas\n",
        "#     tokenizer = RegexpTokenizer(r\"\\b[a-zA-Z√°√©√≠√≥√∫√º√±√Å√â√ç√ì√ö√ú√ë'-]+\")\n",
        "\n",
        "#     X_preprocesado = X.apply(lambda x: tokenizer.tokenize(x))\n",
        "#     X_preprocesado = [[t.lower() for t in text] for text in X_preprocesado]\n",
        "\n",
        "#     # Filtrar palabras vac√≠as\n",
        "#     X_preprocesado = [[token for token in text if token not in nltk_stopwords_set] for text in X_preprocesado]\n",
        "#     texto_nube = ' '.join(word for text in X_preprocesado for word in text)\n",
        "#     return texto_nube"
      ],
      "metadata": {
        "id": "T57xBkmKtilY"
      },
      "id": "T57xBkmKtilY",
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #Visualizaci√≥n inicial de las palabras que contienen los documentos.\n",
        "# texto_nube = preprocesamiento_exploratorio(X_train['textos'])\n",
        "\n",
        "# # Generaci√≥n Nube de Palabras\n",
        "# wordcloud = WordCloud(\n",
        "#     width=800,\n",
        "#     height=400,\n",
        "#     background_color ='white',\n",
        "#     min_font_size=10,\n",
        "#     max_font_size=110,\n",
        "#     max_words=100\n",
        "# ).generate(texto_nube)\n",
        "# plt.figure(figsize=(10, 10))\n",
        "# plt.imshow(wordcloud)\n",
        "# plt.axis('off')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "sBwcvN1xtktk"
      },
      "id": "sBwcvN1xtktk",
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #Conversi√≥n a dataframe\n",
        "# def palabras_a_dataframe(texto):\n",
        "#     palabras = texto.split()  # Dividir el texto en palabras por espacios\n",
        "#     conteo = Counter(palabras)  # Contar ocurrencias de cada palabra\n",
        "#     df = pd.DataFrame(conteo.items(), columns=['Palabra', 'Frecuencia'])\n",
        "#     df = df.sort_values(by='Frecuencia', ascending=False).reset_index(drop=True)  # Ordenar y resetear √≠ndice\n",
        "#     return df\n",
        "\n",
        "# conteo_palabras = palabras_a_dataframe(texto_nube)\n",
        "# conteo_top = conteo_palabras.head(20)\n",
        "\n",
        "# # Top 20 palabras\n",
        "# plt.figure(figsize=(5, 5))\n",
        "# sns.barplot(x=conteo_top[\"Frecuencia\"], y=conteo_top[\"Palabra\"], palette=\"viridis\")\n",
        "# plt.xlabel(\"Frecuencia\")\n",
        "# plt.ylabel(\"Palabra\")\n",
        "# plt.title(f\"Top {20} Palabras m√°s Frecuentes\")\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "LdeXcjGHts3g"
      },
      "id": "LdeXcjGHts3g",
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# counts = data['ODS'].value_counts()\n",
        "# counts_train = y_train.value_counts()\n",
        "\n",
        "# # Gr√°fica de la proporcionalidad de las clases y los conjuntos divididos\n",
        "# fig, ax = plt.subplots(1, 1, figsize=(5,5))\n",
        "# ax.barh(range(0,16), counts, label=\"Test\")\n",
        "# ax.barh(range(0,16), counts_train, label=\"Train\")\n",
        "# ax.set_yticks(range(0,16), labels=[ods[l-1] + f\" ({l})\" for l in counts.index])\n",
        "# ax.invert_yaxis()\n",
        "# plt.title(\"Distribuci√≥n del split estratificado\")\n",
        "# plt.legend()\n",
        "# fig.show()"
      ],
      "metadata": {
        "id": "UvsQEU5_twrt"
      },
      "id": "UvsQEU5_twrt",
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El objetivo de esta secci√≥n es incorporar varios estilos de pre-procesamiento, probar diferentes maneras de depurar los textos como por ejemplo remover caracteres no alfanum√©ricos, a excepci√≥n de guiones o ap√≥strofes. Tambi√©n haremos uso de dos normalizadores: *Stemming* y *Lemmatization*, ...."
      ],
      "metadata": {
        "id": "vCm-sqa9t8D2"
      },
      "id": "vCm-sqa9t8D2"
    },
    {
      "cell_type": "markdown",
      "id": "_ypyorGqwmRl",
      "metadata": {
        "id": "_ypyorGqwmRl"
      },
      "source": [
        "***\n",
        "\n",
        "# 3. Definici√≥n de *pipelines* de procesamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4370a607-ad43-4c5d-bddd-1a9370469409",
      "metadata": {
        "id": "4370a607-ad43-4c5d-bddd-1a9370469409"
      },
      "source": [
        "***\n",
        "\n",
        "## 3.1. *Pipeline* de preprocesamiento\n",
        "\n",
        "...\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "english_stop = set(stopwords.words('english'))\n",
        "\n",
        "def clean_and_tokenize(text):\n",
        "    # extrae solo palabras alfab√©ticas\n",
        "    tokens = re.findall(r'\\b[a-zA-Z]+\\b', text.lower())\n",
        "    return [t for t in tokens if t not in english_stop]\n",
        "\n",
        "# Prueba\n",
        "example = data.loc[0, 'text']\n",
        "print(clean_and_tokenize(example))"
      ],
      "metadata": {
        "id": "3mx_OdLIDyhG",
        "outputId": "c0642f03-e81a-40b9-9f3b-381e05d6b607",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "3mx_OdLIDyhG",
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['grew', 'b', 'watching', 'loving', 'thunderbirds', 'mates', 'school', 'watched', 'played', 'thunderbirds', 'school', 'lunch', 'school', 'wanted', 'virgil', 'scott', 'one', 'wanted', 'alan', 'counting', 'became', 'art', 'form', 'took', 'children', 'see', 'movie', 'hoping', 'would', 'get', 'glimpse', 'loved', 'child', 'bitterly', 'disappointing', 'high', 'point', 'snappy', 'theme', 'tune', 'could', 'compare', 'original', 'score', 'thunderbirds', 'thankfully', 'early', 'saturday', 'mornings', 'one', 'television', 'channel', 'still', 'plays', 'reruns', 'series', 'gerry', 'anderson', 'wife', 'created', 'jonatha', 'frakes', 'hand', 'directors', 'chair', 'version', 'completely', 'hopeless', 'waste', 'film', 'utter', 'rubbish', 'cgi', 'remake', 'may', 'acceptable', 'replacing', 'marionettes', 'homo', 'sapiens', 'subsp', 'sapiens', 'huge', 'error', 'judgment']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_tokens = [tok for txt in data['text'] for tok in clean_and_tokenize(txt)]\n",
        "freq = Counter(all_tokens)\n",
        "\n",
        "# Top‚Äë20‚ÄØ000 + <PAD>=0, <UNK>=1\n",
        "vocab = {w:i+2 for i,(w,_) in enumerate(freq.most_common(20000))}\n",
        "#Indicadores de inicio y final\n",
        "vocab.update({'<PAD>':0,'<UNK>':1})\n",
        "\n",
        "def encode(tokens, max_len=200):\n",
        "    seq = [vocab.get(t,1) for t in tokens]\n",
        "    # Completa secuencia hasta tener max_len\n",
        "    return seq[:max_len] + [0]*(max_len-len(seq))"
      ],
      "metadata": {
        "id": "zfp-stYtEt71"
      },
      "id": "zfp-stYtEt71",
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "boj68OJEKvb1",
      "metadata": {
        "id": "boj68OJEKvb1"
      },
      "outputs": [],
      "source": [
        "# # Pipeline con Stemming, sin depuraci√≥n de palabras\n",
        "# pipeline_stem = Pipeline([\n",
        "#     ('preprocesador', preprocesador(normalizer=normalizer_stem)),\n",
        "#     ('vectorizer', TfidfVectorizer()),\n",
        "# ])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Stemming\n",
        "# stemmer = SnowballStemmer(\"spanish\")\n",
        "# normalizer_stem = lambda tokens: [stemmer.stem(t) for t in tokens]\n",
        "\n",
        "# # Lemmatization\n",
        "# nlp = spacy.load(\"es_core_news_sm\")\n",
        "# normalizer_lemma = lambda tokens: [t.lemma_ for t in nlp(\" \".join(tokens))]"
      ],
      "metadata": {
        "id": "bqRFW-7euRUA"
      },
      "id": "bqRFW-7euRUA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "G6-RrjwuxYEw",
      "metadata": {
        "id": "G6-RrjwuxYEw"
      },
      "source": [
        "***\n",
        "\n",
        "# 4. Desarrollo del modelo RNN...."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "## 4.1. Hiperpar√°metros, partici√≥n y *DataLoaders*\n",
        "\n",
        "XXXXX"
      ],
      "metadata": {
        "id": "wqy-xlwJ2zMS"
      },
      "id": "wqy-xlwJ2zMS"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se usa una partici√≥n **80/10/10** para los datos de entrenamiento, validaci√≥n y *test*, respectivamente. Tambi√©n se define **`device`** que nos permitir√° ir alternado el uso de GPU y de CPU."
      ],
      "metadata": {
        "id": "88Ve2DvMLVqO"
      },
      "id": "88Ve2DvMLVqO"
    },
    {
      "cell_type": "code",
      "source": [
        "class IMDBDataset(Dataset):\n",
        "    def __init__(self, df, max_len=200):\n",
        "        self.texts  = df['text'].tolist()\n",
        "        self.labels = df['label'].astype(int).tolist()\n",
        "        self.max_len = max_len\n",
        "    def __len__(self): return len(self.texts)\n",
        "    def __getitem__(self, i):\n",
        "        toks = clean_and_tokenize(self.texts[i])\n",
        "        return torch.tensor(encode(toks,self.max_len)), torch.tensor(self.labels[i],dtype=torch.float)\n",
        "\n",
        "# Split 80/10/10 con semilla fija\n",
        "ds = IMDBDataset(data)\n",
        "n = len(ds)\n",
        "train_ds, val_ds, test_ds = random_split(ds, [int(.8*n),int(.1*n),n-int(.9*n)], generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_ds, batch_size, shuffle=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size)\n",
        "test_loader  = DataLoader(test_ds,  batch_size)"
      ],
      "metadata": {
        "id": "OIoaU3iKH6ey"
      },
      "id": "OIoaU3iKH6ey",
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentRNN(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim=100, hid_dim=128, n_layers=2, bidir=True, drop=0.5):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
        "        self.lstm      = nn.LSTM(emb_dim, hid_dim, n_layers, bidirectional=bidir, batch_first=True, dropout=drop)\n",
        "        self.dropout   = nn.Dropout(drop)\n",
        "        self.fc        = nn.Linear(hid_dim*(2 if bidir else 1), 1)\n",
        "    def forward(self, x):\n",
        "        emb, _ = self.embedding(x), None\n",
        "        out, _ = self.lstm(emb)\n",
        "        h_last = out[:, -1, :]\n",
        "        return torch.sigmoid(self.fc(self.dropout(h_last))).squeeze()"
      ],
      "metadata": {
        "id": "cipLcGcoKLdm"
      },
      "id": "cipLcGcoKLdm",
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Trabajar en GPU/CPU\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# # Partici√≥n de los datos\n",
        "# size_dataset  = len(dataset)\n",
        "# size_entrenmiento = int(0.8 * size_dataset)\n",
        "# size_validacion = int(0.1 * size_dataset)\n",
        "# size_test = size_dataset - size_entrenmiento - size_validacion\n",
        "# dataset_train, dataset_val, dataset_test = random_split(\n",
        "#     dataset,\n",
        "#     [size_entrenmiento, size_validacion, size_test],\n",
        "#     generator=torch.Generator().manual_seed(RANDOM_STATE)\n",
        "# )\n",
        "\n",
        "# # Carga \"lazy\" de las particiones\n",
        "# train_loader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
        "# val_loader   = DataLoader(dataset_val,   batch_size=batch_size, shuffle=False)\n",
        "# test_loader  = DataLoader(dataset_test,  batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "QvBVZqZW5R3q"
      },
      "id": "QvBVZqZW5R3q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "## 4.2. Adaptaci√≥n a partir ...\n",
        "</span>"
      ],
      "metadata": {
        "id": "nYOiJFBC-lqR"
      },
      "id": "nYOiJFBC-lqR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "### 4.2.1 Modelo: ...\n",
        "\n",
        "... s capaz de detectar tanto bordes como patrones complejos. Adem√°s, al estar pre-entrenado en *ImageNet*, acelera y facilita la adaptaci√≥n a nuestra nueva tarea. No obstante, dado que trabajamos con un conjunto de datos ..."
      ],
      "metadata": {
        "id": "UuM73kN6TLW9"
      },
      "id": "UuM73kN6TLW9"
    },
    {
      "cell_type": "code",
      "source": [
        "# # Cargar modelo\n",
        "# model = models.alexnet(pretrained=True)\n",
        "\n",
        "# # N√∫mero de par√°metros de la arquitectura sin modificaciones\n",
        "# total_parametros = sum(p.numel() for p in model.parameters())\n",
        "# print(f\"Total parametros {total_parametros:,}\\n\")\n",
        "\n",
        "# # Observamos la arquitectura del modelo original\n",
        "# model"
      ],
      "metadata": {
        "id": "HzGFuR3U6DUE"
      },
      "id": "HzGFuR3U6DUE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo resultante tiene en total **`22,381,764`** par√°metros entrenables que ser√°n ajustados al dataset, buscando una buena generalizaci√≥n mediante early stopping."
      ],
      "metadata": {
        "id": "sLkz_rq6UKoW"
      },
      "id": "sLkz_rq6UKoW"
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "## 4.3. Entrenamiento, validaci√≥n y prueba\n",
        "\n",
        "xxxxxx\n"
      ],
      "metadata": {
        "id": "oz4ZPXG44a8W"
      },
      "id": "oz4ZPXG44a8W"
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model     = SentimentRNN(len(vocab)).to(device)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "#Gradient Clipping\n",
        "clip      = 5\n",
        "\n",
        "best_val = float('inf'); epochs_no_imp=0; patience=3\n",
        "for epoch in range(1, 11):\n",
        "    # Entrenamiento\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for x,y in tqdm(train_loader):\n",
        "        x,y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(model(x), y)\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()*x.size(0)\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "\n",
        "    # Validaci√≥n\n",
        "    model.eval()\n",
        "    val_loss = sum(criterion(model(x.to(device)), y.to(device)).item()*x.size(0)\n",
        "                   for x,y in val_loader)/len(val_loader.dataset)\n",
        "    print(f\"Epoch {epoch} ‚Äî Train: {train_loss:.4f}, Val: {val_loss:.4f}\")\n",
        "    if val_loss < best_val:\n",
        "        best_val = val_loss\n",
        "        torch.save(model.state_dict(),'best_model.pt')\n",
        "        epochs_no_imp = 0\n",
        "    else:\n",
        "        epochs_no_imp += 1\n",
        "        if epochs_no_imp >= patience:\n",
        "            print(\"‚Üí Early stopping\")\n",
        "            break"
      ],
      "metadata": {
        "id": "DVO5O3T1Kh4O",
        "outputId": "11217c11-5fb3-4a85-eb5b-69b83000fb62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "DVO5O3T1Kh4O",
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:17<00:00, 28.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 ‚Äî Train: 0.6939, Val: 0.6924\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:16<00:00, 29.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 ‚Äî Train: 0.6886, Val: 0.6863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:16<00:00, 30.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 ‚Äî Train: 0.6806, Val: 0.6878\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:17<00:00, 29.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 ‚Äî Train: 0.6663, Val: 0.6903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:16<00:00, 29.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 ‚Äî Train: 0.6338, Val: 0.6638\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:17<00:00, 28.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 ‚Äî Train: 0.5779, Val: 0.5555\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:17<00:00, 28.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 ‚Äî Train: 0.4484, Val: 0.4544\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:17<00:00, 28.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 ‚Äî Train: 0.3413, Val: 0.4191\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:17<00:00, 29.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 ‚Äî Train: 0.2795, Val: 0.3968\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:17<00:00, 28.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 ‚Äî Train: 0.2340, Val: 0.3984\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Cargar al device elegido\n",
        "# model = model.to(device)"
      ],
      "metadata": {
        "id": "JAL3sReA-I8h"
      },
      "id": "JAL3sReA-I8h",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Funci√≥n de p√©rdida y optimizador\n",
        "# loss_f = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.Adam(model.parameters(), lr=5e-5)"
      ],
      "metadata": {
        "id": "6et9JqI8_n16"
      },
      "id": "6et9JqI8_n16",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Funci√≥n para calcular el accuracy\n",
        "# def evaluar_modelo_accuracy(m):\n",
        "#   # Modo evaluaci√≥n\n",
        "#   m.eval()\n",
        "#   correctos, total = 0, 0\n",
        "#   # Desactivar ajuste de par√°metros y calcular accuracy\n",
        "#   with torch.no_grad():\n",
        "#     for imgs, labels in test_loader:\n",
        "#         imgs, labels = imgs.to(device), labels.to(device)\n",
        "#         logits = m(imgs)\n",
        "#         # Obtener el √≠ndice (clase) de logit m√°ximo a lo largo de la dim=1\n",
        "#         _, predicciones = torch.max(logits, 1)\n",
        "#         # Actualizaci√≥n iterativa del accuracy\n",
        "#         correctos += (predicciones == labels).sum().item()\n",
        "#         total += labels.size(0)\n",
        "#   return correctos / total * 100"
      ],
      "metadata": {
        "id": "hda66_mf7Wvj"
      },
      "id": "hda66_mf7Wvj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_loss_acumulado = []\n",
        "# val_loss_acumulado = []\n",
        "# accuracy_acumulado = []\n",
        "\n",
        "# # Las siguientes variables forman parte de la implementaci√≥n de Early Stopping:\n",
        "# # Copia inicial del estado del modelo\n",
        "# pesos_mejor_modelo = copy.deepcopy(model.state_dict())\n",
        "# # 'mejor loss'. Se inicializa en un valor infinto positivo\n",
        "# mejor_loss_val  = float('inf')\n",
        "# # Contador de epochs sin mejora significativa\n",
        "# epochs_sin_mejora = 0\n",
        "\n",
        "# start_time = time.time()\n",
        "# # Loop de entrenamiento con Early Stopping\n",
        "# for epoch in range(1, num_epochs+1):\n",
        "\n",
        "#     # Entrenamieto\n",
        "#     model.train() # Cambia a modo de entrenamiento y permite Dropout\n",
        "#     loss_acumulada = 0.0\n",
        "#     for imgs, labels in train_loader:\n",
        "#         imgs, labels = imgs.to(device), labels.to(device)\n",
        "#         # Backpropagation y Ajuste de par√°metros\n",
        "#         optimizer.zero_grad()\n",
        "#         outputs = model(imgs)\n",
        "#         loss = loss_f(outputs, labels)\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "#         loss_acumulada += loss.item() * imgs.size(0)\n",
        "\n",
        "#     # M√©trica de entrenamiento para la epoch actual\n",
        "#     train_loss = loss_acumulada / len(train_loader.dataset)\n",
        "#     train_loss_acumulado.append(train_loss)\n",
        "\n",
        "#     # Validaci√≥n\n",
        "#     model.eval()\n",
        "#     val_loss = 0.0\n",
        "#     # Desactiva la actualizaci√≥n de par√°metos (no gradient) y activa el modo inferencia\n",
        "#     with torch.no_grad():\n",
        "#         for imgs, labels in val_loader:\n",
        "#             imgs, labels = imgs.to(device), labels.to(device)\n",
        "#             outputs = model(imgs)\n",
        "#             loss = loss_f(outputs, labels)\n",
        "#             val_loss += loss.item() * imgs.size(0)\n",
        "#     val_loss /= len(val_loader.dataset)\n",
        "#     val_loss_acumulado.append(val_loss)\n",
        "\n",
        "#     # Prueba iterativa\n",
        "#     acc = evaluar_modelo_accuracy(model)\n",
        "#     accuracy_acumulado.append(acc)\n",
        "\n",
        "#     # Early stopping\n",
        "#     # Si es que hay mejor√≠a...\n",
        "#     if val_loss < mejor_loss_val:\n",
        "#         # ...actualizar el mejor loss\n",
        "#         mejor_loss_val = val_loss\n",
        "#         pesos_mejor_modelo = copy.deepcopy(model.state_dict())\n",
        "#         # Y reiniciar el contador de epochs\n",
        "#         epochs_sin_mejora = 0\n",
        "#         print(f\"Epoch {epoch}/{num_epochs}, Train Loss: {train_loss:.4f},  Val Loss: {val_loss:.4f} --> Nueva mejor m√©trica (Test Accuracy: {acc:.2f}%)\")\n",
        "#     # En caso contrario, seguir iterando hasta superar el umbral o finalizar todas las epochs\n",
        "#     else:\n",
        "#         epochs_sin_mejora += 1\n",
        "#         print(f\"Epoch {epoch}/{num_epochs}, Train Loss: {train_loss:.4f},  Val Loss: {val_loss:.4f} (Test Accuracy: {acc:.2f}%)\")\n",
        "#         if epochs_sin_mejora >= umbral_epochs:\n",
        "#             print(f\"‚Üí Early stopping despu√©s de {epoch} epochs.\")\n",
        "#             break\n",
        "\n",
        "# end_time = time.time()\n",
        "# print(f\"Completado en {(end_time - start_time) / 60.0} minutos.\")"
      ],
      "metadata": {
        "id": "O-cjHNIS5zyf"
      },
      "id": "O-cjHNIS5zyf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lfWLuA-e4LBH"
      },
      "id": "lfWLuA-e4LBH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Prueba piloto de los clasificadores...\n",
        "\n"
      ],
      "metadata": {
        "id": "SPHtDlSr4Mk-"
      },
      "id": "SPHtDlSr4Mk-"
    },
    {
      "cell_type": "markdown",
      "id": "7JgtiyyfIyMM",
      "metadata": {
        "id": "7JgtiyyfIyMM"
      },
      "source": [
        "***\n",
        "\n",
        "\n",
        "# 5. An√°lisis de resultados y conclusiones\n",
        "\n",
        "xxxxx calculando *Accuracy*, *Recall*, *F1-macro* y la *Matriz de confusi√≥n*xxxx"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #Devuelve y_true, y_pred, accuracy y F1-macro.\n",
        "# def evaluar_test(modelo, loader, device):\n",
        "\n",
        "#     modelo.eval()\n",
        "#     y_true, y_pred = [], []\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         for x, y in loader:\n",
        "#             x, y = x.to(device), y.to(device)\n",
        "#             logits = modelo(x)\n",
        "#             _, pred = torch.max(logits, 1)\n",
        "#             y_true.extend(y.cpu().numpy())\n",
        "#             y_pred.extend(pred.cpu().numpy())\n",
        "#     # Accuracy\n",
        "#     acc  = accuracy_score(y_true, y_pred)\n",
        "#     # F1 multi-clase\n",
        "#     f1   = f1_score(y_true, y_pred, average='macro')  #\n",
        "#     cm   = confusion_matrix(y_true, y_pred)\n",
        "#     return acc, f1, cm, y_true, y_pred"
      ],
      "metadata": {
        "id": "Yy_K-NCUcpxU"
      },
      "id": "Yy_K-NCUcpxU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Evaluar sobre test\n",
        "# acc_test, f1_test, cm_test, y_true, y_pred = evaluar_test(model, test_loader, device)\n",
        "\n",
        "# # Print m√©tricas\n",
        "# print(\"\\nResultados en TEST\")\n",
        "# print(f\"‚Ä£ Accuracy : {acc_test*100:6.2f}%\")\n",
        "# print(f\"‚Ä£ F1-macro : {f1_test:6.3f}\")\n",
        "\n",
        "\n",
        "# # Convierte cada etiqueta a int\n",
        "# class_ids   = sorted(set(y_true))\n",
        "# class_names = [str(c) for c in class_ids]\n",
        "\n",
        "# # Plot matriz de confusi√≥n\n",
        "# plt.figure(figsize=(6, 5))\n",
        "# sns.heatmap(cm_test,\n",
        "#             annot=True, fmt='d', cmap='Blues',\n",
        "#             xticklabels=class_names,\n",
        "#             yticklabels=class_names)\n",
        "# plt.xlabel(\"Predicci√≥n\")\n",
        "# plt.ylabel(\"Etiqueta real\")\n",
        "# plt.title(\"Matriz de confusi√≥n ‚Äî Conjunto de prueba\")\n",
        "# plt.tight_layout()\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "eH9UcueZcvQi"
      },
      "id": "eH9UcueZcvQi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "XXXXXX"
      ],
      "metadata": {
        "id": "pxpLuOCGhXt8"
      },
      "id": "pxpLuOCGhXt8"
    },
    {
      "cell_type": "code",
      "source": [
        "# sns.set(style=\"darkgrid\")\n",
        "\n",
        "# fig, axes = plt.subplots(1, 2, figsize=(8, 3.75))\n",
        "\n",
        "# axes[0].plot(train_loss_acumulado, label='P√©rdida de entrenamiento', color = '#5d34f4', marker = \".\", lw= 1.5)\n",
        "# axes[0].plot(val_loss_acumulado, label='P√©rdida de validaci√≥n', color = '#06cf1e', marker = \".\", lw= 1.5)\n",
        "# axes[0].set_xlabel('√âpoca\\n(a)')\n",
        "# axes[0].set_ylabel('P√©rdida')\n",
        "# axes[0].legend()\n",
        "# #axes[0].set_title('P√©rdidas de entrenamiento y validaci√≥n')\n",
        "\n",
        "# axes[1].plot(accuracy_acumulado, label='Test Accuracy', color='#16c8e5', marker = \".\")\n",
        "# axes[1].set_xlabel('√âpoca\\n(b)')\n",
        "# axes[1].set_ylabel('Accuracy')\n",
        "# #axes[1].set_title('Test Accuracy')\n",
        "\n",
        "# plt.tight_layout()\n",
        "# plt.savefig(\"resultados_plot.png\", dpi=300)"
      ],
      "metadata": {
        "id": "89_bnleWB4xW"
      },
      "id": "89_bnleWB4xW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Teniendo en cuenta el an√°lisis anterior se procede a generar algunos ejemplos de las clasificaci√≥n obtenida a partir del modelo CNN entrenado"
      ],
      "metadata": {
        "id": "1KJX9niAyHOR"
      },
      "id": "1KJX9niAyHOR"
    },
    {
      "cell_type": "markdown",
      "id": "DwUWQIAE3O0o",
      "metadata": {
        "id": "DwUWQIAE3O0o"
      },
      "source": [
        "***\n",
        "\n",
        "\n",
        "# 6. Referencias"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BoLDjBS03xiQ",
      "metadata": {
        "id": "BoLDjBS03xiQ"
      },
      "source": [
        "\n",
        "[¬π] **Pytorch, entrenando un clasificador**  \n",
        "Disponible en: [Pytorch.org](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html)\n",
        "\n",
        "[¬≤] **MRI sequences (overview), Radiopaedia.org**  \n",
        "Disponible en: [radiopaedia.org](https://radiopaedia.org/articles/mri-sequences-overview?embed_domain=staging.radpair.comfavicon.icofavicon.icoradiopaedia-icon-144.png&lang=us)\n",
        "\n",
        "[¬≥] **Image Normalization in PyTorch**  \n",
        "Disponible en: [medium.com](https://medium.com/%40piyushkashyap045/image-normalization-in-pytorch-from-tensor-conversion-to-scaling-3951b6337bc8)\n",
        "\n",
        "[‚Å¥] **Harnessing Python and SHA-256: An intuitive guide to removing duplicate files**  \n",
        "Disponible en: [medium.com](https://medium.com/gitconnected/harnessing-python-and-sha-256-an-intuitive-guide-to-removing-duplicate-files-d3b02e0b3978)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}