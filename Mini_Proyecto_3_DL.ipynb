{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jorbnc/MAIA-DL/blob/master/Mini_Proyecto_3_DL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oa_MJEGQ6jTi",
      "metadata": {
        "id": "oa_MJEGQ6jTi"
      },
      "source": [
        "![Universidad_de_los_Andes_30.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sl89pic17iPU",
      "metadata": {
        "id": "sl89pic17iPU"
      },
      "source": [
        "<style>\n",
        "@import url('https://fonts.googleapis.com/css2?family=Latin+Modern+Roman:wght@400;700&display=swap');\n",
        "\n",
        "body, p, h1, h2, h3, h4, h5, h6, li {\n",
        "  font-family: 'Latin Modern Roman', serif;\n",
        "}\n",
        "code, pre {\n",
        "  font-family: 'Fira Mono', monospace;\n",
        "}\n",
        "</style>\n",
        "\n",
        "***\n",
        "\n",
        "# **Miniproyecto 3, T√©cnicas de *Deep Learning*: ...**\n",
        "\n",
        "## **Descripci√≥n del Problema**\n",
        "\n",
        "En este miniproyecto se plantea la **clasificaci√≥n multi-clase** de art√≠culos de noticias de la BBC aprovechando la capacidad de los modelos **transformer** para capturar relaciones contextuales complejas. Cada art√≠culo puede pertenecer a una de varias categor√≠as tem√°ticas (e.g., Sport, Business, Politics, Tech).\n",
        "\n",
        "## **Objetivo**\n",
        "\n",
        "Desarrollar e implementar un modelo de clasificaci√≥n multi-clase basado en transformers ( **BERT** y **RoBERTa**) que, tras un preprocesamiento del texto y la adaptaci√≥n de la capa de salida, sea capaz de predecir con alta precisi√≥n, recall y F1-score las categor√≠as de los art√≠culos de la BBC. El modelo deber√° entrenarse y evaluarse usando particiones de entrenamiento, validaci√≥n y prueba, y reportar m√©tricas detalladas por categor√≠a."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SiCS5j-HAbCB",
      "metadata": {
        "id": "SiCS5j-HAbCB"
      },
      "source": [
        "***\n",
        "\n",
        "**Este proyecto es realizado por Andr√©s Felipe √ëungo y Jordan Bryan N√∫√±ez Campos para entrega el 13 de mayo de 2025.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8VqTMx7TYgjH",
      "metadata": {
        "id": "8VqTMx7TYgjH"
      },
      "source": [
        "\n",
        "***\n",
        "# **√çndice**\n",
        "\n",
        "El *notebook* aborda el proyecto con la siguiente estructura:\n",
        "\n",
        "| üîπ | Secci√≥n        |\n",
        "|----|----------------|\n",
        "| 1Ô∏è‚É£. | **Instalaci√≥n y carga de librer√≠as** |\n",
        "| 1Ô∏è‚É£.1Ô∏è‚É£. | **Word2Vec** |\n",
        "| 1Ô∏è‚É£.2Ô∏è‚É£. | **GloVe** |\n",
        "| 1Ô∏è‚É£.3Ô∏è‚É£. | **Configuraciones adicionales** |\n",
        "| 2Ô∏è‚É£. | **An√°lisis exploratorio y preparaci√≥n de los datos**       |\n",
        "| 2Ô∏è‚É£.1Ô∏è‚É£. | **Carga y estad√≠sticas generales**       |\n",
        "| 2Ô∏è‚É£.2Ô∏è‚É£. | **Limpieza de los datos**       |\n",
        "| 3Ô∏è‚É£. | **Definici√≥n de *pipelines* de procesamiento**          |\n",
        "| 3Ô∏è‚É£.1Ô∏è‚É£. | **Pipeline de preprocesamiento**   |\n",
        "| 4Ô∏è‚É£. | **Desarrollo del modelo RNN**   |\n",
        "| 4Ô∏è‚É£.1Ô∏è‚É£. | **Hiperpar√°metros, Partici√≥n y DataLoaders**   |\n",
        "| 4Ô∏è‚É£.2Ô∏è‚É£. | **Definici√≥n del modelo**   |\n",
        "| 4Ô∏è‚É£.3Ô∏è‚É£. | **Entrenamiento, validaci√≥n y prueba**   |\n",
        "| 5Ô∏è‚É£. | **An√°lisis de resultados y discusi√≥n**   |\n",
        "| 5Ô∏è‚É£.1Ô∏è‚É£. | **Pruebas individuales del modelo**   |\n",
        "| 6Ô∏è‚É£. | **Conclusi√≥n**   |\n",
        "| 7Ô∏è‚É£. | **Referencias**   |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cyVuwlHB_W3",
      "metadata": {
        "id": "2cyVuwlHB_W3"
      },
      "source": [
        "***\n",
        "\n",
        "# 1. Instalaci√≥n y carga de librer√≠as"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "...."
      ],
      "metadata": {
        "id": "DkjBiBB5rU6t"
      },
      "id": "DkjBiBB5rU6t"
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations"
      ],
      "metadata": {
        "id": "NWJ88VFyzBPK"
      },
      "id": "NWJ88VFyzBPK",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalaci√≥n de librer√≠as necesarias para correr en Colab/Coursera\n",
        "!pip -q install kagglehub langdetect matplotlib scikit-learn plotly"
      ],
      "metadata": {
        "id": "l26426jMLCxE"
      },
      "id": "l26426jMLCxE",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Librer√≠as comunes\n",
        "import os, random, gc, time\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "CHECKPOINT_PATH = \"/content/drive/MyDrive/bert_checkpoints/best_bert.pt\"\n",
        "\n",
        "# Descarga de datasets y de embeddings\n",
        "import kagglehub\n",
        "\n",
        "# Limipieza y preparaci√≥n de los txtos\n",
        "from langdetect import detect, DetectorFactory\n",
        "import re\n",
        "\n",
        "# Preprocesamiento y herramientas de PLN\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from transformers import (get_linear_schedule_with_warmup,\n",
        "                          AutoTokenizer, AutoModelForSequenceClassification,)\n",
        "\n",
        "# Modelado\n",
        "\n",
        "from typing import List, Dict, Any\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from transformers import PreTrainedTokenizerBase\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "# Evaluaci√≥n\n",
        "from sklearn.metrics import (accuracy_score, f1_score,\n",
        "                              precision_score,\n",
        "                              recall_score,\n",
        "                              classification_report)\n",
        "\n",
        "# Librer√≠as para visualizaciones\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
      ],
      "metadata": {
        "id": "osjmTJMvtxua"
      },
      "id": "osjmTJMvtxua",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uses ‚Äúbert-base-uncased‚Äù version of BERT, which is pre-trained on lower-cased English text\n",
        "\n",
        "(with 12-layer, 768-hidden, 12-heads, 110M parameters)\n",
        "\n",
        "For the purposes of fine-tuning, the authors recommend choosing from the following values (from Appendix A.3 of the BERT paper: https://arxiv.org/pdf/1810.04805.pdf):\n",
        "\n",
        "*   **Batch size:** 16, 32\n",
        "*   **Learning rate (Adam):** 5e-5, 3e-5, 2e-5\n",
        "*   **Number of epochs:** 2, 3, 4\n",
        "\n",
        "[1]"
      ],
      "metadata": {
        "id": "OeOXzQpOa-Lz"
      },
      "id": "OeOXzQpOa-Lz"
    },
    {
      "cell_type": "code",
      "source": [
        "#Par√°metros globales de los modelos\n",
        "TEXT_COL   = \"text\"\n",
        "LABEL_COL  = \"labels\"                    # columna con la categor√≠a en texto\n",
        "MAX_LEN    = 256\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS     = 5\n",
        "PATIENCE   = 2\n",
        "UNFREEZE_PER_EPOCH = 2                 # capas a liberar por √©poca\n",
        "SEED = 13"
      ],
      "metadata": {
        "id": "afgVSw4d1AIw"
      },
      "id": "afgVSw4d1AIw",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se descarga el conjunto de datos de rese√±as de noticias de la BBC de **`kagglehub`**. La funci√≥n **`dataset_download`** guarda los archivos de manera local y devuelve la ruta absoluta, que se almacena en **`path`** y se muestra en pantalla mediante **`print`** para confirmar d√≥nde quedaron los datos."
      ],
      "metadata": {
        "id": "yHwealvATakn"
      },
      "id": "yHwealvATakn"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3. Configuraciones adicionales\n",
        "\n",
        "Con el siguiente bloque se detecta si el entorno dispone de GPU y selecciona el **`device`** apropiado para PyTorch.  \n",
        "\n",
        "Primero se llama a **`is_available()`**, que devuelve *True* si se ha asignado una GPU CUDA al *runtime* de Colab. Seg√∫n el resultado se imprime un mensaje informativo. Posteriormente, se construye el objeto **`device`**, que ser√° pasado a la red y a los tensores de entrada para que se ubiquen en la GPU cuando sea posible. Por √∫ltimo se muestra en pantalla el dispositivo elegido."
      ],
      "metadata": {
        "id": "uOceAejmVjqF"
      },
      "id": "uOceAejmVjqF"
    },
    {
      "cell_type": "code",
      "source": [
        "# Devuelve asignaci√≥n de GPU\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Dispositivo activo ‚Üí {DEVICE}\")"
      ],
      "metadata": {
        "id": "LksJ95qEPWVr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e3be0de-d41b-4545-eeb3-adbf5fe5f039"
      },
      "id": "LksJ95qEPWVr",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dispositivo activo ‚Üí cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adicionalmente se ocultan avisos para mantener limpias algunas salidas del notebook; y se imprimen las versiones de un conjunto de librer√≠as clave ( **`numpy`**, **`pandas`**, **`torch`**, **`scikit-learn`**, **`kagglehub`**, **`matplotlib`**). Mostrar estas versiones al inicio del notebook facilita la reproducibilidad y ayuda a depurar posibles conflictos de dependencias."
      ],
      "metadata": {
        "id": "pfXxKk09Vulp"
      },
      "id": "pfXxKk09Vulp"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "LSwlUgjUjtR_",
      "metadata": {
        "id": "LSwlUgjUjtR_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86b9bb15-1f67-4cc7-9196-3db0db20c26b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numpy :  2.0.2\n",
            "pandas :  2.2.2\n",
            "torch :  2.6.0+cu124\n",
            "scikit-learn :  1.6.1\n",
            "kagglehub :  0.3.12\n",
            "matplotlib :  3.10.0\n"
          ]
        }
      ],
      "source": [
        "# Ignorar las warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Versiones utilizadas\n",
        "from importlib.metadata import version\n",
        "librerias = [\"numpy\", \"pandas\", \"torch\", \"scikit-learn\", \"kagglehub\",\"matplotlib\"]\n",
        "for library in librerias:\n",
        "  print(library, \": \", version(library))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalmente, para cerrar esta secci√≥n se configuran algunas semillas para tener cierto grado de control en la aleatoriedad."
      ],
      "metadata": {
        "id": "ok4F_5E1njTi"
      },
      "id": "ok4F_5E1njTi"
    },
    {
      "cell_type": "code",
      "source": [
        "# Definici√≥n del random state y seeds\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark     = False"
      ],
      "metadata": {
        "id": "xdgcOt7gznvJ"
      },
      "id": "xdgcOt7gznvJ",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "qK311OLFzPep",
      "metadata": {
        "id": "qK311OLFzPep"
      },
      "source": [
        "***\n",
        "\n",
        "# 2. An√°lisis exploratorio y preparaci√≥n de los datos\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "## 2.1. Carga y estad√≠sticas generales"
      ],
      "metadata": {
        "id": "4KxKy7H1eID-"
      },
      "id": "4KxKy7H1eID-"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "K4yOzyWKJbov",
      "metadata": {
        "id": "K4yOzyWKJbov",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b690181f-1b06-4bc2-d11d-b359f1fe32b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datos descargados en: /kaggle/input/bbc-articles-dataset\n",
            "Dataset descargado en: /kaggle/input/bbc-articles-dataset/bbc_news_text_complexity_summarization.csv\n",
            "Filas totales: 2127\n"
          ]
        }
      ],
      "source": [
        "# Leer el conjunto de datos y cargarlo a un dataframe\n",
        "\n",
        "# Descarga del conjunto de datos\n",
        "path = kagglehub.dataset_download(\"jacopoferretti/bbc-articles-dataset\")\n",
        "print(\"Datos descargados en:\", path)\n",
        "\n",
        "CSV_PATH = os.path.join(path, \"bbc_news_text_complexity_summarization.csv\")\n",
        "print(f\"Dataset descargado en: {CSV_PATH}\")\n",
        "\n",
        "data_raw = pd.read_csv(CSV_PATH)\n",
        "print(\"Filas totales:\", len(data_raw))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CNfurSnbmf79",
      "metadata": {
        "id": "CNfurSnbmf79"
      },
      "source": [
        "***\n",
        "\n",
        "## 2.2. Limpieza de los datos\n",
        "\n",
        "En estas secci√≥n identificamos y corregimos:\n",
        "\n",
        "* Valores faltantes\n",
        "* Textos duplicados\n",
        "* Textos en otros idiomas distintos al ingl√©s"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_raw.isna().sum()"
      ],
      "metadata": {
        "id": "2r0P2t_Ysjbq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "outputId": "5c3fc55f-616d-4beb-8fc0-852cd8bca252"
      },
      "id": "2r0P2t_Ysjbq",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text                            0\n",
              "labels                          0\n",
              "no_sentences                    0\n",
              "Flesch Reading Ease Score       0\n",
              "Dale-Chall Readability Score    0\n",
              "text_rank_summary               0\n",
              "lsa_summary                     0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>text</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>labels</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>no_sentences</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Flesch Reading Ease Score</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dale-Chall Readability Score</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>text_rank_summary</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lsa_summary</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_raw.duplicated().sum()"
      ],
      "metadata": {
        "id": "m3IgmRbWskuE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "888f26dc-862a-46a9-fc95-ab0d10bdf776"
      },
      "id": "m3IgmRbWskuE",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int64(0)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = data_raw.copy()"
      ],
      "metadata": {
        "id": "fJETbmzSRX7o"
      },
      "id": "fJETbmzSRX7o",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.1. Carga y estad√≠sticas  ‚ûú  justo despu√©s de copiar el DataFrame\n",
        "\n",
        "le = LabelEncoder()\n",
        "df[\"label_id\"] = le.fit_transform(df[LABEL_COL])\n",
        "\n",
        "NUM_LABELS = len(le.classes_)      # üëà  siempre un entero\n",
        "\n",
        "id2label = {i: lbl for i, lbl in enumerate(le.classes_)}\n",
        "label2id = {v: k for k, v in id2label.items()}"
      ],
      "metadata": {
        "id": "XU6qAVkrjUo3"
      },
      "id": "XU6qAVkrjUo3",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gr√°fica para mostrar distribuci√≥n de las clases\n",
        "def plot_class_distribution(df: pd.DataFrame,\n",
        "                            label_col: str = \"label_id\",\n",
        "                            class_names: list[str] | None = None) -> None:\n",
        "    \"\"\"\n",
        "    Grafica la distribuci√≥n de las clases en el DataFrame.\n",
        "    - df: DataFrame con la columna de etiquetas.\n",
        "    - label_col: nombre de la columna num√©rica de etiquetas.\n",
        "    - class_names: lista de nombres de clase en orden de los IDs.\n",
        "    \"\"\"\n",
        "    counts = df[label_col].value_counts().sort_index()\n",
        "    # Si no se proveen nombres, utilizamos los √≠ndices num√©ricos\n",
        "    labels = class_names if class_names is not None else counts.index.astype(str)\n",
        "\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.bar(labels, counts.values)\n",
        "    plt.xlabel(\"Clase\")\n",
        "    plt.ylabel(\"N√∫mero de art√≠culos\")\n",
        "    plt.title(\"Distribuci√≥n de clases en el dataset\")\n",
        "    plt.xticks(rotation=45, ha=\"right\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Llamada de ejemplo sobre todo el dataset\n",
        "plot_class_distribution(df,\n",
        "                        label_col=\"label_id\",\n",
        "                        class_names=le.classes_.tolist())"
      ],
      "metadata": {
        "id": "1TQpLnbwan5r"
      },
      "id": "1TQpLnbwan5r",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detectar_idiomas(df: pd.DataFrame,\n",
        "                     col_texto: str = 'text') -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Detecta el idioma de cada fila en la columna **col_texto**,\n",
        "    a√±ade la columna **idioma** y muestra ejemplos no ingleses.\n",
        "    \"\"\"\n",
        "    # Inicializamos con 'desconocido'\n",
        "    df['idioma'] = 'desconocido'\n",
        "\n",
        "    # Funci√≥n auxiliar segura\n",
        "    def _detectar(texto):\n",
        "        if isinstance(texto, str) and texto.strip():\n",
        "            try:\n",
        "                return detect(texto)\n",
        "            except Exception:\n",
        "                return 'desconocido'\n",
        "        return 'desconocido'\n",
        "\n",
        "    # Aplicamos detecci√≥n\n",
        "    df['idioma'] = df[col_texto].apply(_detectar)\n",
        "\n",
        "    # Filtramos los que no son ingl√©s\n",
        "    mask = df['idioma'] != 'en'\n",
        "    idx_no_en = df[mask].index\n",
        "\n",
        "    if len(idx_no_en) > 0:\n",
        "        print(f\"Se encontraron {len(idx_no_en)} textos NO en ingl√©s (ejemplos):\")\n",
        "        # Mostramos hasta 5 ejemplos\n",
        "        for i in idx_no_en[:5]:\n",
        "            print(f\" ‚Ä¢ √çndice {i}: [{df.at[i,'idioma']}] {df.at[i,col_texto][:100]}...\")\n",
        "    else:\n",
        "        print(\"Todos los textos est√°n detectados como ingl√©s.\")\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "_WQ5tiJps-bO"
      },
      "id": "_WQ5tiJps-bO",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nota: En algunas ocasiones, la funci√≥n `detect` confunde la presencia de nombres propios o peque√±as secciones en otros idiomas como un indicativo de que el texto no est√° en ingl√©s. Sin embargo, estas ocurrencias suelen ser m√≠nimas o nulas."
      ],
      "metadata": {
        "id": "bAyfWDggeQW-"
      },
      "id": "bAyfWDggeQW-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Detectando otros idiomas:"
      ],
      "metadata": {
        "id": "znjAi7TSPK3f"
      },
      "id": "znjAi7TSPK3f"
    },
    {
      "cell_type": "code",
      "source": [
        "df = detectar_idiomas(df, col_texto='text')"
      ],
      "metadata": {
        "id": "DpTn9HpSW6V9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ed8b82b-816b-47f9-f934-b67dfc91d29f"
      },
      "id": "DpTn9HpSW6V9",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Todos los textos est√°n detectados como ingl√©s.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_ypyorGqwmRl",
      "metadata": {
        "id": "_ypyorGqwmRl"
      },
      "source": [
        "***\n",
        "\n",
        "# 3. Definici√≥n de *pipelines* de procesamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4370a607-ad43-4c5d-bddd-1a9370469409",
      "metadata": {
        "id": "4370a607-ad43-4c5d-bddd-1a9370469409"
      },
      "source": [
        "***\n",
        "\n",
        "## 3.1. *Pipeline* de preprocesamiento\n",
        "\n",
        "...."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Limpieza b√°sica\n",
        "def clean_text(text: str) -> str:\n",
        "    text = re.sub(r\"\\s+\", \" \", text)            #¬†colapsar whitespace\n",
        "    text = re.sub(r\"[^\\w.,;:!?()¬ø¬° ]+\", \"\", text)\n",
        "    return text.strip()\n",
        "\n",
        "for col in (\"text\", \"text_rank_summary\", \"lsa_summary\"):\n",
        "    if col in df.columns:\n",
        "        df[col] = df[col].astype(str).apply(clean_text)\n"
      ],
      "metadata": {
        "id": "tK_D4XVsnk6c"
      },
      "id": "tK_D4XVsnk6c",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, test_df = train_test_split(\n",
        "    df, test_size=0.10, stratify=df[\"label_id\"], random_state=SEED\n",
        ")\n",
        "train_df, val_df = train_test_split(\n",
        "    train_df, test_size=0.10, stratify=train_df[\"label_id\"], random_state=SEED\n",
        ")\n",
        "print(\"Tama√±os ‚Äì¬†Train / Val / Test:\", len(train_df), len(val_df), len(test_df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6QJGsVGvoIK",
        "outputId": "f0f70522-0f33-4bf6-d399-ccecaaee5be6"
      },
      "id": "L6QJGsVGvoIK",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tama√±os ‚Äì¬†Train / Val / Test: 1722 192 213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[2]"
      ],
      "metadata": {
        "id": "TFInYXoOXHTh"
      },
      "id": "TFInYXoOXHTh"
    },
    {
      "cell_type": "markdown",
      "id": "G6-RrjwuxYEw",
      "metadata": {
        "id": "G6-RrjwuxYEw"
      },
      "source": [
        "***\n",
        "\n",
        "# 4. Desarrollo del modelo RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "## 4.1. Hiperpar√°metros, partici√≥n y *DataLoaders*\n",
        "\n",
        "AutoTokenizer\tCuando tu pipeline puede alternar entre arquitecturas (BERT, RoBERTa, DistilBERT‚Ä¶) o quieres mantener el c√≥digo gen√©rico.  \n",
        "+ Detecta internamente la clase correcta ( BertTokenizerFast, RobertaTokenizerFast ‚Ä¶).\n",
        "+ Un √∫nico import.\n",
        "+ Reduce ‚Äúif/else‚Äù en tu c√≥digo.\n",
        "‚àí Ligeramente m√°s sobrecarga al resolver la clase la primera vez (irrelevante en la pr√°ctica).\n",
        "\n",
        "¬øD√≥nde est√° la ‚Äúpreparaci√≥n de secuencias‚Äù en tu c√≥digo?\n",
        "El punto exacto aparece dentro del m√©todo __getitem__ de la clase BBCDataset (alrededor de la mitad del archivo mini_proyecto_3_dl.py). All√≠ se llama al tokenizer para convertir cada art√≠culo en la representaci√≥n num√©rica que entiende BERT/RoBERTa:\n",
        "\n",
        "Tokenizaci√≥n\n",
        "AutoTokenizer descompone el texto en sub-palabras seg√∫n el vocabulario del modelo (WordPiece para BERT, Byte-Pair para RoBERTa, etc.). Tambi√©n a√±ade los special tokens [CLS] y [SEP] que marcan inicio y fin de la secuencia.\n",
        "\n",
        "Conversi√≥n a IDs\n",
        "Cada token se mapea a un entero (input_ids) que luego se transformar√° en embeddings dentro del modelo.\n",
        "\n",
        "M√°scara de atenci√≥n\n",
        "Se crea attention_mask, un vector 1/0 que indica cu√°les posiciones son texto real y cu√°les son padding.\n",
        "\n",
        "Truncado y padding\n",
        "Con truncation=True y padding=\"max_length\" el texto se corta si supera MAX_LEN (256) y se rellena con ceros hasta ese mismo largo, garantizando que todos los ejemplos midan lo mismo y puedan apilarse en un batch.\n",
        "\n",
        "Empaquetado en tensores PyTorch\n",
        "return_tensors=\"pt\" devuelve cada parte como un tensor; luego squeeze(0) elimina la dimensi√≥n de tama√±o 1 a√±adida por el tokenizer para facilitar el batching posterior.\n",
        "\n",
        "En conjunto, este bloque es el ‚Äúpreparador de secuencias‚Äù: convierte texto crudo en el lote de tensores (input_ids, attention_mask, y opcionalmente token_type_ids) que el encoder transformer necesita para producir embeddings y, finalmente, la predicci√≥n de clase."
      ],
      "metadata": {
        "id": "wqy-xlwJ2zMS"
      },
      "id": "wqy-xlwJ2zMS"
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------\n",
        "#  BBCDataset   (misma l√≥gica, solo un par de detalles)\n",
        "# -----------------------------------------------------\n",
        "class BBCDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset para la clasificaci√≥n BBC.\n",
        "    ‚Ä¢ Mantiene tokenizaci√≥n con el tokenizer recibido (AutoTokenizer).\n",
        "    ‚Ä¢ Devuelve exactamente las mismas claves que antes:\n",
        "        input_ids / attention_mask / (token_type_ids) / labels\n",
        "    ‚Ä¢ Opci√≥n `return_idx` por si en alg√∫n an√°lisis necesitas\n",
        "      recuperar el √≠ndice original; por defecto NO cambia nada.\n",
        "    \"\"\"\n",
        "    def __init__(self, df, tokenizer, max_len, *, return_idx: bool = False):\n",
        "        self.texts  = df[TEXT_COL].tolist()\n",
        "        self.labels = df[\"label_id\"].tolist()\n",
        "        self.tok    = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.return_idx = return_idx\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        enc = self.tok(\n",
        "            self.texts[idx],\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=self.max_len,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        item = {k: v.squeeze(0) for k, v in enc.items()}\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        item[\"text\"] = self.texts[idx]\n",
        "        if self.return_idx:\n",
        "            item[\"idx\"] = torch.tensor(idx)   # ‚Üê opcional, no molesta al resto\n",
        "        return item"
      ],
      "metadata": {
        "id": "zfp-stYtEt71"
      },
      "id": "zfp-stYtEt71",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_with_text(batch):\n",
        "    texts  = [b.pop(\"text\") for b in batch]\n",
        "    keys   = batch[0].keys()          # input_ids, attention_mask, labels, ‚Ä¶\n",
        "    out    = {k: torch.stack([b[k] for b in batch]) for k in keys}\n",
        "    out[\"text\"] = texts               # vuelve a incluir texto\n",
        "    if \"idx\" in batch[0]:\n",
        "        out[\"idx\"] = torch.stack([b[\"idx\"] for b in batch])\n",
        "    return out"
      ],
      "metadata": {
        "id": "zPBwOr5LvZBH"
      },
      "id": "zPBwOr5LvZBH",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_loader(df, tokenizer, split, batch_size, max_len,\n",
        "                *, return_idx=False, num_workers=2):\n",
        "    ds = BBCDataset(df, tokenizer, max_len, return_idx=return_idx)\n",
        "    return DataLoader(\n",
        "        ds, batch_size=batch_size, shuffle=(split==\"train\"),\n",
        "        num_workers=num_workers, pin_memory=True,\n",
        "        collate_fn=collate_with_text                     #  ‚Üê  nuevo\n",
        "    )"
      ],
      "metadata": {
        "id": "3bPJ2rdm_v46"
      },
      "id": "3bPJ2rdm_v46",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def freeze_layers(model,\n",
        "                  *,\n",
        "                  freeze: bool = True,\n",
        "                  last_n: int | None = None) -> None:\n",
        "    \"\"\"\n",
        "    Congela/descongela capas del encoder de un modelo *transformers*.\n",
        "\n",
        "    Par√°metros\n",
        "    ----------\n",
        "    model   : instancia de AutoModelForSequenceClassification\n",
        "    freeze  : si *True* congela; si *False* descongela.\n",
        "    last_n  :  ‚Ä¢ None  ‚ûú aplica a **todo** el encoder\n",
        "               ‚Ä¢ int   ‚ûú afecta solo a las *n* √∫ltimas capas\n",
        "\n",
        "    Ejemplos\n",
        "    --------\n",
        "    # 1) Congelar todo el encoder\n",
        "    freeze_layers(model)                       # freeze=True, last_n=None\n",
        "\n",
        "    # 2) Descongelar las 4 √∫ltimas capas\n",
        "    freeze_layers(model, freeze=False, last_n=4)\n",
        "\n",
        "    # 3) Congelar todo excepto las 2 √∫ltimas capas\n",
        "    freeze_layers(model, freeze=True,  last_n=2)\n",
        "    \"\"\"\n",
        "    # 1) Hay modelos (e.g., DistilBERT) donde el encoder vive en .transformer\n",
        "    encoder = getattr(model.base_model, \"encoder\", None) \\\n",
        "              or getattr(model.base_model, \"transformer\", None)\n",
        "\n",
        "    if encoder is None:            # fallback gen√©rico\n",
        "        for p in model.base_model.parameters():\n",
        "            p.requires_grad = not freeze if last_n is None else p.requires_grad\n",
        "        return\n",
        "\n",
        "    layers = list(encoder.layer)\n",
        "    if last_n is None:\n",
        "        # Congela o descongela todo el encoder\n",
        "        for p in encoder.parameters():\n",
        "            p.requires_grad = not freeze\n",
        "    else:\n",
        "        # Asegura que last_n no exceda el n√∫mero total de capas\n",
        "        last_n = max(0, min(last_n, len(layers)))\n",
        "\n",
        "        # 2) Definir subconjuntos\n",
        "        affected = layers[-last_n:]           # capas que cambian\n",
        "        unaffected = layers[:-last_n]         # capas que se mantienen\n",
        "\n",
        "        # 3) Aplicar flags\n",
        "        for layer in affected:\n",
        "            for p in layer.parameters():\n",
        "                p.requires_grad = not freeze if freeze else True\n",
        "\n",
        "        if freeze:                            # solo cuando queremos congelar\n",
        "            for layer in unaffected:\n",
        "                for p in layer.parameters():\n",
        "                    p.requires_grad = False"
      ],
      "metadata": {
        "id": "qudFCuoD0Gw_"
      },
      "id": "qudFCuoD0Gw_",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) predict_proba  ‚ûú  decorador\n",
        "@torch.no_grad()\n",
        "def predict_proba(model, batch, *, device):\n",
        "    \"\"\"\n",
        "    Devuelve las probabilidades (softmax) para un batch.\n",
        "    ‚ûú batch: dict con input_ids, attention_mask, (token_type_ids)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    inputs = {k: v.to(device) for k, v in batch.items()\n",
        "              if k not in [\"labels\", \"text\", \"idx\"]}\n",
        "    logits = model(**inputs).logits           # (B, num_labels)\n",
        "    probs  = F.softmax(logits, dim=-1)\n",
        "    return probs.cpu()"
      ],
      "metadata": {
        "id": "s6UVvASWngOQ"
      },
      "id": "s6UVvASWngOQ",
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------\n",
        "# 4. Funci√≥n train_and_evaluate  >>> MODIFIED <<<\n",
        "# -----------------------------------------------------\n",
        "\n",
        "\n",
        "def train_and_evaluate(model_name: str, train_df, val_df, test_df):\n",
        "    print(f\"\\n========== Entrenando {model_name} ==========\")\n",
        "\n",
        "    start = time.time()\n",
        "    # Tokenizer + modelo\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        model_name,\n",
        "        num_labels=NUM_LABELS,\n",
        "        id2label=id2label,\n",
        "        label2id=label2id,\n",
        "    ).to(DEVICE)\n",
        "\n",
        "    # 5.1 Congelar encoder completo y luego liberar gradualmente\n",
        "    freeze_layers(model)\n",
        "\n",
        "    # 5.2 Pesos de clase balanceados\n",
        "    class_weights = compute_class_weight(\n",
        "        class_weight=\"balanced\", classes=np.arange(NUM_LABELS), y=train_df[\"label_id\"]\n",
        "    )\n",
        "    class_weights = torch.tensor(class_weights, dtype=torch.float32, device=DEVICE)\n",
        "\n",
        "    # 5.3 DataLoaders\n",
        "    loaders = {\n",
        "        \"train\": make_loader(train_df, tokenizer, \"train\", BATCH_SIZE, MAX_LEN),\n",
        "        \"val\":   make_loader(val_df,   tokenizer, \"val\",   BATCH_SIZE, MAX_LEN),\n",
        "        \"test\":  make_loader(test_df,  tokenizer, \"test\",  BATCH_SIZE, MAX_LEN),\n",
        "    }\n",
        "\n",
        "    # 5.4 Optimizador & scheduler\n",
        "    total_steps = len(loaders[\"train\"]) * EPOCHS\n",
        "    optimizer   = AdamW(model.parameters(), lr=2e-5, weight_decay=1e-2)\n",
        "    scheduler   = get_linear_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps=int(0.06 * total_steps),\n",
        "        num_training_steps=total_steps,\n",
        "    )\n",
        "\n",
        "    criterion   = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "    best_f1, patience_cnt = 0.0, 0\n",
        "    best_path = f\"best_{model_name.split('-')[0]}_bbc.pt\"\n",
        "\n",
        "    def epoch_pass(split):\n",
        "        is_train = split == \"train\"\n",
        "        model.train() if is_train else model.eval()\n",
        "        losses, preds_all, trues_all = [], [], []\n",
        "\n",
        "        for batch in loaders[split]:\n",
        "            batch = {k: (v.to(DEVICE) if torch.is_tensor(v) else v) for k,v in batch.items()}\n",
        "            with torch.set_grad_enabled(is_train):\n",
        "                inputs = {k: v for k, v in batch.items() if k not in [\"labels\", \"text\", \"idx\"]}\n",
        "                outputs = model(**inputs)\n",
        "                loss = criterion(outputs.logits, batch[\"labels\"])\n",
        "                if is_train:\n",
        "                    loss.backward()\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "                    optimizer.step(); scheduler.step(); optimizer.zero_grad()\n",
        "\n",
        "            losses.append(loss.item())\n",
        "            preds_all.extend(outputs.logits.argmax(dim=-1).cpu().numpy())\n",
        "            trues_all.extend(batch[\"labels\"].cpu().numpy())\n",
        "\n",
        "        acc = accuracy_score(trues_all, preds_all)\n",
        "        f1m = f1_score(trues_all, preds_all, average=\"macro\", zero_division=0)\n",
        "        f1¬µ = f1_score(trues_all, preds_all, average=\"micro\", zero_division=0)\n",
        "        return np.mean(losses), acc, f1m, f1¬µ\n",
        "\n",
        "    # 5.5 Entrenamiento\n",
        "    hist = {k: [] for k in [\"epoch\",\"train_loss\",\"val_loss\",\n",
        "                        \"train_acc\",\"val_acc\",\"train_f1\",\"val_f1\"]}\n",
        "    for epoch in range(1, EPOCHS + 1):\n",
        "        freeze_layers(model, freeze=False,last_n=epoch * UNFREEZE_PER_EPOCH)\n",
        "        train_loss, train_acc, train_f1m, train_f1¬µ = epoch_pass(\"train\")\n",
        "        val_loss,   val_acc,   val_f1m,   val_f1¬µ   = epoch_pass(\"val\")\n",
        "        hist[\"epoch\"].append(epoch)\n",
        "        hist[\"train_loss\"].append(train_loss); hist[\"val_loss\"].append(val_loss)\n",
        "        hist[\"train_acc\"].append(train_acc);   hist[\"val_acc\"].append(val_acc)\n",
        "        hist[\"train_f1\"].append(train_f1m);    hist[\"val_f1\"].append(val_f1m)\n",
        "\n",
        "        print(f\"Ep {epoch:02d}: \\tTL {train_loss:.4f} / VL {val_loss:.4f} | \"\n",
        "              f\"F1_macro {val_f1m:.3f}  Acc {val_acc:.3f}\")\n",
        "\n",
        "        if val_f1m > best_f1:\n",
        "            best_f1 = val_f1m\n",
        "            patience_cnt = 0\n",
        "            torch.save(model.state_dict(), best_path)\n",
        "        else:\n",
        "            patience_cnt += 1\n",
        "            if patience_cnt == PATIENCE:\n",
        "                print(\"Early stopping¬†‚ÜØ\\n\")\n",
        "                break\n",
        "\n",
        "    # 5.6 Evaluaci√≥n sobre *test*\n",
        "    model.load_state_dict(torch.load(best_path))\n",
        "    test_loss, test_acc, test_f1m, test_f1¬µ = epoch_pass(\"test\")\n",
        "\n",
        "    y_true, y_pred = [], []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in loaders[\"test\"]:\n",
        "            batch = {k: (v.to(DEVICE) if torch.is_tensor(v) else v) for k,v in batch.items()}\n",
        "            inputs = {k: v for k, v in batch.items() if k not in [\"labels\", \"text\", \"idx\"]}\n",
        "            outputs = model(**inputs)\n",
        "            y_true.extend(batch[\"labels\"].cpu().numpy())\n",
        "            y_pred.extend(outputs.logits.argmax(dim=-1).cpu().numpy())\n",
        "\n",
        "    # Precisi√≥n y recall (macro / micro)\n",
        "    prec_macro = precision_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
        "    prec_micro = precision_score(y_true, y_pred, average=\"micro\", zero_division=0)\n",
        "    rec_macro  = recall_score   (y_true, y_pred, average=\"macro\", zero_division=0)\n",
        "    rec_micro  = recall_score   (y_true, y_pred, average=\"micro\", zero_division=0)\n",
        "\n",
        "    report = classification_report(\n",
        "        y_true,\n",
        "        y_pred,\n",
        "        labels=list(range(NUM_LABELS)),\n",
        "        target_names=le.classes_.tolist(),\n",
        "        digits=3,\n",
        "        zero_division=0,\n",
        "    )\n",
        "\n",
        "    # 5.7 Limpieza expl√≠cita\n",
        "    test_loader_ref = loaders[\"test\"]    # referencia antes de borrar\n",
        "    del loaders, optimizer, scheduler, criterion\n",
        "    gc.collect(); torch.cuda.empty_cache()\n",
        "\n",
        "    metrics: dict[str, Any] = {\n",
        "        \"model\": model_name,\n",
        "        \"test_acc\":        test_acc,\n",
        "        \"test_precision_macro\": prec_macro,\n",
        "        \"test_precision_micro\": prec_micro,\n",
        "        \"test_recall_macro\":    rec_macro,\n",
        "        \"test_recall_micro\":    rec_micro,\n",
        "        \"test_f1_macro\":        test_f1m,\n",
        "        \"test_f1_micro\":        test_f1¬µ,\n",
        "        \"report\":  report,          # classification_report\n",
        "        \"history\": hist,            # losses / accuracies por √©poca\n",
        "        # --- NUEVO ---\n",
        "        \"trained_model\": model,     # para an√°lisis posterior\n",
        "        \"test_loader\": test_loader_ref  } # coherente\n",
        "\n",
        "    print(f\"\\n‚è± Duraci√≥n total: {(time.time()-start)/60:.1f} min\")\n",
        "    return metrics, model, tokenizer, test_loader_ref , hist"
      ],
      "metadata": {
        "id": "yod5PSrpEXcq"
      },
      "id": "yod5PSrpEXcq",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "...."
      ],
      "metadata": {
        "id": "iYYOH084USqx"
      },
      "id": "iYYOH084USqx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "## 4.3. Entrenamiento, validaci√≥n y prueba\n",
        "\n",
        " **`gradient clipping`** m"
      ],
      "metadata": {
        "id": "oz4ZPXG44a8W"
      },
      "id": "oz4ZPXG44a8W"
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    start_main = time.time()          # ‚Üê aqu√≠\n",
        "    MODELS = {\n",
        "        \"bert-base-uncased\": \"BERT\",\n",
        "        \"roberta-base\": \"RoBERTa\",\n",
        "    }\n",
        "\n",
        "    results =[]\n",
        "    models, loaders, histories = {}, {}, {}\n",
        "    for mdl_name, label in MODELS.items():\n",
        "        m, mol, tok, tl, h  = train_and_evaluate(mdl_name, train_df, val_df, test_df)\n",
        "        results.append(m)\n",
        "        models[mdl_name]   = m\n",
        "        loaders[mdl_name]  = tl\n",
        "        histories[mdl_name]= h\n",
        "        print(\"\\n>>> Reporte detallado\")\n",
        "        print(m[\"report\"])\n",
        "        print(\"=\"*60)\n",
        "\n",
        "    # tabla comparativa\n",
        "    print(\"\\n======= Comparativa final =======\")\n",
        "    for res in results:\n",
        "        print(f\"{MODELS[res['model']]:9s} | \"\n",
        "        f\"Acc {res['test_acc']:.3f} | \"\n",
        "        f\"P_macro {res['test_precision_macro']:.3f} | \"\n",
        "        f\"R_macro {res['test_recall_macro']:.3f} | \"\n",
        "        f\"F1_macro {res['test_f1_macro']:.3f}\")\n",
        "\n",
        "    dur = (time.time() - start_main) / 60\n",
        "    print(f\"\\nTiempo total: {dur:.1f} min\\n\")"
      ],
      "metadata": {
        "id": "JAtN1d5G21to",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f979f849-bc40-462a-9c7f-ad204a0b5f59"
      },
      "id": "JAtN1d5G21to",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========== Entrenando bert-base-uncased ==========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "M√©trica\t¬øC√≥mo se calcula?\tCu√°ndo aporta valor\tObservaciones para tu proyecto (BBC News, 5 clases)\n",
        "Micro-precision/recall/F1\tSuma todos los TP, FP, FN y calcula la raz√≥n una sola vez.\t‚Ä¢ Multi-label‚ÄÇ(muchas etiquetas por muestra).\n",
        "‚Ä¢ Conjuntos muy desbalanceados donde el ‚Äútama√±o‚Äù total importa (p. ej., m√©tricas de search).\tPara clasificaci√≥n single-label multi-clase, el micro-F1 coincide con la accuracy. Si ya reportas accuracy, el micro-F1 a√±ade poca informaci√≥n nueva.\n",
        "Macro-precision/recall/F1\tCalcula la m√©trica por clase y luego hace el promedio simple (no ponderado).\t‚Ä¢ Quieres ver si el modelo trata a todas las clases por igual.\n",
        "‚Ä¢ Dataset algo desbalanceado.\n",
        "‚Ä¢ Necesitas comparaci√≥n justa entre modelos cuando hay minor√≠as.\t√ötil incluso con BBC (distribuci√≥n ‚âà balanceada, pero nunca perfecta) para evidenciar si alguna categor√≠a -‚Äútech‚Äù, ‚Äúsport‚Äù‚Ä¶- se queda atr√°s."
      ],
      "metadata": {
        "id": "wFt2XQ0PcZIJ"
      },
      "id": "wFt2XQ0PcZIJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "[3]"
      ],
      "metadata": {
        "id": "Pfn0fl1zaEVT"
      },
      "id": "Pfn0fl1zaEVT"
    },
    {
      "cell_type": "markdown",
      "source": [
        "..."
      ],
      "metadata": {
        "id": "75G3J6o5ieVc"
      },
      "id": "75G3J6o5ieVc"
    },
    {
      "cell_type": "markdown",
      "id": "7JgtiyyfIyMM",
      "metadata": {
        "id": "7JgtiyyfIyMM"
      },
      "source": [
        "***\n",
        "\n",
        "\n",
        "# 5. An√°lisis de resultados y discusi√≥n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "..."
      ],
      "metadata": {
        "id": "Ty3gzWEui8xK"
      },
      "id": "Ty3gzWEui8xK"
    },
    {
      "cell_type": "markdown",
      "source": [
        "..."
      ],
      "metadata": {
        "id": "qJZ_NDzdjQ7G"
      },
      "id": "qJZ_NDzdjQ7G"
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_model_diagnostics(*,\n",
        "                            history: dict | None = None,\n",
        "                            model = None,\n",
        "                            test_loader = None,\n",
        "                            class_names: list[str] | None = None,\n",
        "                            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
        "                            title: str = \"\") -> None:\n",
        "    \"\"\"\n",
        "    Combina en una sola figura:\n",
        "       ‚Ä¢ Curvas de Loss y Accuracy (si se pasa `history`)\n",
        "       ‚Ä¢ Matriz de confusi√≥n        (si se pasa `model` + `test_loader`)\n",
        "    Puedes suministrar solo una de las dos partes si lo prefieres.\n",
        "\n",
        "    Par√°metros\n",
        "    ----------\n",
        "    history      : dict con claves 'train_loss', 'val_loss', 'train_acc', 'val_acc'\n",
        "    model        : modelo transformers ya entrenado\n",
        "    test_loader  : DataLoader con el set de test\n",
        "    class_names  : lista de etiquetas (str) en el mismo orden que los IDs\n",
        "    device       : cpu / cuda\n",
        "    title        : t√≠tulo base que se antepone a cada sub-gr√°fico\n",
        "    \"\"\"\n",
        "    # ------ determinar cu√°ntas filas de subplots necesitamos ------\n",
        "    n_rows = 0\n",
        "    if history is not None:\n",
        "        n_rows += 2                # Loss y Accuracy\n",
        "    if model is not None and test_loader is not None and class_names is not None:\n",
        "        n_rows += 1                # Matriz de confusi√≥n\n",
        "    if n_rows == 0:\n",
        "        raise ValueError(\"Debes pasar `history` o (`model`, `test_loader`, `class_names`).\")\n",
        "\n",
        "    plt.figure(figsize=(7, 4 * n_rows))\n",
        "    plot_idx = 1\n",
        "\n",
        "    # ------ curvas de entrenamiento ------------------------------\n",
        "    if history is not None:\n",
        "        epochs = range(1, len(history[\"train_loss\"]) + 1)\n",
        "\n",
        "        # Loss\n",
        "        plt.subplot(n_rows, 1, plot_idx)\n",
        "        plt.plot(epochs, history[\"train_loss\"], label=\"Train Loss\")\n",
        "        plt.plot(epochs, history[\"val_loss\"],   label=\"Val Loss\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.title(f\"{title} ‚Äì Loss\")\n",
        "        plt.legend()\n",
        "        plot_idx += 1\n",
        "\n",
        "        # Accuracy\n",
        "        plt.subplot(n_rows, 1, plot_idx)\n",
        "        plt.plot(epochs, history[\"train_acc\"], label=\"Train Acc\")\n",
        "        plt.plot(epochs, history[\"val_acc\"],   label=\"Val Acc\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"Accuracy\")\n",
        "        plt.title(f\"{title} ‚Äì Accuracy\")\n",
        "        plt.legend()\n",
        "        plot_idx += 1\n",
        "\n",
        "    # ------ matriz de confusi√≥n ----------------------------------\n",
        "    if model is not None and test_loader is not None and class_names is not None:\n",
        "        model.eval()\n",
        "        y_true, y_pred = [], []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in test_loader:\n",
        "                # ‚Üê el DataLoader sigue entregando las mismas claves que antes\n",
        "                labels = batch[\"labels\"]\n",
        "                inputs = {k: v.to(device) for k, v in batch.items() if k not in [\"labels\", \"text\", \"idx\"]}\n",
        "\n",
        "                logits = model(**inputs).logits\n",
        "                probs = F.softmax(logits, dim=-1)\n",
        "                preds = torch.argmax(probs, dim=1)\n",
        "\n",
        "                y_true.extend(labels.cpu().tolist())\n",
        "                y_pred.extend(preds.cpu().tolist())\n",
        "\n",
        "        cm = confusion_matrix(y_true, y_pred)\n",
        "        plt.subplot(n_rows, 1, plot_idx)\n",
        "        disp = ConfusionMatrixDisplay(cm, display_labels=class_names)\n",
        "        disp.plot(ax=plt.gca(), cmap=\"Blues\", colorbar=False)\n",
        "        plt.title(f\"{title} ‚Äì Confusion Matrix\")\n",
        "        plt.xlabel(\"Predicted\")\n",
        "        plt.ylabel(\"True\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "uaauR7IpagRo"
      },
      "id": "uaauR7IpagRo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model_diagnostics(\n",
        "    history     = histories[\"bert-base-uncased\"],\n",
        "    model       = models[\"bert-base-uncased\"],\n",
        "    test_loader = loaders[\"bert-base-uncased\"],\n",
        "    class_names = le.classes_.tolist(),\n",
        "    title       = \"BERT\"\n",
        ")\n",
        "\n",
        "plot_model_diagnostics(\n",
        "    history     = histories[\"roberta-base\"],\n",
        "    model       = models[\"roberta-base\"],\n",
        "    test_loader = loaders[\"roberta-base\"],\n",
        "    class_names = le.classes_.tolist(),\n",
        "    title       = \"RoBERTa\"\n",
        ")"
      ],
      "metadata": {
        "id": "KWYnrx5nGZtR"
      },
      "id": "KWYnrx5nGZtR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------\n",
        "#  Ejemplos FN / FP por clase  (c√≥digo simplificado)\n",
        "# -----------------------------------------------------\n",
        "def collect_fn_fp_examples(model,\n",
        "                            test_loader,\n",
        "                            test_df,\n",
        "                            class_names: list[str],\n",
        "                            *,\n",
        "                            device=DEVICE,\n",
        "                            k: int = 5) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Devuelve un DataFrame con **hasta `k`** ejemplos *FN* y *FP*\n",
        "    por clase, adem√°s de los *TP* para referencia.\n",
        "\n",
        "    Columnas devueltas:\n",
        "      ‚îú‚îÄ text     : texto original\n",
        "      ‚îú‚îÄ true     : etiqueta real         (int)\n",
        "      ‚îú‚îÄ pred     : etiqueta predicha     (int)\n",
        "      ‚îî‚îÄ type     : 'TP' ‚Äñ 'FN' ‚Äñ 'FP'\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    texts, y_true, y_pred = [], [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            labels = batch[\"labels\"]\n",
        "            inputs = {k:v.to(device) for k,v in batch.items()\n",
        "                      if k not in [\"labels\",\"text\",\"idx\"]}\n",
        "            logits = model(**inputs).logits\n",
        "            probs  = F.softmax(logits, dim=-1)\n",
        "            preds  = torch.argmax(probs, dim=1)\n",
        "\n",
        "            y_true.extend(labels.cpu().tolist())\n",
        "            y_pred.extend(preds.cpu().tolist())\n",
        "            texts.extend(batch[\"text\"])\n",
        "    # --- DataFrame --------------------------------------------------------\n",
        "    df = pd.DataFrame({\n",
        "        \"text\": texts,\n",
        "        \"true\": y_true,\n",
        "        \"pred\": y_pred,\n",
        "    })\n",
        "    df[\"type\"] = \"UNDEF\"\n",
        "    # --- Etiquetar tipo de acierto/error ----------------------------------\n",
        "\n",
        "    # --- Seleccionar hasta k ejemplos por clase y tipo --------------------\n",
        "    out_rows = []\n",
        "    rows=[]\n",
        "    for cls in range(len(class_names)):\n",
        "        df.loc[(df.true==cls) & (df.pred!=cls), \"type\"] = \"FN\"\n",
        "        df.loc[(df.pred==cls) & (df.true!=cls), \"type\"] = \"FP\"\n",
        "        df.loc[(df.true==cls) & (df.pred==cls), \"type\"] = \"TP\"\n",
        "        fn = df[(df.true==cls)&(df.pred!=cls)].head(k)\n",
        "        fp = df[(df.pred==cls)&(df.true!=cls)].head(k)\n",
        "        rows.extend(fn.assign(tipo=\"FN\", clase=class_names[cls]).to_dict(\"records\"))\n",
        "        rows.extend(fp.assign(tipo=\"FP\", clase=class_names[cls]).to_dict(\"records\"))\n",
        "    return pd.DataFrame(rows)"
      ],
      "metadata": {
        "id": "VrcMKrQPGt2J"
      },
      "id": "VrcMKrQPGt2J",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Corre primero la inferencia sobre test_loader\n",
        "df_err_bert = collect_fn_fp_examples(models[\"BERT\"], test_loader,\n",
        "                                     test_df, le.classes_.tolist(), k=3)\n",
        "\n",
        "df_err_roberta = collect_fn_fp_examples(models[\"RoBERTa\"], test_loader,\n",
        "                                     test_df, le.classes_.tolist(), k=3)\n",
        "# 2) Visualiza\n",
        "display(df_err_bert[[\"text\",\"true\",\"pred\",\"tipo\"]].head(10))\n",
        "display(df_err_roberta[[\"text\",\"true\",\"pred\",\"tipo\"]].head(10))"
      ],
      "metadata": {
        "id": "I80o-UdGG4SO"
      },
      "id": "I80o-UdGG4SO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tsne_cls(*,\n",
        "             model,\n",
        "             test_loader,\n",
        "             class_names,\n",
        "             device,\n",
        "             save_path: str | None = None):\n",
        "    \"\"\"\n",
        "    ‚Ä¢ Extrae embeddings [CLS] del modelo sobre `test_loader`.\n",
        "    ‚Ä¢ Ejecuta t-SNE en 2 D con perplexity adaptativa:\n",
        "          perplexity = min(40, n_samples // 10)\n",
        "    ‚Ä¢ Si existe `save_path` y el archivo est√° creado,\n",
        "      reutiliza los embeddings proyectados (ahorra **`time`**).\n",
        "    \"\"\"\n",
        "    # ------------ 1) Obtener o cargar los vectores ----------------\n",
        "    if save_path and os.path.isfile(save_path):\n",
        "        print(f\"‚úî  t-SNE cargado de {save_path}\")\n",
        "        data = np.load(save_path)\n",
        "        X_2d, y = data[:, :2], data[:, 2].astype(int)\n",
        "    else:\n",
        "        model.eval()\n",
        "        reps, labels = [], []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in test_loader:\n",
        "                inputs = {k: v.to(device) for k, v in batch.items()\n",
        "                          if k not in [\"labels\", \"text\"]}\n",
        "                out = model(**inputs, output_hidden_states=True)\n",
        "                cls = out.hidden_states[-1][:, 0, :]      # (B, H)\n",
        "\n",
        "                reps.append(cls.cpu())\n",
        "                labels.extend(batch[\"labels\"].tolist())\n",
        "\n",
        "        X = torch.cat(reps).numpy()\n",
        "        y = np.array(labels)\n",
        "\n",
        "        # ------------ 2) t-SNE con perplexity din√°mica ------------\n",
        "        n_samples   = X.shape[0]\n",
        "        perplexity  = max(5, min(40, n_samples // 10))\n",
        "        print(f\"‚Üí n_samples={n_samples} | perplexity={perplexity}\")\n",
        "\n",
        "        tsne = TSNE(\n",
        "            n_components=2,\n",
        "            perplexity=perplexity,\n",
        "            init=\"random\",\n",
        "            learning_rate=\"auto\",\n",
        "            random_state=42,\n",
        "            n_iter=1000\n",
        "        )\n",
        "        X_2d = tsne.fit_transform(X)\n",
        "\n",
        "        if save_path:\n",
        "            np.save(save_path, np.c_[X_2d, y])\n",
        "            print(f\"üíæ  Guardado en {save_path}\")\n",
        "\n",
        "    # ------------ 3) Graficar ------------------------------------\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    for cls_id, cls_name in enumerate(class_names):\n",
        "        pts = X_2d[y == cls_id]\n",
        "        plt.scatter(pts[:, 0], pts[:, 1], alpha=0.6, label=cls_name, s=15)\n",
        "\n",
        "    plt.title(\"t-SNE de embeddings CLS\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "1jB6JKlLVoQG"
      },
      "id": "1jB6JKlLVoQG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Escoge el modelo que quieres proyectar\n",
        "model_to_plot = models[\"BERT\"]     # o \"RoBERTa\"\n",
        "\n",
        "# 2) Ejecuci√≥n (reutiliza si ya existe 'tsne_cls.npy')\n",
        "tsne_cls(\n",
        "    model       = model_to_plot,\n",
        "    test_loader = test_loader,\n",
        "    class_names = le.classes_.tolist(),\n",
        "    device      = DEVICE,\n",
        "    save_path   = Path(\"tsne_cls.npy\")          # guarda para futuras corridas\n",
        ")"
      ],
      "metadata": {
        "id": "EWyptqdMhynP"
      },
      "id": "EWyptqdMhynP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "\n",
        "# 6. Conclusi√≥n\n",
        "\n",
        "....."
      ],
      "metadata": {
        "id": "uDjo26cIk10k"
      },
      "id": "uDjo26cIk10k"
    },
    {
      "cell_type": "markdown",
      "id": "DwUWQIAE3O0o",
      "metadata": {
        "id": "DwUWQIAE3O0o"
      },
      "source": [
        "***\n",
        "\n",
        "\n",
        "# 7. Referencias"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BoLDjBS03xiQ",
      "metadata": {
        "id": "BoLDjBS03xiQ"
      },
      "source": [
        "[1] **BERT: Pre-training of Deep Bidirectional Transformers for\n",
        "Language Understanding  Google AI Language**  \n",
        "Disponible en: [arxiv.org](https://arxiv.org/abs/1810.04805)\n",
        "\n",
        "\n",
        "[2] **Documents Classification using BERT on BBC Dataset**  \n",
        "Disponible en: [kaggle.com](https://www.kaggle.com/code/ouardasakram/documents-classification-using-bert-on-bbc-dataset)\n",
        "\n",
        "\n",
        "[3] **Bert-Classification-BBC-News**  \n",
        "Disponible en: [github.com](https://github.com/bymi15/Bert-Classification-BBC-News/blob/main/bert_classification_bbc_news.ipynb)\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}