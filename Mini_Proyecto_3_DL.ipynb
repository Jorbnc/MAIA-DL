{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jorbnc/MAIA-DL/blob/master/Mini_Proyecto_3_DL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oa_MJEGQ6jTi",
      "metadata": {
        "id": "oa_MJEGQ6jTi"
      },
      "source": [
        "![Universidad_de_los_Andes_30.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sl89pic17iPU",
      "metadata": {
        "id": "sl89pic17iPU"
      },
      "source": [
        "<style>\n",
        "@import url('https://fonts.googleapis.com/css2?family=Latin+Modern+Roman:wght@400;700&display=swap');\n",
        "\n",
        "body, p, h1, h2, h3, h4, h5, h6, li {\n",
        "  font-family: 'Latin Modern Roman', serif;\n",
        "}\n",
        "code, pre {\n",
        "  font-family: 'Fira Mono', monospace;\n",
        "}\n",
        "</style>\n",
        "\n",
        "***\n",
        "\n",
        "# **Miniproyecto 3, T√©cnicas de *Deep Learning*: ...**\n",
        "\n",
        "## **Descripci√≥n del problema:**\n",
        "\n",
        "...\n",
        "\n",
        "## **Objetivo:**\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SiCS5j-HAbCB",
      "metadata": {
        "id": "SiCS5j-HAbCB"
      },
      "source": [
        "***\n",
        "\n",
        "**Este proyecto es realizado por Andr√©s Felipe √ëungo y Jordan Bryan N√∫√±ez Campos para entrega el 13 de mayo de 2025.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8VqTMx7TYgjH",
      "metadata": {
        "id": "8VqTMx7TYgjH"
      },
      "source": [
        "\n",
        "***\n",
        "# **√çndice**\n",
        "\n",
        "El *notebook* aborda el proyecto con la siguiente estructura:\n",
        "\n",
        "| üîπ | Secci√≥n        |\n",
        "|----|----------------|\n",
        "| 1Ô∏è‚É£. | **Instalaci√≥n y carga de librer√≠as** |\n",
        "| 1Ô∏è‚É£.1Ô∏è‚É£. | **Word2Vec** |\n",
        "| 1Ô∏è‚É£.2Ô∏è‚É£. | **GloVe** |\n",
        "| 1Ô∏è‚É£.3Ô∏è‚É£. | **Configuraciones adicionales** |\n",
        "| 2Ô∏è‚É£. | **An√°lisis exploratorio y preparaci√≥n de los datos**       |\n",
        "| 2Ô∏è‚É£.1Ô∏è‚É£. | **Carga y estad√≠sticas generales**       |\n",
        "| 2Ô∏è‚É£.2Ô∏è‚É£. | **Limpieza de los datos**       |\n",
        "| 3Ô∏è‚É£. | **Definici√≥n de *pipelines* de procesamiento**          |\n",
        "| 3Ô∏è‚É£.1Ô∏è‚É£. | **Pipeline de preprocesamiento**   |\n",
        "| 4Ô∏è‚É£. | **Desarrollo del modelo RNN**   |\n",
        "| 4Ô∏è‚É£.1Ô∏è‚É£. | **Hiperpar√°metros, Partici√≥n y DataLoaders**   |\n",
        "| 4Ô∏è‚É£.2Ô∏è‚É£. | **Definici√≥n del modelo**   |\n",
        "| 4Ô∏è‚É£.3Ô∏è‚É£. | **Entrenamiento, validaci√≥n y prueba**   |\n",
        "| 5Ô∏è‚É£. | **An√°lisis de resultados y discusi√≥n**   |\n",
        "| 5Ô∏è‚É£.1Ô∏è‚É£. | **Pruebas individuales del modelo**   |\n",
        "| 6Ô∏è‚É£. | **Conclusi√≥n**   |\n",
        "| 7Ô∏è‚É£. | **Referencias**   |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cyVuwlHB_W3",
      "metadata": {
        "id": "2cyVuwlHB_W3"
      },
      "source": [
        "***\n",
        "\n",
        "# 1. Instalaci√≥n y carga de librer√≠as"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "...."
      ],
      "metadata": {
        "id": "DkjBiBB5rU6t"
      },
      "id": "DkjBiBB5rU6t"
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalaci√≥n de librer√≠as necesarias para correr en Colab/Coursera\n",
        "!pip -q install kagglehub langdetect wordcloud matplotlib scikit-learn plotly"
      ],
      "metadata": {
        "id": "l26426jMLCxE",
        "outputId": "06b49bc8-e545-4165-99a5-653075a2cdad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "l26426jMLCxE",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/981.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m122.9/981.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m430.1/981.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m972.8/981.5 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Librer√≠as comunes\n",
        "import os, random, sys, time, gc\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Descarga de datasets y de embeddings\n",
        "import kagglehub\n",
        "\n",
        "# Limipieza y preparaci√≥n de los txtos\n",
        "from langdetect import detect, DetectorFactory\n",
        "import re\n",
        "\n",
        "# Preprocesamiento y herramientas de PLN\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from transformers import (BertTokenizer,\n",
        "                          BertForSequenceClassification,\n",
        "                          get_linear_schedule_with_warmup)\n",
        "\n",
        "# Modelado\n",
        "import torch, torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_linear_schedule_with_warmup\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Evaluaci√≥n\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Librer√≠as para visualizaciones\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "from wordcloud import WordCloud"
      ],
      "metadata": {
        "id": "osjmTJMvtxua"
      },
      "id": "osjmTJMvtxua",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uses ‚Äúbert-base-uncased‚Äù version of BERT, which is pre-trained on lower-cased English text\n",
        "\n",
        "(with 12-layer, 768-hidden, 12-heads, 110M parameters)\n",
        "\n",
        "For the purposes of fine-tuning, the authors recommend choosing from the following values (from Appendix A.3 of the BERT paper: https://arxiv.org/pdf/1810.04805.pdf):\n",
        "\n",
        "*   **Batch size:** 16, 32\n",
        "*   **Learning rate (Adam):** 5e-5, 3e-5, 2e-5\n",
        "*   **Number of epochs:** 2, 3, 4\n",
        "\n",
        "[1]"
      ],
      "metadata": {
        "id": "OeOXzQpOa-Lz"
      },
      "id": "OeOXzQpOa-Lz"
    },
    {
      "cell_type": "code",
      "source": [
        "#Par√°metros globales de los modelos\n",
        "MODEL_NAMES = [  # (checkpoint, alias para impresi√≥n)\n",
        "    (\"bert-base-uncased\", \"BERT\"),\n",
        "    (\"roberta-base\", \"RoBERTa\"),\n",
        "]\n",
        "MAX_LEN     = 256\n",
        "BATCH_SIZE  = 16\n",
        "EPOCHS      = 3\n",
        "LR          = 2e-5\n",
        "RANDOM_SEED = 13"
      ],
      "metadata": {
        "id": "afgVSw4d1AIw"
      },
      "id": "afgVSw4d1AIw",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se descarga el conjunto de datos de rese√±as de noticias de la BBC de **`kagglehub`**. La funci√≥n **`dataset_download`** guarda los archivos de manera local y devuelve la ruta absoluta, que se almacena en **`path`** y se muestra en pantalla mediante **`print`** para confirmar d√≥nde quedaron los datos."
      ],
      "metadata": {
        "id": "yHwealvATakn"
      },
      "id": "yHwealvATakn"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3. Configuraciones adicionales\n",
        "\n",
        "Con el siguiente bloque se detecta si el entorno dispone de GPU y selecciona el **`device`** apropiado para PyTorch.  \n",
        "\n",
        "Primero se llama a **`is_available()`**, que devuelve *True* si se ha asignado una GPU CUDA al *runtime* de Colab. Seg√∫n el resultado se imprime un mensaje informativo. Posteriormente, se construye el objeto **`device`**, que ser√° pasado a la red y a los tensores de entrada para que se ubiquen en la GPU cuando sea posible. Por √∫ltimo se muestra en pantalla el dispositivo elegido."
      ],
      "metadata": {
        "id": "uOceAejmVjqF"
      },
      "id": "uOceAejmVjqF"
    },
    {
      "cell_type": "code",
      "source": [
        "# Devuelve asignaci√≥n de GPU\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Dispositivo activo ‚Üí {DEVICE}\")"
      ],
      "metadata": {
        "id": "LksJ95qEPWVr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e86f5355-6829-4b92-b5ae-3a4a56db66a1"
      },
      "id": "LksJ95qEPWVr",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dispositivo activo ‚Üí cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adicionalmente se ocultan avisos para mantener limpias algunas salidas del notebook; y se imprimen las versiones de un conjunto de librer√≠as clave ( **`numpy`**, **`pandas`**, **`torch`**, **`scikit-learn`**, **`kagglehub`**, **`matplotlib`**). Mostrar estas versiones al inicio del notebook facilita la reproducibilidad y ayuda a depurar posibles conflictos de dependencias."
      ],
      "metadata": {
        "id": "pfXxKk09Vulp"
      },
      "id": "pfXxKk09Vulp"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "LSwlUgjUjtR_",
      "metadata": {
        "id": "LSwlUgjUjtR_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c74cd9f7-11cf-4ce9-ae4a-4dbeee4472b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numpy :  2.0.2\n",
            "pandas :  2.2.2\n",
            "torch :  2.6.0+cu124\n",
            "scikit-learn :  1.6.1\n",
            "kagglehub :  0.3.12\n",
            "matplotlib :  3.10.0\n",
            "nltk :  3.9.1\n"
          ]
        }
      ],
      "source": [
        "# Ignorar las warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Versiones utilizadas\n",
        "from importlib.metadata import version\n",
        "librerias = [\"numpy\", \"pandas\", \"torch\", \"scikit-learn\", \"kagglehub\",\"matplotlib\", \"nltk\"]\n",
        "for library in librerias:\n",
        "  print(library, \": \", version(library))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalmente, para cerrar esta secci√≥n se configuran algunas semillas para tener cierto grado de control en la aleatoriedad."
      ],
      "metadata": {
        "id": "ok4F_5E1njTi"
      },
      "id": "ok4F_5E1njTi"
    },
    {
      "cell_type": "code",
      "source": [
        "# Definici√≥n del random state y seeds\n",
        "np.random.seed(RANDOM_SEED)\n",
        "random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "DetectorFactory.seed = RANDOM_SEED"
      ],
      "metadata": {
        "id": "xdgcOt7gznvJ"
      },
      "id": "xdgcOt7gznvJ",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "qK311OLFzPep",
      "metadata": {
        "id": "qK311OLFzPep"
      },
      "source": [
        "***\n",
        "\n",
        "# 2. An√°lisis exploratorio y preparaci√≥n de los datos\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "## 2.1. Carga y estad√≠sticas generales"
      ],
      "metadata": {
        "id": "4KxKy7H1eID-"
      },
      "id": "4KxKy7H1eID-"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "K4yOzyWKJbov",
      "metadata": {
        "id": "K4yOzyWKJbov",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9537f79e-abbd-400d-8015-71e035a7d7a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datos descargados en: /kaggle/input/bbc-articles-dataset\n",
            "Dataset descargado en: /kaggle/input/bbc-articles-dataset/bbc_news_text_complexity_summarization.csv\n",
            "Filas totales: 2127\n"
          ]
        }
      ],
      "source": [
        "# Leer el conjunto de datos y cargarlo a un dataframe\n",
        "\n",
        "# Descarga del conjunto de datos\n",
        "path = kagglehub.dataset_download(\"jacopoferretti/bbc-articles-dataset\")\n",
        "print(\"Datos descargados en:\", path)\n",
        "\n",
        "CSV_PATH = os.path.join(path, \"bbc_news_text_complexity_summarization.csv\")\n",
        "print(f\"Dataset descargado en: {CSV_PATH}\")\n",
        "\n",
        "data_raw = pd.read_csv(CSV_PATH)\n",
        "print(\"Filas totales:\", len(data_raw))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CNfurSnbmf79",
      "metadata": {
        "id": "CNfurSnbmf79"
      },
      "source": [
        "***\n",
        "\n",
        "## 2.2. Limpieza de los datos\n",
        "\n",
        "En estas secci√≥n identificamos y corregimos:\n",
        "\n",
        "* Valores faltantes\n",
        "* Textos duplicados\n",
        "* Textos en otros idiomas distintos al ingl√©s"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_raw.isna().sum()"
      ],
      "metadata": {
        "id": "2r0P2t_Ysjbq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "outputId": "10688fe2-5189-49cd-8733-ceefa9e7ed19"
      },
      "id": "2r0P2t_Ysjbq",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text                            0\n",
              "labels                          0\n",
              "no_sentences                    0\n",
              "Flesch Reading Ease Score       0\n",
              "Dale-Chall Readability Score    0\n",
              "text_rank_summary               0\n",
              "lsa_summary                     0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>text</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>labels</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>no_sentences</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Flesch Reading Ease Score</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dale-Chall Readability Score</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>text_rank_summary</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lsa_summary</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_raw.duplicated().sum()"
      ],
      "metadata": {
        "id": "m3IgmRbWskuE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9703b92-a67f-4872-ac48-eb7ca5d7d719"
      },
      "id": "m3IgmRbWskuE",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int64(0)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = data_raw.copy()"
      ],
      "metadata": {
        "id": "fJETbmzSRX7o"
      },
      "id": "fJETbmzSRX7o",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.1. Carga y estad√≠sticas  ‚ûú  justo despu√©s de copiar el DataFrame\n",
        "LABEL_COL = \"labels\"               # nombre real de la columna en tu CSV\n",
        "\n",
        "le = LabelEncoder()\n",
        "df[\"label_id\"] = le.fit_transform(df[LABEL_COL])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "id": "XU6qAVkrjUo3",
        "outputId": "b148196d-42f6-46a7-ec90-6b6e6d08475e"
      },
      "id": "XU6qAVkrjUo3",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'label'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'label'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-01357477d9eb>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label_id\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 'label' ‚Üí str  / 'label_id' ‚Üí int\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'label'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gr√°fica para mostrar distribuci√≥n de las clases"
      ],
      "metadata": {
        "id": "1TQpLnbwan5r"
      },
      "id": "1TQpLnbwan5r",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detectar_idiomas(df: pd.DataFrame,\n",
        "                     col_texto: str = 'text') -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Detecta el idioma de cada fila en la columna **col_texto**,\n",
        "    a√±ade la columna **idioma** y muestra ejemplos no ingleses.\n",
        "    \"\"\"\n",
        "    # Inicializamos con 'desconocido'\n",
        "    df['idioma'] = 'desconocido'\n",
        "\n",
        "    # Funci√≥n auxiliar segura\n",
        "    def _detectar(texto):\n",
        "        if isinstance(texto, str) and texto.strip():\n",
        "            try:\n",
        "                return detect(texto)\n",
        "            except Exception:\n",
        "                return 'desconocido'\n",
        "        return 'desconocido'\n",
        "\n",
        "    # Aplicamos detecci√≥n\n",
        "    df['idioma'] = df[col_texto].apply(_detectar)\n",
        "\n",
        "    # Filtramos los que no son ingl√©s\n",
        "    mask = df['idioma'] != 'en'\n",
        "    idx_no_en = df[mask].index\n",
        "\n",
        "    if len(idx_no_en) > 0:\n",
        "        print(f\"Se encontraron {len(idx_no_en)} textos NO en ingl√©s (ejemplos):\")\n",
        "        # Mostramos hasta 5 ejemplos\n",
        "        for i in idx_no_en[:5]:\n",
        "            print(f\" ‚Ä¢ √çndice {i}: [{df.at[i,'idioma']}] {df.at[i,col_texto][:100]}...\")\n",
        "    else:\n",
        "        print(\"Todos los textos est√°n detectados como ingl√©s.\")\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "_WQ5tiJps-bO"
      },
      "id": "_WQ5tiJps-bO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nota: En algunas ocasiones, la funci√≥n `detect` confunde la presencia de nombres propios o peque√±as secciones en otros idiomas como un indicativo de que el texto no est√° en ingl√©s. Sin embargo, estas ocurrencias suelen ser m√≠nimas o nulas."
      ],
      "metadata": {
        "id": "bAyfWDggeQW-"
      },
      "id": "bAyfWDggeQW-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Detectando otros idiomas:"
      ],
      "metadata": {
        "id": "znjAi7TSPK3f"
      },
      "id": "znjAi7TSPK3f"
    },
    {
      "cell_type": "code",
      "source": [
        "df = detectar_idiomas(df, col_texto='text')"
      ],
      "metadata": {
        "id": "DpTn9HpSW6V9"
      },
      "id": "DpTn9HpSW6V9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "_ypyorGqwmRl",
      "metadata": {
        "id": "_ypyorGqwmRl"
      },
      "source": [
        "***\n",
        "\n",
        "# 3. Definici√≥n de *pipelines* de procesamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4370a607-ad43-4c5d-bddd-1a9370469409",
      "metadata": {
        "id": "4370a607-ad43-4c5d-bddd-1a9370469409"
      },
      "source": [
        "***\n",
        "\n",
        "## 3.1. *Pipeline* de preprocesamiento\n",
        "\n",
        "...."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Limpieza b√°sica\n",
        "def clean_text(text: str) -> str:\n",
        "    text = re.sub(r\"\\s+\", \" \", text)            #¬†colapsar whitespace\n",
        "    text = re.sub(r\"[^\\w.,;:!?()¬ø¬° ]+\", \"\", text)\n",
        "    return text.strip()\n",
        "\n",
        "for col in (\"text\", \"text_rank_summary\", \"lsa_summary\"):\n",
        "    if col in df.columns:\n",
        "        df[col] = df[col].astype(str).apply(clean_text)\n"
      ],
      "metadata": {
        "id": "tK_D4XVsnk6c"
      },
      "id": "tK_D4XVsnk6c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4.b. Nube de palabras para art√≠culos en ingl√©s ---\n",
        "# Unimos todos los textos limpios de la columna 'text' detectados como ingl√©s\n",
        "textos_en = ' '.join(df[df['idioma'] == 'en']['text'].tolist())\n",
        "\n",
        "# Creamos la nube de palabras\n",
        "wc = WordCloud(\n",
        "    width=800,\n",
        "    height=400,\n",
        "    background_color='white',\n",
        "    max_words=200,\n",
        "    collocations=False  # evita duplicados de bigramas\n",
        ").generate(textos_en)\n",
        "\n",
        "# Mostramos la figura\n",
        "plt.figure(figsize=(15, 7))\n",
        "plt.imshow(wc, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.title('Nube de palabras - Textos en ingl√©s')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "sBwcvN1xtktk"
      },
      "id": "sBwcvN1xtktk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, test_df = train_test_split(\n",
        "    df, test_size=0.10, stratify=df[\"label_id\"], random_state=RANDOM_SEED\n",
        ")\n",
        "train_df, val_df = train_test_split(\n",
        "    train_df, test_size=0.10, stratify=train_df[\"label_id\"], random_state=RANDOM_SEED\n",
        ")\n",
        "print(\"Tama√±os ‚Äì¬†Train / Val / Test:\", len(train_df), len(val_df), len(test_df))"
      ],
      "metadata": {
        "id": "L6QJGsVGvoIK"
      },
      "id": "L6QJGsVGvoIK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[2]"
      ],
      "metadata": {
        "id": "TFInYXoOXHTh"
      },
      "id": "TFInYXoOXHTh"
    },
    {
      "cell_type": "markdown",
      "id": "G6-RrjwuxYEw",
      "metadata": {
        "id": "G6-RrjwuxYEw"
      },
      "source": [
        "***\n",
        "\n",
        "# 4. Desarrollo del modelo RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "## 4.1. Hiperpar√°metros, partici√≥n y *DataLoaders*\n",
        "\n",
        "..."
      ],
      "metadata": {
        "id": "wqy-xlwJ2zMS"
      },
      "id": "wqy-xlwJ2zMS"
    },
    {
      "cell_type": "code",
      "source": [
        "class BBCDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer, max_len):\n",
        "        self.texts   = df[\"text\"].tolist()\n",
        "        self.labels  = df[\"label_id\"].tolist()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len  = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        enc = self.tokenizer(\n",
        "            self.texts[idx],\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=self.max_len,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        # Squeeze para quitar la dimensi√≥n batch ficticia\n",
        "        item = {k: v.squeeze() for k, v in enc.items()}\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        return item"
      ],
      "metadata": {
        "id": "zfp-stYtEt71"
      },
      "id": "zfp-stYtEt71",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_dataloaders(splits: dict, tokenizer, max_len: int, batch_size: int, num_workers: int = 2):\n",
        "    \"\"\"Crea DataLoaders, uno por split, sin dejar referencias globales.\"\"\"\n",
        "    return {\n",
        "        split: DataLoader(\n",
        "            BBCDataset(df_split, tokenizer, max_len),\n",
        "            batch_size=batch_size,\n",
        "            shuffle=(split == \"train\"),\n",
        "            num_workers=num_workers,\n",
        "            pin_memory=True,\n",
        "        )\n",
        "        for split, df_split in splits.items()\n",
        "    }"
      ],
      "metadata": {
        "id": "Mmw_2vXRQMlr"
      },
      "id": "Mmw_2vXRQMlr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------\n",
        "# 4. Funci√≥n train_and_evaluate  >>> MODIFIED <<<\n",
        "# -----------------------------------------------------\n",
        "\n",
        "def train_and_evaluate(\n",
        "    ckpt: str,\n",
        "    name: str,\n",
        "    splits: dict,\n",
        "    target_names: list,\n",
        "    device: torch.device,\n",
        "    *,\n",
        "    epochs: int = EPOCHS,\n",
        "    lr: float = LR,\n",
        "    batch_size: int = BATCH_SIZE,\n",
        "    max_len: int = MAX_LEN,\n",
        "):\n",
        "    \"\"\"Entrena y eval√∫a un modelo, liberando memoria al terminar.\"\"\"\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(ckpt, use_fast=True)\n",
        "    loaders   = build_dataloaders(splits, tokenizer, max_len, batch_size)\n",
        "\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        ckpt, num_labels=len(target_names)\n",
        "    ).to(device)\n",
        "\n",
        "    opt   = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "    tot_steps = len(loaders[\"train\"]) * epochs\n",
        "    sched = get_linear_schedule_with_warmup(opt, int(0.1 * tot_steps), tot_steps)\n",
        "\n",
        "    history = {k: [] for k in (\"train_loss\", \"val_loss\", \"train_acc\", \"val_acc\")}\n",
        "\n",
        "    for ep in range(1, epochs + 1):\n",
        "        for phase in (\"train\", \"val\"):\n",
        "            is_train = phase == \"train\"\n",
        "            model.train() if is_train else model.eval()\n",
        "\n",
        "            losses, preds, trues = [], [], []\n",
        "            for batch in loaders[phase]:\n",
        "                batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "                with torch.set_grad_enabled(is_train):\n",
        "                    out  = model(**batch)\n",
        "                    loss = out.loss\n",
        "                    logits = out.logits\n",
        "\n",
        "                if is_train:  # backward only in training\n",
        "                    loss.backward()\n",
        "                    nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "                    opt.step(); sched.step(); opt.zero_grad()\n",
        "\n",
        "                losses.append(loss.item())\n",
        "                preds.extend(logits.argmax(1).cpu().numpy())\n",
        "                trues.extend(batch[\"label_id\"].cpu().numpy())\n",
        "\n",
        "            acc = accuracy_score(trues, preds)\n",
        "            if is_train:\n",
        "                history[\"train_loss\"].append(np.mean(losses))\n",
        "                history[\"train_acc\"].append(acc)\n",
        "            else:\n",
        "                history[\"val_loss\"].append(np.mean(losses))\n",
        "                history[\"val_acc\"].append(acc)\n",
        "            print(f\"Epoch {ep} {phase.capitalize()} ‚Äì Loss: {np.mean(losses):.4f}, Acc: {acc:.3f}\")\n",
        "\n",
        "    # ---------- Test split ----------\n",
        "    model.eval(); test_preds, test_trues = [], []\n",
        "    for batch in loaders[\"test\"]:\n",
        "        b = {k: v.to(device) for k, v in batch.items()}\n",
        "        logits = model(**b).logits\n",
        "        test_preds.extend(logits.argmax(1).cpu().numpy())\n",
        "        test_trues.extend(b[\"label_id\"].cpu().numpy())\n",
        "\n",
        "    report = classification_report(test_trues, test_preds, labels=range(len(le.classes_)), target_names=le.classes_, digits=3)\n",
        "\n",
        "    # Liberar memoria expl√≠citamente  >>> MODIFIED <<<\n",
        "    del model, loaders\n",
        "    torch.cuda.empty_cache(); gc.collect()\n",
        "\n",
        "    return history, report"
      ],
      "metadata": {
        "id": "yod5PSrpEXcq"
      },
      "id": "yod5PSrpEXcq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "...."
      ],
      "metadata": {
        "id": "iYYOH084USqx"
      },
      "id": "iYYOH084USqx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "## 4.3. Entrenamiento, validaci√≥n y prueba\n",
        "\n",
        " **`gradient clipping`** m"
      ],
      "metadata": {
        "id": "oz4ZPXG44a8W"
      },
      "id": "oz4ZPXG44a8W"
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_history(hist):\n",
        "    epochs = list(range(1,len(hist['train_loss'])+1))\n",
        "    plt.figure(figsize=(8,4))\n",
        "    plt.plot(epochs,hist['train_loss'],label='Train Loss')\n",
        "    plt.plot(epochs,hist['val_loss'],label='Val Loss')\n",
        "    plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Loss vs Epoch'); plt.legend(); plt.show()\n",
        "\n",
        "    plt.figure(figsize=(8,4))\n",
        "    plt.plot(epochs,hist['train_acc'],label='Train Acc')\n",
        "    plt.plot(epochs,hist['val_acc'],label='Val Acc')\n",
        "    plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Accuracy vs Epoch'); plt.legend(); plt.show()\n"
      ],
      "metadata": {
        "id": "-cJ5T70bXb2c"
      },
      "id": "-cJ5T70bXb2c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[3]"
      ],
      "metadata": {
        "id": "Pfn0fl1zaEVT"
      },
      "id": "Pfn0fl1zaEVT"
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================\n",
        "# 8. Loop sobre cada modelo y recolecci√≥n de m√©tricas\n",
        "# ===============================================================\n",
        "\n",
        "target_names = le.classes_.tolist()\n",
        "splits = {\"train\": train_df, \"val\": val_df, \"test\": test_df}\n",
        "\n",
        "results = {}\n",
        "for ckpt, name in MODEL_NAMES:\n",
        "    print(f\"\\n### Modelo: {name} ###\")\n",
        "    hist, rep = train_and_evaluate(\n",
        "        ckpt, name, splits, target_names, DEVICE,\n",
        "        epochs=EPOCHS, lr=LR, batch_size=BATCH_SIZE, max_len=MAX_LEN\n",
        "    )\n",
        "    plot_history(hist)\n",
        "    print(f\"\\n--- Test Report for {name} ---\\n\", rep)\n",
        "    results[name] = {\"history\": hist, \"report\": rep}"
      ],
      "metadata": {
        "id": "DVO5O3T1Kh4O"
      },
      "id": "DVO5O3T1Kh4O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "..."
      ],
      "metadata": {
        "id": "75G3J6o5ieVc"
      },
      "id": "75G3J6o5ieVc"
    },
    {
      "cell_type": "markdown",
      "id": "7JgtiyyfIyMM",
      "metadata": {
        "id": "7JgtiyyfIyMM"
      },
      "source": [
        "***\n",
        "\n",
        "\n",
        "# 5. An√°lisis de resultados y discusi√≥n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "..."
      ],
      "metadata": {
        "id": "Ty3gzWEui8xK"
      },
      "id": "Ty3gzWEui8xK"
    },
    {
      "cell_type": "markdown",
      "source": [
        "..."
      ],
      "metadata": {
        "id": "qJZ_NDzdjQ7G"
      },
      "id": "qJZ_NDzdjQ7G"
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================\n",
        "# 9. Resumen comparativo final\n",
        "# ===============================================================\n",
        "print(\"\\n# Resumen comparativo final #\")\n",
        "for name, res in results.items():\n",
        "    print(f\"\\nModel: {name}\\n\", res[\"report\"])"
      ],
      "metadata": {
        "id": "tbtQicsqWwTa"
      },
      "id": "tbtQicsqWwTa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mariz de confusi√≥n de ambos modelos"
      ],
      "metadata": {
        "id": "uaauR7IpagRo"
      },
      "id": "uaauR7IpagRo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
        "# 10. t-SNE 3D de los embeddings de entrada\n",
        "# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
        "\n",
        "N = 500  # n√∫mero de tokens a mostrar por vocabulario\n",
        "\n",
        "# 1) Obtener los N primeros tokens de cada tokenizer\n",
        "tokens_bert    = list(tokenizer_bert.get_vocab().keys())[:N]\n",
        "tokens_roberta = list(tokenizer_roberta.get_vocab().keys())[:N]\n",
        "\n",
        "# 2) Extraer sus vectores de embedding\n",
        "#    get_input_embeddings().weight es [vocab_size x hidden_size]\n",
        "emb_bert    = model_bert.get_input_embeddings().weight.detach().cpu().numpy()\n",
        "emb_roberta = model_roberta.get_input_embeddings().weight.detach().cpu().numpy()\n",
        "\n",
        "# 3) Indexar s√≥lo los tokens seleccionados\n",
        "ids_bert    = [tokenizer_bert.convert_tokens_to_ids(t) for t in tokens_bert]\n",
        "ids_roberta = [tokenizer_roberta.convert_tokens_to_ids(t) for t in tokens_roberta]\n",
        "\n",
        "vecs_bert    = emb_bert[ids_bert, :]\n",
        "vecs_roberta = emb_roberta[ids_roberta, :]\n",
        "\n",
        "# 4) Concatenar y normalizar\n",
        "V = np.vstack([vecs_bert, vecs_roberta])\n",
        "V = StandardScaler().fit_transform(V)\n",
        "\n",
        "# 5) Reducir dimensionalidad con PCA a 50 componentes\n",
        "pca    = PCA(n_components=50, random_state=RANDOM_SEED)\n",
        "V_pca  = pca.fit_transform(V)\n",
        "\n",
        "# 6) t-SNE en 3D\n",
        "tsne   = TSNE(\n",
        "    n_components=3,\n",
        "    perplexity=40,\n",
        "    init='pca',\n",
        "    random_state=RANDOM_SEED,\n",
        "    learning_rate='auto'\n",
        ")\n",
        "X_tsne = tsne.fit_transform(V_pca)\n",
        "\n",
        "# 7) Preparar DataFrame para Plotly\n",
        "df_vis = pd.DataFrame({\n",
        "    'x':       X_tsne[:, 0],\n",
        "    'y':       X_tsne[:, 1],\n",
        "    'z':       X_tsne[:, 2],\n",
        "    'token':   tokens_bert + tokens_roberta,\n",
        "    'modelo':  ['BERT'] * N + ['RoBERTa'] * N\n",
        "})\n",
        "\n",
        "# 8) Gr√°fico interactivo 3D\n",
        "fig = px.scatter_3d(\n",
        "    df_vis,\n",
        "    x='x', y='y', z='z',\n",
        "    color='modelo',\n",
        "    hover_name='token',\n",
        "    title='t-SNE 3D ‚Äî Embeddings de entrada de BERT vs. RoBERTa'\n",
        ")\n",
        "fig.update_traces(marker=dict(size=3))\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "1jB6JKlLVoQG"
      },
      "id": "1jB6JKlLVoQG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "\n",
        "# 6. Conclusi√≥n\n",
        "\n",
        "....."
      ],
      "metadata": {
        "id": "uDjo26cIk10k"
      },
      "id": "uDjo26cIk10k"
    },
    {
      "cell_type": "markdown",
      "id": "DwUWQIAE3O0o",
      "metadata": {
        "id": "DwUWQIAE3O0o"
      },
      "source": [
        "***\n",
        "\n",
        "\n",
        "# 7. Referencias"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BoLDjBS03xiQ",
      "metadata": {
        "id": "BoLDjBS03xiQ"
      },
      "source": [
        "[1] **BERT: Pre-training of Deep Bidirectional Transformers for\n",
        "Language Understanding  Google AI Language**  \n",
        "Disponible en: [arxiv.org](https://arxiv.org/abs/1810.04805)\n",
        "\n",
        "\n",
        "[2] **Documents Classification using BERT on BBC Dataset**  \n",
        "Disponible en: [kaggle.com](https://www.kaggle.com/code/ouardasakram/documents-classification-using-bert-on-bbc-dataset)\n",
        "\n",
        "\n",
        "[3] **Bert-Classification-BBC-News**  \n",
        "Disponible en: [github.com](https://github.com/bymi15/Bert-Classification-BBC-News/blob/main/bert_classification_bbc_news.ipynb)\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}