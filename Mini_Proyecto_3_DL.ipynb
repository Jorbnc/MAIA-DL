{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jorbnc/MAIA-DL/blob/master/Mini_Proyecto_3_DL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oa_MJEGQ6jTi",
      "metadata": {
        "id": "oa_MJEGQ6jTi"
      },
      "source": [
        "![Universidad_de_los_Andes_30.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sl89pic17iPU",
      "metadata": {
        "id": "sl89pic17iPU"
      },
      "source": [
        "<style>\n",
        "@import url('https://fonts.googleapis.com/css2?family=Latin+Modern+Roman:wght@400;700&display=swap');\n",
        "\n",
        "body, p, h1, h2, h3, h4, h5, h6, li {\n",
        "  font-family: 'Latin Modern Roman', serif;\n",
        "}\n",
        "code, pre {\n",
        "  font-family: 'Fira Mono', monospace;\n",
        "}\n",
        "</style>\n",
        "\n",
        "***\n",
        "\n",
        "# **Miniproyecto 3, T√©cnicas de *Deep Learning*: ...**\n",
        "\n",
        "## **Descripci√≥n del problema:**\n",
        "\n",
        "...\n",
        "\n",
        "## **Objetivo:**\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SiCS5j-HAbCB",
      "metadata": {
        "id": "SiCS5j-HAbCB"
      },
      "source": [
        "***\n",
        "\n",
        "**Este proyecto es realizado por Andr√©s Felipe √ëungo y Jordan Bryan N√∫√±ez Campos para entrega el 13 de mayo de 2025.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8VqTMx7TYgjH",
      "metadata": {
        "id": "8VqTMx7TYgjH"
      },
      "source": [
        "\n",
        "***\n",
        "# **√çndice**\n",
        "\n",
        "El *notebook* aborda el proyecto con la siguiente estructura:\n",
        "\n",
        "| üîπ | Secci√≥n        |\n",
        "|----|----------------|\n",
        "| 1Ô∏è‚É£. | **Instalaci√≥n y carga de librer√≠as** |\n",
        "| 1Ô∏è‚É£.1Ô∏è‚É£. | **Word2Vec** |\n",
        "| 1Ô∏è‚É£.2Ô∏è‚É£. | **GloVe** |\n",
        "| 1Ô∏è‚É£.3Ô∏è‚É£. | **Configuraciones adicionales** |\n",
        "| 2Ô∏è‚É£. | **An√°lisis exploratorio y preparaci√≥n de los datos**       |\n",
        "| 2Ô∏è‚É£.1Ô∏è‚É£. | **Carga y estad√≠sticas generales**       |\n",
        "| 2Ô∏è‚É£.2Ô∏è‚É£. | **Limpieza de los datos**       |\n",
        "| 3Ô∏è‚É£. | **Definici√≥n de *pipelines* de procesamiento**          |\n",
        "| 3Ô∏è‚É£.1Ô∏è‚É£. | **Pipeline de preprocesamiento**   |\n",
        "| 4Ô∏è‚É£. | **Desarrollo del modelo RNN**   |\n",
        "| 4Ô∏è‚É£.1Ô∏è‚É£. | **Hiperpar√°metros, Partici√≥n y DataLoaders**   |\n",
        "| 4Ô∏è‚É£.2Ô∏è‚É£. | **Definici√≥n del modelo**   |\n",
        "| 4Ô∏è‚É£.3Ô∏è‚É£. | **Entrenamiento, validaci√≥n y prueba**   |\n",
        "| 5Ô∏è‚É£. | **An√°lisis de resultados y discusi√≥n**   |\n",
        "| 5Ô∏è‚É£.1Ô∏è‚É£. | **Pruebas individuales del modelo**   |\n",
        "| 6Ô∏è‚É£. | **Conclusi√≥n**   |\n",
        "| 7Ô∏è‚É£. | **Referencias**   |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cyVuwlHB_W3",
      "metadata": {
        "id": "2cyVuwlHB_W3"
      },
      "source": [
        "***\n",
        "\n",
        "# 1. Instalaci√≥n y carga de librer√≠as"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "...."
      ],
      "metadata": {
        "id": "DkjBiBB5rU6t"
      },
      "id": "DkjBiBB5rU6t"
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations"
      ],
      "metadata": {
        "id": "NWJ88VFyzBPK"
      },
      "id": "NWJ88VFyzBPK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalaci√≥n de librer√≠as necesarias para correr en Colab/Coursera\n",
        "!pip -q install kagglehub langdetect matplotlib scikit-learn plotly"
      ],
      "metadata": {
        "id": "l26426jMLCxE",
        "outputId": "e124a8aa-bb6e-42d2-9be4-bcf5f3c246e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "l26426jMLCxE",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/981.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m215.0/981.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m972.8/981.5 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Librer√≠as comunes\n",
        "import os, random, gc, time\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "\n",
        "# Descarga de datasets y de embeddings\n",
        "import kagglehub\n",
        "\n",
        "# Limipieza y preparaci√≥n de los txtos\n",
        "from langdetect import detect, DetectorFactory\n",
        "import re\n",
        "\n",
        "# Preprocesamiento y herramientas de PLN\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from transformers import (get_linear_schedule_with_warmup,\n",
        "                          AutoTokenizer, AutoModelForSequenceClassification,)\n",
        "\n",
        "# Modelado\n",
        "\n",
        "from typing import List, Dict, Any\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from transformers import PreTrainedTokenizerBase\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "# Evaluaci√≥n\n",
        "from sklearn.metrics import (accuracy_score, f1_score,\n",
        "                              precision_score,\n",
        "                              recall_score,\n",
        "                              classification_report)\n",
        "\n",
        "# Librer√≠as para visualizaciones\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
      ],
      "metadata": {
        "id": "osjmTJMvtxua"
      },
      "id": "osjmTJMvtxua",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uses ‚Äúbert-base-uncased‚Äù version of BERT, which is pre-trained on lower-cased English text\n",
        "\n",
        "(with 12-layer, 768-hidden, 12-heads, 110M parameters)\n",
        "\n",
        "For the purposes of fine-tuning, the authors recommend choosing from the following values (from Appendix A.3 of the BERT paper: https://arxiv.org/pdf/1810.04805.pdf):\n",
        "\n",
        "*   **Batch size:** 16, 32\n",
        "*   **Learning rate (Adam):** 5e-5, 3e-5, 2e-5\n",
        "*   **Number of epochs:** 2, 3, 4\n",
        "\n",
        "[1]"
      ],
      "metadata": {
        "id": "OeOXzQpOa-Lz"
      },
      "id": "OeOXzQpOa-Lz"
    },
    {
      "cell_type": "code",
      "source": [
        "#Par√°metros globales de los modelos\n",
        "TEXT_COL   = \"text\"\n",
        "LABEL_COL  = \"labels\"                    # columna con la categor√≠a en texto\n",
        "MAX_LEN    = 256\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS     = 5\n",
        "PATIENCE   = 2\n",
        "UNFREEZE_PER_EPOCH = 2                 # capas a liberar por √©poca\n",
        "SEED = 13"
      ],
      "metadata": {
        "id": "afgVSw4d1AIw"
      },
      "id": "afgVSw4d1AIw",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se descarga el conjunto de datos de rese√±as de noticias de la BBC de **`kagglehub`**. La funci√≥n **`dataset_download`** guarda los archivos de manera local y devuelve la ruta absoluta, que se almacena en **`path`** y se muestra en pantalla mediante **`print`** para confirmar d√≥nde quedaron los datos."
      ],
      "metadata": {
        "id": "yHwealvATakn"
      },
      "id": "yHwealvATakn"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3. Configuraciones adicionales\n",
        "\n",
        "Con el siguiente bloque se detecta si el entorno dispone de GPU y selecciona el **`device`** apropiado para PyTorch.  \n",
        "\n",
        "Primero se llama a **`is_available()`**, que devuelve *True* si se ha asignado una GPU CUDA al *runtime* de Colab. Seg√∫n el resultado se imprime un mensaje informativo. Posteriormente, se construye el objeto **`device`**, que ser√° pasado a la red y a los tensores de entrada para que se ubiquen en la GPU cuando sea posible. Por √∫ltimo se muestra en pantalla el dispositivo elegido."
      ],
      "metadata": {
        "id": "uOceAejmVjqF"
      },
      "id": "uOceAejmVjqF"
    },
    {
      "cell_type": "code",
      "source": [
        "# Devuelve asignaci√≥n de GPU\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Dispositivo activo ‚Üí {DEVICE}\")"
      ],
      "metadata": {
        "id": "LksJ95qEPWVr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12f44eb2-5091-4a70-be52-f436a1d6cc31"
      },
      "id": "LksJ95qEPWVr",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dispositivo activo ‚Üí cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adicionalmente se ocultan avisos para mantener limpias algunas salidas del notebook; y se imprimen las versiones de un conjunto de librer√≠as clave ( **`numpy`**, **`pandas`**, **`torch`**, **`scikit-learn`**, **`kagglehub`**, **`matplotlib`**). Mostrar estas versiones al inicio del notebook facilita la reproducibilidad y ayuda a depurar posibles conflictos de dependencias."
      ],
      "metadata": {
        "id": "pfXxKk09Vulp"
      },
      "id": "pfXxKk09Vulp"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "LSwlUgjUjtR_",
      "metadata": {
        "id": "LSwlUgjUjtR_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb2e8713-4e10-4e43-dd73-018de23a1ba3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numpy :  2.0.2\n",
            "pandas :  2.2.2\n",
            "torch :  2.6.0+cu124\n",
            "scikit-learn :  1.6.1\n",
            "kagglehub :  0.3.12\n",
            "matplotlib :  3.10.0\n"
          ]
        }
      ],
      "source": [
        "# Ignorar las warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Versiones utilizadas\n",
        "from importlib.metadata import version\n",
        "librerias = [\"numpy\", \"pandas\", \"torch\", \"scikit-learn\", \"kagglehub\",\"matplotlib\"]\n",
        "for library in librerias:\n",
        "  print(library, \": \", version(library))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalmente, para cerrar esta secci√≥n se configuran algunas semillas para tener cierto grado de control en la aleatoriedad."
      ],
      "metadata": {
        "id": "ok4F_5E1njTi"
      },
      "id": "ok4F_5E1njTi"
    },
    {
      "cell_type": "code",
      "source": [
        "# Definici√≥n del random state y seeds\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark     = False"
      ],
      "metadata": {
        "id": "xdgcOt7gznvJ"
      },
      "id": "xdgcOt7gznvJ",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "qK311OLFzPep",
      "metadata": {
        "id": "qK311OLFzPep"
      },
      "source": [
        "***\n",
        "\n",
        "# 2. An√°lisis exploratorio y preparaci√≥n de los datos\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "## 2.1. Carga y estad√≠sticas generales"
      ],
      "metadata": {
        "id": "4KxKy7H1eID-"
      },
      "id": "4KxKy7H1eID-"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "K4yOzyWKJbov",
      "metadata": {
        "id": "K4yOzyWKJbov",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdd31bea-9349-4a1a-9e27-bc4a6bf99a5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datos descargados en: /kaggle/input/bbc-articles-dataset\n",
            "Dataset descargado en: /kaggle/input/bbc-articles-dataset/bbc_news_text_complexity_summarization.csv\n",
            "Filas totales: 2127\n"
          ]
        }
      ],
      "source": [
        "# Leer el conjunto de datos y cargarlo a un dataframe\n",
        "\n",
        "# Descarga del conjunto de datos\n",
        "path = kagglehub.dataset_download(\"jacopoferretti/bbc-articles-dataset\")\n",
        "print(\"Datos descargados en:\", path)\n",
        "\n",
        "CSV_PATH = os.path.join(path, \"bbc_news_text_complexity_summarization.csv\")\n",
        "print(f\"Dataset descargado en: {CSV_PATH}\")\n",
        "\n",
        "data_raw = pd.read_csv(CSV_PATH)\n",
        "print(\"Filas totales:\", len(data_raw))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CNfurSnbmf79",
      "metadata": {
        "id": "CNfurSnbmf79"
      },
      "source": [
        "***\n",
        "\n",
        "## 2.2. Limpieza de los datos\n",
        "\n",
        "En estas secci√≥n identificamos y corregimos:\n",
        "\n",
        "* Valores faltantes\n",
        "* Textos duplicados\n",
        "* Textos en otros idiomas distintos al ingl√©s"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_raw.isna().sum()"
      ],
      "metadata": {
        "id": "2r0P2t_Ysjbq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "outputId": "cbba7a17-873f-4794-a538-2b93fb269198"
      },
      "id": "2r0P2t_Ysjbq",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text                            0\n",
              "labels                          0\n",
              "no_sentences                    0\n",
              "Flesch Reading Ease Score       0\n",
              "Dale-Chall Readability Score    0\n",
              "text_rank_summary               0\n",
              "lsa_summary                     0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>text</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>labels</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>no_sentences</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Flesch Reading Ease Score</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dale-Chall Readability Score</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>text_rank_summary</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lsa_summary</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_raw.duplicated().sum()"
      ],
      "metadata": {
        "id": "m3IgmRbWskuE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f5b76e8-2c76-4ff6-cf51-d31c72bfc686"
      },
      "id": "m3IgmRbWskuE",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int64(0)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = data_raw.copy()"
      ],
      "metadata": {
        "id": "fJETbmzSRX7o"
      },
      "id": "fJETbmzSRX7o",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.1. Carga y estad√≠sticas  ‚ûú  justo despu√©s de copiar el DataFrame\n",
        "\n",
        "le = LabelEncoder()\n",
        "df[\"label_id\"] = le.fit_transform(df[LABEL_COL])\n",
        "\n",
        "NUM_LABELS = len(le.classes_)      # üëà  siempre un entero\n",
        "\n",
        "id2label = {i: lbl for i, lbl in enumerate(le.classes_)}\n",
        "label2id = {v: k for k, v in id2label.items()}"
      ],
      "metadata": {
        "id": "XU6qAVkrjUo3"
      },
      "id": "XU6qAVkrjUo3",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gr√°fica para mostrar distribuci√≥n de las clases"
      ],
      "metadata": {
        "id": "1TQpLnbwan5r"
      },
      "id": "1TQpLnbwan5r",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detectar_idiomas(df: pd.DataFrame,\n",
        "                     col_texto: str = 'text') -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Detecta el idioma de cada fila en la columna **col_texto**,\n",
        "    a√±ade la columna **idioma** y muestra ejemplos no ingleses.\n",
        "    \"\"\"\n",
        "    # Inicializamos con 'desconocido'\n",
        "    df['idioma'] = 'desconocido'\n",
        "\n",
        "    # Funci√≥n auxiliar segura\n",
        "    def _detectar(texto):\n",
        "        if isinstance(texto, str) and texto.strip():\n",
        "            try:\n",
        "                return detect(texto)\n",
        "            except Exception:\n",
        "                return 'desconocido'\n",
        "        return 'desconocido'\n",
        "\n",
        "    # Aplicamos detecci√≥n\n",
        "    df['idioma'] = df[col_texto].apply(_detectar)\n",
        "\n",
        "    # Filtramos los que no son ingl√©s\n",
        "    mask = df['idioma'] != 'en'\n",
        "    idx_no_en = df[mask].index\n",
        "\n",
        "    if len(idx_no_en) > 0:\n",
        "        print(f\"Se encontraron {len(idx_no_en)} textos NO en ingl√©s (ejemplos):\")\n",
        "        # Mostramos hasta 5 ejemplos\n",
        "        for i in idx_no_en[:5]:\n",
        "            print(f\" ‚Ä¢ √çndice {i}: [{df.at[i,'idioma']}] {df.at[i,col_texto][:100]}...\")\n",
        "    else:\n",
        "        print(\"Todos los textos est√°n detectados como ingl√©s.\")\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "_WQ5tiJps-bO"
      },
      "id": "_WQ5tiJps-bO",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nota: En algunas ocasiones, la funci√≥n `detect` confunde la presencia de nombres propios o peque√±as secciones en otros idiomas como un indicativo de que el texto no est√° en ingl√©s. Sin embargo, estas ocurrencias suelen ser m√≠nimas o nulas."
      ],
      "metadata": {
        "id": "bAyfWDggeQW-"
      },
      "id": "bAyfWDggeQW-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Detectando otros idiomas:"
      ],
      "metadata": {
        "id": "znjAi7TSPK3f"
      },
      "id": "znjAi7TSPK3f"
    },
    {
      "cell_type": "code",
      "source": [
        "df = detectar_idiomas(df, col_texto='text')"
      ],
      "metadata": {
        "id": "DpTn9HpSW6V9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "986ab451-9490-4f2b-a0ad-1b8c9a19f25a"
      },
      "id": "DpTn9HpSW6V9",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Todos los textos est√°n detectados como ingl√©s.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_ypyorGqwmRl",
      "metadata": {
        "id": "_ypyorGqwmRl"
      },
      "source": [
        "***\n",
        "\n",
        "# 3. Definici√≥n de *pipelines* de procesamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4370a607-ad43-4c5d-bddd-1a9370469409",
      "metadata": {
        "id": "4370a607-ad43-4c5d-bddd-1a9370469409"
      },
      "source": [
        "***\n",
        "\n",
        "## 3.1. *Pipeline* de preprocesamiento\n",
        "\n",
        "...."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Limpieza b√°sica\n",
        "def clean_text(text: str) -> str:\n",
        "    text = re.sub(r\"\\s+\", \" \", text)            #¬†colapsar whitespace\n",
        "    text = re.sub(r\"[^\\w.,;:!?()¬ø¬° ]+\", \"\", text)\n",
        "    return text.strip()\n",
        "\n",
        "for col in (\"text\", \"text_rank_summary\", \"lsa_summary\"):\n",
        "    if col in df.columns:\n",
        "        df[col] = df[col].astype(str).apply(clean_text)\n"
      ],
      "metadata": {
        "id": "tK_D4XVsnk6c"
      },
      "id": "tK_D4XVsnk6c",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, test_df = train_test_split(\n",
        "    df, test_size=0.10, stratify=df[\"label_id\"], random_state=SEED\n",
        ")\n",
        "train_df, val_df = train_test_split(\n",
        "    train_df, test_size=0.10, stratify=train_df[\"label_id\"], random_state=SEED\n",
        ")\n",
        "print(\"Tama√±os ‚Äì¬†Train / Val / Test:\", len(train_df), len(val_df), len(test_df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6QJGsVGvoIK",
        "outputId": "1eac6228-afa3-4ec7-8c36-6715919d72c7"
      },
      "id": "L6QJGsVGvoIK",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tama√±os ‚Äì¬†Train / Val / Test: 1722 192 213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[2]"
      ],
      "metadata": {
        "id": "TFInYXoOXHTh"
      },
      "id": "TFInYXoOXHTh"
    },
    {
      "cell_type": "markdown",
      "id": "G6-RrjwuxYEw",
      "metadata": {
        "id": "G6-RrjwuxYEw"
      },
      "source": [
        "***\n",
        "\n",
        "# 4. Desarrollo del modelo RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "## 4.1. Hiperpar√°metros, partici√≥n y *DataLoaders*\n",
        "\n",
        "AutoTokenizer\tCuando tu pipeline puede alternar entre arquitecturas (BERT, RoBERTa, DistilBERT‚Ä¶) o quieres mantener el c√≥digo gen√©rico.  \n",
        "+ Detecta internamente la clase correcta ( BertTokenizerFast, RobertaTokenizerFast ‚Ä¶).\n",
        "+ Un √∫nico import.\n",
        "+ Reduce ‚Äúif/else‚Äù en tu c√≥digo.\n",
        "‚àí Ligeramente m√°s sobrecarga al resolver la clase la primera vez (irrelevante en la pr√°ctica).\n",
        "\n",
        "¬øD√≥nde est√° la ‚Äúpreparaci√≥n de secuencias‚Äù en tu c√≥digo?\n",
        "El punto exacto aparece dentro del m√©todo __getitem__ de la clase BBCDataset (alrededor de la mitad del archivo mini_proyecto_3_dl.py). All√≠ se llama al tokenizer para convertir cada art√≠culo en la representaci√≥n num√©rica que entiende BERT/RoBERTa:\n",
        "\n",
        "Tokenizaci√≥n\n",
        "AutoTokenizer descompone el texto en sub-palabras seg√∫n el vocabulario del modelo (WordPiece para BERT, Byte-Pair para RoBERTa, etc.). Tambi√©n a√±ade los special tokens [CLS] y [SEP] que marcan inicio y fin de la secuencia.\n",
        "\n",
        "Conversi√≥n a IDs\n",
        "Cada token se mapea a un entero (input_ids) que luego se transformar√° en embeddings dentro del modelo.\n",
        "\n",
        "M√°scara de atenci√≥n\n",
        "Se crea attention_mask, un vector 1/0 que indica cu√°les posiciones son texto real y cu√°les son padding.\n",
        "\n",
        "Truncado y padding\n",
        "Con truncation=True y padding=\"max_length\" el texto se corta si supera MAX_LEN (256) y se rellena con ceros hasta ese mismo largo, garantizando que todos los ejemplos midan lo mismo y puedan apilarse en un batch.\n",
        "\n",
        "Empaquetado en tensores PyTorch\n",
        "return_tensors=\"pt\" devuelve cada parte como un tensor; luego squeeze(0) elimina la dimensi√≥n de tama√±o 1 a√±adida por el tokenizer para facilitar el batching posterior.\n",
        "\n",
        "En conjunto, este bloque es el ‚Äúpreparador de secuencias‚Äù: convierte texto crudo en el lote de tensores (input_ids, attention_mask, y opcionalmente token_type_ids) que el encoder transformer necesita para producir embeddings y, finalmente, la predicci√≥n de clase."
      ],
      "metadata": {
        "id": "wqy-xlwJ2zMS"
      },
      "id": "wqy-xlwJ2zMS"
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------\n",
        "#  BBCDataset   (misma l√≥gica, solo un par de detalles)\n",
        "# -----------------------------------------------------\n",
        "class BBCDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset para la clasificaci√≥n BBC.\n",
        "    ‚Ä¢ Mantiene tokenizaci√≥n con el tokenizer recibido (AutoTokenizer).\n",
        "    ‚Ä¢ Devuelve exactamente las mismas claves que antes:\n",
        "        input_ids / attention_mask / (token_type_ids) / labels\n",
        "    ‚Ä¢ Opci√≥n `return_idx` por si en alg√∫n an√°lisis necesitas\n",
        "      recuperar el √≠ndice original; por defecto NO cambia nada.\n",
        "    \"\"\"\n",
        "    def __init__(self, df, tokenizer, max_len, *, return_idx: bool = False):\n",
        "        self.texts  = df[TEXT_COL].tolist()\n",
        "        self.labels = df[\"label_id\"].tolist()\n",
        "        self.tok    = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.return_idx = return_idx\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        enc = self.tok(\n",
        "            self.texts[idx],\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=self.max_len,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        item = {k: v.squeeze(0) for k, v in enc.items()}\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        item[\"text\"] = self.texts[idx]\n",
        "        if self.return_idx:\n",
        "            item[\"idx\"] = torch.tensor(idx)   # ‚Üê opcional, no molesta al resto\n",
        "        return item"
      ],
      "metadata": {
        "id": "zfp-stYtEt71"
      },
      "id": "zfp-stYtEt71",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_with_text(batch):\n",
        "    texts  = [b.pop(\"text\") for b in batch]\n",
        "    keys   = batch[0].keys()          # input_ids, attention_mask, labels, ‚Ä¶\n",
        "    out    = {k: torch.stack([b[k] for b in batch]) for k in keys}\n",
        "    out[\"text\"] = texts               # vuelve a incluir texto\n",
        "    if \"idx\" in batch[0]:\n",
        "        out[\"idx\"] = torch.stack([b[\"idx\"] for b in batch])\n",
        "    return out"
      ],
      "metadata": {
        "id": "zPBwOr5LvZBH"
      },
      "id": "zPBwOr5LvZBH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_loader(df, tokenizer, split, batch_size, max_len,\n",
        "                *, return_idx=False, num_workers=2):\n",
        "    ds = BBCDataset(df, tokenizer, max_len, return_idx=return_idx)\n",
        "    return DataLoader(\n",
        "        ds, batch_size=batch_size, shuffle=(split==\"train\"),\n",
        "        num_workers=num_workers, pin_memory=True,\n",
        "        collate_fn=collate_with_text                     #  ‚Üê  nuevo\n",
        "    )"
      ],
      "metadata": {
        "id": "3bPJ2rdm_v46"
      },
      "id": "3bPJ2rdm_v46",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def freeze_layers(model,\n",
        "                  *,\n",
        "                  freeze: bool = True,\n",
        "                  last_n: int | None = None) -> None:\n",
        "    \"\"\"\n",
        "    Congela/descongela capas del encoder de un modelo *transformers*.\n",
        "\n",
        "    Par√°metros\n",
        "    ----------\n",
        "    model   : instancia de AutoModelForSequenceClassification\n",
        "    freeze  : si *True* congela; si *False* descongela.\n",
        "    last_n  :  ‚Ä¢ None  ‚ûú aplica a **todo** el encoder\n",
        "               ‚Ä¢ int   ‚ûú afecta solo a las *n* √∫ltimas capas\n",
        "\n",
        "    Ejemplos\n",
        "    --------\n",
        "    # 1) Congelar todo el encoder\n",
        "    freeze_layers(model)                       # freeze=True, last_n=None\n",
        "\n",
        "    # 2) Descongelar las 4 √∫ltimas capas\n",
        "    freeze_layers(model, freeze=False, last_n=4)\n",
        "\n",
        "    # 3) Congelar todo excepto las 2 √∫ltimas capas\n",
        "    freeze_layers(model, freeze=True,  last_n=2)\n",
        "    \"\"\"\n",
        "    # 1) Hay modelos (e.g., DistilBERT) donde el encoder vive en .transformer\n",
        "    encoder = getattr(model.base_model, \"encoder\", None) \\\n",
        "              or getattr(model.base_model, \"transformer\", None)\n",
        "\n",
        "    if encoder is None:            # fallback gen√©rico\n",
        "        for p in model.base_model.parameters():\n",
        "            p.requires_grad = not freeze if last_n is None else p.requires_grad\n",
        "        return\n",
        "\n",
        "    layers = list(encoder.layer)\n",
        "    if last_n is None:\n",
        "        # Congela o descongela todo el encoder\n",
        "        for p in encoder.parameters():\n",
        "            p.requires_grad = not freeze\n",
        "    else:\n",
        "        # Asegura que last_n no exceda el n√∫mero total de capas\n",
        "        last_n = max(0, min(last_n, len(layers)))\n",
        "\n",
        "        # 2) Definir subconjuntos\n",
        "        affected = layers[-last_n:]           # capas que cambian\n",
        "        unaffected = layers[:-last_n]         # capas que se mantienen\n",
        "\n",
        "        # 3) Aplicar flags\n",
        "        for layer in affected:\n",
        "            for p in layer.parameters():\n",
        "                p.requires_grad = not freeze if freeze else True\n",
        "\n",
        "        if freeze:                            # solo cuando queremos congelar\n",
        "            for layer in unaffected:\n",
        "                for p in layer.parameters():\n",
        "                    p.requires_grad = False"
      ],
      "metadata": {
        "id": "qudFCuoD0Gw_"
      },
      "id": "qudFCuoD0Gw_",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) predict_proba  ‚ûú  decorador\n",
        "@torch.no_grad()\n",
        "def predict_proba(model, batch, *, device):\n",
        "    \"\"\"\n",
        "    Devuelve las probabilidades (softmax) para un batch.\n",
        "    ‚ûú batch: dict con input_ids, attention_mask, (token_type_ids)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    inputs = {k: v.to(device) for k, v in batch.items()\n",
        "              if k not in [\"labels\", \"text\", \"idx\"]}\n",
        "    logits = model(**inputs).logits           # (B, num_labels)\n",
        "    probs  = F.softmax(logits, dim=-1)\n",
        "    return probs.cpu()"
      ],
      "metadata": {
        "id": "s6UVvASWngOQ"
      },
      "id": "s6UVvASWngOQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------\n",
        "# 4. Funci√≥n train_and_evaluate  >>> MODIFIED <<<\n",
        "# -----------------------------------------------------\n",
        "\n",
        "\n",
        "def train_and_evaluate(model_name: str, train_df, val_df, test_df):\n",
        "    print(f\"\\n========== Entrenando {model_name} ==========\")\n",
        "\n",
        "    start = time.time()\n",
        "    # Tokenizer + modelo\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        model_name,\n",
        "        num_labels=NUM_LABELS,\n",
        "        id2label=id2label,\n",
        "        label2id=label2id,\n",
        "    ).to(DEVICE)\n",
        "\n",
        "    # 5.1 Congelar encoder completo y luego liberar gradualmente\n",
        "    freeze_layers(model)\n",
        "\n",
        "    # 5.2 Pesos de clase balanceados\n",
        "    class_weights = compute_class_weight(\n",
        "        class_weight=\"balanced\", classes=np.arange(NUM_LABELS), y=train_df[\"label_id\"]\n",
        "    )\n",
        "    class_weights = torch.tensor(class_weights, dtype=torch.float32, device=DEVICE)\n",
        "\n",
        "    # 5.3 DataLoaders\n",
        "    loaders = {\n",
        "        \"train\": make_loader(train_df, tokenizer, \"train\", BATCH_SIZE, MAX_LEN),\n",
        "        \"val\":   make_loader(val_df,   tokenizer, \"val\",   BATCH_SIZE, MAX_LEN),\n",
        "        \"test\":  make_loader(test_df,  tokenizer, \"test\",  BATCH_SIZE, MAX_LEN),\n",
        "    }\n",
        "\n",
        "    # 5.4 Optimizador & scheduler\n",
        "    total_steps = len(loaders[\"train\"]) * EPOCHS\n",
        "    optimizer   = AdamW(model.parameters(), lr=2e-5, weight_decay=1e-2)\n",
        "    scheduler   = get_linear_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps=int(0.06 * total_steps),\n",
        "        num_training_steps=total_steps,\n",
        "    )\n",
        "\n",
        "    criterion   = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "    best_f1, patience_cnt = 0.0, 0\n",
        "    best_path = f\"best_{model_name.split('-')[0]}_bbc.pt\"\n",
        "\n",
        "    def epoch_pass(split):\n",
        "        is_train = split == \"train\"\n",
        "        model.train() if is_train else model.eval()\n",
        "        losses, preds_all, trues_all = [], [], []\n",
        "\n",
        "        for batch in loaders[split]:\n",
        "            batch = {k: (v.to(DEVICE) if torch.is_tensor(v) else v) for k,v in batch.items()}\n",
        "            with torch.set_grad_enabled(is_train):\n",
        "                inputs = {k: v for k, v in batch.items() if k not in [\"labels\", \"text\", \"idx\"]}\n",
        "                outputs = model(**inputs)\n",
        "                loss = criterion(outputs.logits, batch[\"labels\"])\n",
        "                if is_train:\n",
        "                    loss.backward()\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "                    optimizer.step(); scheduler.step(); optimizer.zero_grad()\n",
        "\n",
        "            losses.append(loss.item())\n",
        "            preds_all.extend(outputs.logits.argmax(dim=-1).cpu().numpy())\n",
        "            trues_all.extend(batch[\"labels\"].cpu().numpy())\n",
        "\n",
        "        acc = accuracy_score(trues_all, preds_all)\n",
        "        f1m = f1_score(trues_all, preds_all, average=\"macro\", zero_division=0)\n",
        "        f1¬µ = f1_score(trues_all, preds_all, average=\"micro\", zero_division=0)\n",
        "        return np.mean(losses), acc, f1m, f1¬µ\n",
        "\n",
        "    # 5.5 Entrenamiento\n",
        "    hist = {k: [] for k in [\"epoch\",\"train_loss\",\"val_loss\",\n",
        "                        \"train_acc\",\"val_acc\",\"train_f1\",\"val_f1\"]}\n",
        "    for epoch in range(1, EPOCHS + 1):\n",
        "        freeze_layers(model, freeze=False,last_n=epoch * UNFREEZE_PER_EPOCH)\n",
        "        train_loss, train_acc, train_f1m, train_f1¬µ = epoch_pass(\"train\")\n",
        "        val_loss,   val_acc,   val_f1m,   val_f1¬µ   = epoch_pass(\"val\")\n",
        "        hist[\"epoch\"].append(epoch)\n",
        "        hist[\"train_loss\"].append(train_loss); hist[\"val_loss\"].append(val_loss)\n",
        "        hist[\"train_acc\"].append(train_acc);   hist[\"val_acc\"].append(val_acc)\n",
        "        hist[\"train_f1\"].append(train_f1m);    hist[\"val_f1\"].append(val_f1m)\n",
        "\n",
        "        print(f\"Ep {epoch:02d}: \\tTL {train_loss:.4f} / VL {val_loss:.4f} | \"\n",
        "              f\"F1_macro {val_f1m:.3f}  Acc {val_acc:.3f}\")\n",
        "\n",
        "        if val_f1m > best_f1:\n",
        "            best_f1 = val_f1m\n",
        "            patience_cnt = 0\n",
        "            torch.save(model.state_dict(), best_path)\n",
        "        else:\n",
        "            patience_cnt += 1\n",
        "            if patience_cnt == PATIENCE:\n",
        "                print(\"Early stopping¬†‚ÜØ\\n\")\n",
        "                break\n",
        "\n",
        "    # 5.6 Evaluaci√≥n sobre *test*\n",
        "    model.load_state_dict(torch.load(best_path))\n",
        "    test_loss, test_acc, test_f1m, test_f1¬µ = epoch_pass(\"test\")\n",
        "\n",
        "    y_true, y_pred = [], []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in loaders[\"test\"]:\n",
        "            batch = {k: (v.to(DEVICE) if torch.is_tensor(v) else v) for k,v in batch.items()}\n",
        "            inputs = {k: v for k, v in batch.items() if k not in [\"labels\", \"text\", \"idx\"]}\n",
        "            outputs = model(**inputs)\n",
        "            y_true.extend(batch[\"labels\"].cpu().numpy())\n",
        "            y_pred.extend(outputs.logits.argmax(dim=-1).cpu().numpy())\n",
        "\n",
        "    # Precisi√≥n y recall (macro / micro)\n",
        "    prec_macro = precision_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
        "    prec_micro = precision_score(y_true, y_pred, average=\"micro\", zero_division=0)\n",
        "    rec_macro  = recall_score   (y_true, y_pred, average=\"macro\", zero_division=0)\n",
        "    rec_micro  = recall_score   (y_true, y_pred, average=\"micro\", zero_division=0)\n",
        "\n",
        "    report = classification_report(\n",
        "        y_true,\n",
        "        y_pred,\n",
        "        labels=list(range(NUM_LABELS)),\n",
        "        target_names=le.classes_.tolist(),\n",
        "        digits=3,\n",
        "        zero_division=0,\n",
        "    )\n",
        "\n",
        "    # 5.7 Limpieza expl√≠cita\n",
        "    test_loader_ref = loaders[\"test\"]\n",
        "    del loaders, optimizer, scheduler, criterion\n",
        "    gc.collect(); torch.cuda.empty_cache()\n",
        "\n",
        "    metrics: dict[str, Any] = {\n",
        "        \"model\": model_name,\n",
        "        \"test_acc\":        test_acc,\n",
        "        \"test_precision_macro\": prec_macro,\n",
        "        \"test_precision_micro\": prec_micro,\n",
        "        \"test_recall_macro\":    rec_macro,\n",
        "        \"test_recall_micro\":    rec_micro,\n",
        "        \"test_f1_macro\":        test_f1m,\n",
        "        \"test_f1_micro\":        test_f1¬µ,\n",
        "        \"report\":  report,          # classification_report\n",
        "        \"history\": hist,            # losses / accuracies por √©poca\n",
        "        # --- NUEVO ---\n",
        "        \"trained_model\": model,     # para an√°lisis posterior\n",
        "        \"test_loader\": test_loader_ref }\n",
        "    print(f\"\\n‚è± Duraci√≥n total: {(time.time()-start)/60:.1f} min\")\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "yod5PSrpEXcq"
      },
      "id": "yod5PSrpEXcq",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "...."
      ],
      "metadata": {
        "id": "iYYOH084USqx"
      },
      "id": "iYYOH084USqx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "## 4.3. Entrenamiento, validaci√≥n y prueba\n",
        "\n",
        " **`gradient clipping`** m"
      ],
      "metadata": {
        "id": "oz4ZPXG44a8W"
      },
      "id": "oz4ZPXG44a8W"
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    start_main = time.time()          # ‚Üê aqu√≠\n",
        "    MODELS = {\n",
        "        \"bert-base-uncased\": \"BERT\",\n",
        "        \"roberta-base\": \"RoBERTa\",\n",
        "    }\n",
        "\n",
        "    results   = []\n",
        "    histories = {}\n",
        "    models    = {}            # ‚¨ÖÔ∏é NUEVO\n",
        "    test_loader = None        # ‚¨ÖÔ∏é NUEVO\n",
        "    for mdl_name, label in MODELS.items():\n",
        "        out = train_and_evaluate(mdl_name, train_df, val_df, test_df)\n",
        "        results.append(out)\n",
        "        histories[label]  = out[\"history\"]\n",
        "        models[label]     = out[\"trained_model\"]\n",
        "        test_loader       = out[\"test_loader\"]   # mismo loader para ambos\n",
        "        print(\"\\n>>> Reporte detallado\")\n",
        "        print(out[\"report\"])\n",
        "        print(\"=\"*60)\n",
        "\n",
        "    # tabla comparativa\n",
        "    print(\"\\n======= Comparativa final =======\")\n",
        "    for res in results:\n",
        "        print(f\"{MODELS[res['model']]:9s} | \"\n",
        "        f\"Acc {res['test_acc']:.3f} | \"\n",
        "        f\"P_macro {res['test_precision_macro']:.3f} | \"\n",
        "        f\"R_macro {res['test_recall_macro']:.3f} | \"\n",
        "        f\"F1_macro {res['test_f1_macro']:.3f}\")\n",
        "\n",
        "    dur = (time.time() - start_main) / 60\n",
        "    print(f\"\\nTiempo total: {dur:.1f} min\\n\")"
      ],
      "metadata": {
        "id": "JAtN1d5G21to",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660,
          "referenced_widgets": [
            "04380d7d68fa47c3ae3559c82dc311fc",
            "b46156f1ee5647d1818cf14679d15a04",
            "b98aa2fbbf34401997f77bc1d6a29de6",
            "2e29edcb73f841c186bcb56911b8e9a9",
            "1bc74ad7d4d346debf778364152bf63b",
            "db920349936144e8bef9816ce07c0cea",
            "77a2193df8f54cb89339efabbb6196b5",
            "67c5eb5d82e9499c8456af2f97148cb5",
            "dbfdc1549a0b49dcadd1f4029d7397a3",
            "f65aefe482604b9eaaf2563b5d53bc09",
            "f03d5adb016b48fe8a9adf6cb403a913",
            "b9c72c8b48b04908ae17c05da8146702",
            "5e4fbf79a1e9448fb795ca07df88bb6b",
            "3cd9b787c5ea410d9e8524d75b185ea7",
            "e829a2292f9047bda5a50267fa5514b3",
            "04ac4da70e7443adb613bd2cbcbd5f5b",
            "5f31068bea7d4eb7a1a910e210a19641",
            "fc441cd08c694961871ce15c5560d677",
            "c615b8a22e7b4a5980dcf92642b135be",
            "fc8f0e7683aa48358278b44c30c6a1c5",
            "eb36703cdb1447dd92c34b3ebc1eb077",
            "d930ec207f67486c9a3f24a673071e0b",
            "aa1e148dcdf947ea928b59deeba28bbd",
            "c6343d04e83b4222a4988798c9a47886",
            "a1209c6955084e75825b2543df70d05a",
            "2dfae09593b74110abee4b23bd296593",
            "e2329998b9c242ec9bc029fdd45504bb",
            "aa28259b002e4272b5a18f8e20154585",
            "ff57e25391814093b66ae8d0a4953b8b",
            "ca49fad476fb42588d693066d7b3430d",
            "892c9f39dd294dc7999aa8f238d2956b",
            "0bb04b9faf414ea899307176cac68775",
            "ce986e07c66641879dd855c223401b05",
            "c0cb189961f7498aab28dc48bfaaa9c7",
            "f1ac80c33c694e60bec91cf7792f0ef9",
            "6dbab34daef745fab5b562c9f3f3ddd6",
            "3f6e9c988ed04d9c878afcfdffd93b8d",
            "fcb6e69617d24c38859913d033368d79",
            "1f9c480e37cc4fb4ae18ef2ff6abec17",
            "7798d93baf6f40edad3309abc79bf0d7",
            "2cefb5dcf1984e32bf1da3766a087be9",
            "b83785b24e62451096a5d2ee2c036f7c",
            "841f5450f6d5457296d07d501ed11dd0",
            "72fe72bdaaa74c6db92eb37378e6e4c6",
            "849cdb60d82e4b7791e8f2d358f6de6d",
            "5d54516313cd4219a53917faea814fa6",
            "64036bf22a754950a5d040a69e2a7fff",
            "c8923806df584cef99097642ed4ad311",
            "afc48583a4754a64943333ffa832a458",
            "a406f2013fcd4369bea824dbef6b29de",
            "226f742b3ddf438299d072ae4cb7570a",
            "2dfdd48cd10b4868a72455e2d52f757b",
            "95ac8ffb68364f8c837d420fc234f430",
            "79c5fb06d986491eb41a8a333c70d821",
            "8167bcf40e81479980d8fa4503102185"
          ]
        },
        "outputId": "8335226f-4e35-4c42-ae30-e7e19d1bc928"
      },
      "id": "JAtN1d5G21to",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========== Entrenando bert-base-uncased ==========\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "04380d7d68fa47c3ae3559c82dc311fc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b9c72c8b48b04908ae17c05da8146702"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa1e148dcdf947ea928b59deeba28bbd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c0cb189961f7498aab28dc48bfaaa9c7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "849cdb60d82e4b7791e8f2d358f6de6d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-3293a18522cd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m        \u001b[0;31m# ‚¨ÖÔ∏é NUEVO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmdl_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mMODELS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmdl_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mhistories\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"history\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-1f0c04256dce>\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(model_name, train_df, val_df, test_df)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mfreeze_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreeze\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlast_n\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mUNFREEZE_PER_EPOCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_f1m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_f1¬µ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0mval_f1m\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0mval_f1¬µ\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mepoch_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"val\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mhist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-1f0c04256dce>\u001b[0m in \u001b[0;36mepoch_pass\u001b[0;34m(split)\u001b[0m\n\u001b[1;32m     58\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m                     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "M√©trica\t¬øC√≥mo se calcula?\tCu√°ndo aporta valor\tObservaciones para tu proyecto (BBC News, 5 clases)\n",
        "Micro-precision/recall/F1\tSuma todos los TP, FP, FN y calcula la raz√≥n una sola vez.\t‚Ä¢ Multi-label‚ÄÇ(muchas etiquetas por muestra).\n",
        "‚Ä¢ Conjuntos muy desbalanceados donde el ‚Äútama√±o‚Äù total importa (p. ej., m√©tricas de search).\tPara clasificaci√≥n single-label multi-clase, el micro-F1 coincide con la accuracy. Si ya reportas accuracy, el micro-F1 a√±ade poca informaci√≥n nueva.\n",
        "Macro-precision/recall/F1\tCalcula la m√©trica por clase y luego hace el promedio simple (no ponderado).\t‚Ä¢ Quieres ver si el modelo trata a todas las clases por igual.\n",
        "‚Ä¢ Dataset algo desbalanceado.\n",
        "‚Ä¢ Necesitas comparaci√≥n justa entre modelos cuando hay minor√≠as.\t√ötil incluso con BBC (distribuci√≥n ‚âà balanceada, pero nunca perfecta) para evidenciar si alguna categor√≠a -‚Äútech‚Äù, ‚Äúsport‚Äù‚Ä¶- se queda atr√°s."
      ],
      "metadata": {
        "id": "wFt2XQ0PcZIJ"
      },
      "id": "wFt2XQ0PcZIJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "[3]"
      ],
      "metadata": {
        "id": "Pfn0fl1zaEVT"
      },
      "id": "Pfn0fl1zaEVT"
    },
    {
      "cell_type": "markdown",
      "source": [
        "..."
      ],
      "metadata": {
        "id": "75G3J6o5ieVc"
      },
      "id": "75G3J6o5ieVc"
    },
    {
      "cell_type": "markdown",
      "id": "7JgtiyyfIyMM",
      "metadata": {
        "id": "7JgtiyyfIyMM"
      },
      "source": [
        "***\n",
        "\n",
        "\n",
        "# 5. An√°lisis de resultados y discusi√≥n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "..."
      ],
      "metadata": {
        "id": "Ty3gzWEui8xK"
      },
      "id": "Ty3gzWEui8xK"
    },
    {
      "cell_type": "markdown",
      "source": [
        "..."
      ],
      "metadata": {
        "id": "qJZ_NDzdjQ7G"
      },
      "id": "qJZ_NDzdjQ7G"
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_model_diagnostics(*,\n",
        "                            history: dict | None = None,\n",
        "                            model = None,\n",
        "                            test_loader = None,\n",
        "                            class_names: list[str] | None = None,\n",
        "                            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
        "                            title: str = \"\") -> None:\n",
        "    \"\"\"\n",
        "    Combina en una sola figura:\n",
        "       ‚Ä¢ Curvas de Loss y Accuracy (si se pasa `history`)\n",
        "       ‚Ä¢ Matriz de confusi√≥n        (si se pasa `model` + `test_loader`)\n",
        "    Puedes suministrar solo una de las dos partes si lo prefieres.\n",
        "\n",
        "    Par√°metros\n",
        "    ----------\n",
        "    history      : dict con claves 'train_loss', 'val_loss', 'train_acc', 'val_acc'\n",
        "    model        : modelo transformers ya entrenado\n",
        "    test_loader  : DataLoader con el set de test\n",
        "    class_names  : lista de etiquetas (str) en el mismo orden que los IDs\n",
        "    device       : cpu / cuda\n",
        "    title        : t√≠tulo base que se antepone a cada sub-gr√°fico\n",
        "    \"\"\"\n",
        "    # ------ determinar cu√°ntas filas de subplots necesitamos ------\n",
        "    n_rows = 0\n",
        "    if history is not None:\n",
        "        n_rows += 2                # Loss y Accuracy\n",
        "    if model is not None and test_loader is not None and class_names is not None:\n",
        "        n_rows += 1                # Matriz de confusi√≥n\n",
        "    if n_rows == 0:\n",
        "        raise ValueError(\"Debes pasar `history` o (`model`, `test_loader`, `class_names`).\")\n",
        "\n",
        "    plt.figure(figsize=(7, 4 * n_rows))\n",
        "    plot_idx = 1\n",
        "\n",
        "    # ------ curvas de entrenamiento ------------------------------\n",
        "    if history is not None:\n",
        "        epochs = range(1, len(history[\"train_loss\"]) + 1)\n",
        "\n",
        "        # Loss\n",
        "        plt.subplot(n_rows, 1, plot_idx)\n",
        "        plt.plot(epochs, history[\"train_loss\"], label=\"Train Loss\")\n",
        "        plt.plot(epochs, history[\"val_loss\"],   label=\"Val Loss\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.title(f\"{title} ‚Äì Loss\")\n",
        "        plt.legend()\n",
        "        plot_idx += 1\n",
        "\n",
        "        # Accuracy\n",
        "        plt.subplot(n_rows, 1, plot_idx)\n",
        "        plt.plot(epochs, history[\"train_acc\"], label=\"Train Acc\")\n",
        "        plt.plot(epochs, history[\"val_acc\"],   label=\"Val Acc\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"Accuracy\")\n",
        "        plt.title(f\"{title} ‚Äì Accuracy\")\n",
        "        plt.legend()\n",
        "        plot_idx += 1\n",
        "\n",
        "    # ------ matriz de confusi√≥n ----------------------------------\n",
        "    if model is not None and test_loader is not None and class_names is not None:\n",
        "        model.eval()\n",
        "        y_true, y_pred = [], []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in test_loader:\n",
        "                # ‚Üê el DataLoader sigue entregando las mismas claves que antes\n",
        "                labels = batch[\"labels\"].to(device)\n",
        "                inputs = {k: v.to(device)\n",
        "                          for k, v in batch.items()\n",
        "                          if k not in [\"labels\", \"text\"]}\n",
        "\n",
        "                logits = model(**inputs).logits\n",
        "                probs = F.softmax(logits, dim=-1)\n",
        "                preds = torch.argmax(probs, dim=1)\n",
        "\n",
        "                y_true.extend(labels.cpu().tolist())\n",
        "                y_pred.extend(preds.cpu().tolist())\n",
        "\n",
        "        cm = confusion_matrix(y_true, y_pred)\n",
        "        plt.subplot(n_rows, 1, plot_idx)\n",
        "        disp = ConfusionMatrixDisplay(cm, display_labels=class_names)\n",
        "        disp.plot(ax=plt.gca(), cmap=\"Blues\", colorbar=False)\n",
        "        plt.title(f\"{title} ‚Äì Confusion Matrix\")\n",
        "        plt.xlabel(\"Predicted\")\n",
        "        plt.ylabel(\"True\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "uaauR7IpagRo"
      },
      "id": "uaauR7IpagRo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model_diagnostics(\n",
        "    history      = histories[\"BERT\"],\n",
        "    model        = models[\"BERT\"],\n",
        "    test_loader  = test_loader,\n",
        "    class_names  = le.classes_.tolist(),\n",
        "    title        = \"BERT\"\n",
        ")\n",
        "\n",
        "plot_model_diagnostics(\n",
        "    history      = histories[\"RoBERTa\"],\n",
        "    model        = models[\"RoBERTa\"],\n",
        "    test_loader  = test_loader,\n",
        "    class_names  = le.classes_.tolist(),\n",
        "    title        = \"RoBERTa\"\n",
        ")"
      ],
      "metadata": {
        "id": "KWYnrx5nGZtR"
      },
      "id": "KWYnrx5nGZtR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------\n",
        "#  Ejemplos FN / FP por clase  (c√≥digo simplificado)\n",
        "# -----------------------------------------------------\n",
        "def collect_fn_fp_examples(model,\n",
        "                            test_loader,\n",
        "                            test_df,\n",
        "                            class_names: list[str],\n",
        "                            *,\n",
        "                            device=DEVICE,\n",
        "                            k: int = 5) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Devuelve un DataFrame con **hasta `k`** ejemplos *FN* y *FP*\n",
        "    por clase, adem√°s de los *TP* para referencia.\n",
        "\n",
        "    Columnas devueltas:\n",
        "      ‚îú‚îÄ text     : texto original\n",
        "      ‚îú‚îÄ true     : etiqueta real         (int)\n",
        "      ‚îú‚îÄ pred     : etiqueta predicha     (int)\n",
        "      ‚îî‚îÄ type     : 'TP' ‚Äñ 'FN' ‚Äñ 'FP'\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    texts, y_true, y_pred = [], [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "            inputs = {k:v.to(device) for k,v in batch.items()\n",
        "                      if k not in [\"labels\",\"text\",\"idx\"]}\n",
        "            logits = model(**inputs).logits\n",
        "            probs  = F.softmax(logits, dim=-1)\n",
        "            preds  = torch.argmax(probs, dim=1)\n",
        "\n",
        "            y_true.extend(labels.cpu().tolist())\n",
        "            y_pred.extend(preds.cpu().tolist())\n",
        "            texts.extend(batch[\"text\"])\n",
        "    # --- DataFrame --------------------------------------------------------\n",
        "    df = pd.DataFrame({\n",
        "        \"text\": texts,\n",
        "        \"true\": y_true,\n",
        "        \"pred\": y_pred,\n",
        "    })\n",
        "    df[\"type\"] = \"UNDEF\"\n",
        "    # --- Etiquetar tipo de acierto/error ----------------------------------\n",
        "\n",
        "    # --- Seleccionar hasta k ejemplos por clase y tipo --------------------\n",
        "    out_rows = []\n",
        "    rows=[]\n",
        "    for cls in range(len(class_names)):\n",
        "        df.loc[(df.true==cls) & (df.pred!=cls), \"type\"] = \"FN\"\n",
        "        df.loc[(df.pred==cls) & (df.true!=cls), \"type\"] = \"FP\"\n",
        "        df.loc[(df.true==cls) & (df.pred==cls), \"type\"] = \"TP\"\n",
        "        fn = df[(df.true==cls)&(df.pred!=cls)].head(k)\n",
        "        fp = df[(df.pred==cls)&(df.true!=cls)].head(k)\n",
        "        rows.extend(fn.assign(tipo=\"FN\", clase=class_names[cls]).to_dict(\"records\"))\n",
        "        rows.extend(fp.assign(tipo=\"FP\", clase=class_names[cls]).to_dict(\"records\"))\n",
        "    return pd.DataFrame(rows)"
      ],
      "metadata": {
        "id": "VrcMKrQPGt2J"
      },
      "id": "VrcMKrQPGt2J",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Corre primero la inferencia sobre test_loader\n",
        "df_err_bert = collect_fn_fp_examples(models[\"BERT\"], test_loader,\n",
        "                                     test_df, le.classes_.tolist(), k=3)\n",
        "\n",
        "df_err_roberta = collect_fn_fp_examples(models[\"RoBERTa\"], test_loader,\n",
        "                                     test_df, le.classes_.tolist(), k=3)\n",
        "# 2) Visualiza\n",
        "display(df_err_bert[[\"text\",\"true\",\"pred\",\"tipo\"]].head(10))\n",
        "display(df_err_roberta[[\"text\",\"true\",\"pred\",\"tipo\"]].head(10))"
      ],
      "metadata": {
        "id": "I80o-UdGG4SO"
      },
      "id": "I80o-UdGG4SO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tsne_cls(*,\n",
        "             model,\n",
        "             test_loader,\n",
        "             class_names,\n",
        "             device,\n",
        "             save_path: str | None = None):\n",
        "    \"\"\"\n",
        "    ‚Ä¢ Extrae embeddings [CLS] del modelo sobre `test_loader`.\n",
        "    ‚Ä¢ Ejecuta t-SNE en 2 D con perplexity adaptativa:\n",
        "          perplexity = min(40, n_samples // 10)\n",
        "    ‚Ä¢ Si existe `save_path` y el archivo est√° creado,\n",
        "      reutiliza los embeddings proyectados (ahorra **`time`**).\n",
        "    \"\"\"\n",
        "    # ------------ 1) Obtener o cargar los vectores ----------------\n",
        "    if save_path and os.path.isfile(save_path):\n",
        "        print(f\"‚úî  t-SNE cargado de {save_path}\")\n",
        "        data = np.load(save_path)\n",
        "        X_2d, y = data[:, :2], data[:, 2].astype(int)\n",
        "    else:\n",
        "        model.eval()\n",
        "        reps, labels = [], []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in test_loader:\n",
        "                inputs = {k: v.to(device) for k, v in batch.items()\n",
        "                          if k not in [\"labels\", \"text\"]}\n",
        "                out = model(**inputs, output_hidden_states=True)\n",
        "                cls = out.hidden_states[-1][:, 0, :]      # (B, H)\n",
        "\n",
        "                reps.append(cls.cpu())\n",
        "                labels.extend(batch[\"labels\"].tolist())\n",
        "\n",
        "        X = torch.cat(reps).numpy()\n",
        "        y = np.array(labels)\n",
        "\n",
        "        # ------------ 2) t-SNE con perplexity din√°mica ------------\n",
        "        n_samples   = X.shape[0]\n",
        "        perplexity  = max(5, min(40, n_samples // 10))\n",
        "        print(f\"‚Üí n_samples={n_samples} | perplexity={perplexity}\")\n",
        "\n",
        "        tsne = TSNE(\n",
        "            n_components=2,\n",
        "            perplexity=perplexity,\n",
        "            init=\"random\",\n",
        "            learning_rate=\"auto\",\n",
        "            random_state=42,\n",
        "            n_iter=1000\n",
        "        )\n",
        "        X_2d = tsne.fit_transform(X)\n",
        "\n",
        "        if save_path:\n",
        "            np.save(save_path, np.c_[X_2d, y])\n",
        "            print(f\"üíæ  Guardado en {save_path}\")\n",
        "\n",
        "    # ------------ 3) Graficar ------------------------------------\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    for cls_id, cls_name in enumerate(class_names):\n",
        "        pts = X_2d[y == cls_id]\n",
        "        plt.scatter(pts[:, 0], pts[:, 1], alpha=0.6, label=cls_name, s=15)\n",
        "\n",
        "    plt.title(\"t-SNE de embeddings CLS\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "1jB6JKlLVoQG"
      },
      "id": "1jB6JKlLVoQG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Escoge el modelo que quieres proyectar\n",
        "model_to_plot = models[\"BERT\"]     # o \"RoBERTa\"\n",
        "\n",
        "# 2) Ejecuci√≥n (reutiliza si ya existe 'tsne_cls.npy')\n",
        "tsne_cls(\n",
        "    model       = model_to_plot,\n",
        "    test_loader = test_loader,\n",
        "    class_names = le.classes_.tolist(),\n",
        "    device      = DEVICE,\n",
        "    save_path   = Path(\"tsne_cls.npy\")          # guarda para futuras corridas\n",
        ")"
      ],
      "metadata": {
        "id": "EWyptqdMhynP"
      },
      "id": "EWyptqdMhynP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "\n",
        "# 6. Conclusi√≥n\n",
        "\n",
        "....."
      ],
      "metadata": {
        "id": "uDjo26cIk10k"
      },
      "id": "uDjo26cIk10k"
    },
    {
      "cell_type": "markdown",
      "id": "DwUWQIAE3O0o",
      "metadata": {
        "id": "DwUWQIAE3O0o"
      },
      "source": [
        "***\n",
        "\n",
        "\n",
        "# 7. Referencias"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BoLDjBS03xiQ",
      "metadata": {
        "id": "BoLDjBS03xiQ"
      },
      "source": [
        "[1] **BERT: Pre-training of Deep Bidirectional Transformers for\n",
        "Language Understanding  Google AI Language**  \n",
        "Disponible en: [arxiv.org](https://arxiv.org/abs/1810.04805)\n",
        "\n",
        "\n",
        "[2] **Documents Classification using BERT on BBC Dataset**  \n",
        "Disponible en: [kaggle.com](https://www.kaggle.com/code/ouardasakram/documents-classification-using-bert-on-bbc-dataset)\n",
        "\n",
        "\n",
        "[3] **Bert-Classification-BBC-News**  \n",
        "Disponible en: [github.com](https://github.com/bymi15/Bert-Classification-BBC-News/blob/main/bert_classification_bbc_news.ipynb)\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "04380d7d68fa47c3ae3559c82dc311fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b46156f1ee5647d1818cf14679d15a04",
              "IPY_MODEL_b98aa2fbbf34401997f77bc1d6a29de6",
              "IPY_MODEL_2e29edcb73f841c186bcb56911b8e9a9"
            ],
            "layout": "IPY_MODEL_1bc74ad7d4d346debf778364152bf63b"
          }
        },
        "b46156f1ee5647d1818cf14679d15a04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db920349936144e8bef9816ce07c0cea",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_77a2193df8f54cb89339efabbb6196b5",
            "value": "tokenizer_config.json:‚Äá100%"
          }
        },
        "b98aa2fbbf34401997f77bc1d6a29de6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67c5eb5d82e9499c8456af2f97148cb5",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dbfdc1549a0b49dcadd1f4029d7397a3",
            "value": 48
          }
        },
        "2e29edcb73f841c186bcb56911b8e9a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f65aefe482604b9eaaf2563b5d53bc09",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f03d5adb016b48fe8a9adf6cb403a913",
            "value": "‚Äá48.0/48.0‚Äá[00:00&lt;00:00,‚Äá4.07kB/s]"
          }
        },
        "1bc74ad7d4d346debf778364152bf63b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db920349936144e8bef9816ce07c0cea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77a2193df8f54cb89339efabbb6196b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67c5eb5d82e9499c8456af2f97148cb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbfdc1549a0b49dcadd1f4029d7397a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f65aefe482604b9eaaf2563b5d53bc09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f03d5adb016b48fe8a9adf6cb403a913": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9c72c8b48b04908ae17c05da8146702": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5e4fbf79a1e9448fb795ca07df88bb6b",
              "IPY_MODEL_3cd9b787c5ea410d9e8524d75b185ea7",
              "IPY_MODEL_e829a2292f9047bda5a50267fa5514b3"
            ],
            "layout": "IPY_MODEL_04ac4da70e7443adb613bd2cbcbd5f5b"
          }
        },
        "5e4fbf79a1e9448fb795ca07df88bb6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f31068bea7d4eb7a1a910e210a19641",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_fc441cd08c694961871ce15c5560d677",
            "value": "config.json:‚Äá100%"
          }
        },
        "3cd9b787c5ea410d9e8524d75b185ea7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c615b8a22e7b4a5980dcf92642b135be",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fc8f0e7683aa48358278b44c30c6a1c5",
            "value": 570
          }
        },
        "e829a2292f9047bda5a50267fa5514b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb36703cdb1447dd92c34b3ebc1eb077",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_d930ec207f67486c9a3f24a673071e0b",
            "value": "‚Äá570/570‚Äá[00:00&lt;00:00,‚Äá34.0kB/s]"
          }
        },
        "04ac4da70e7443adb613bd2cbcbd5f5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f31068bea7d4eb7a1a910e210a19641": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc441cd08c694961871ce15c5560d677": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c615b8a22e7b4a5980dcf92642b135be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc8f0e7683aa48358278b44c30c6a1c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb36703cdb1447dd92c34b3ebc1eb077": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d930ec207f67486c9a3f24a673071e0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa1e148dcdf947ea928b59deeba28bbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c6343d04e83b4222a4988798c9a47886",
              "IPY_MODEL_a1209c6955084e75825b2543df70d05a",
              "IPY_MODEL_2dfae09593b74110abee4b23bd296593"
            ],
            "layout": "IPY_MODEL_e2329998b9c242ec9bc029fdd45504bb"
          }
        },
        "c6343d04e83b4222a4988798c9a47886": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa28259b002e4272b5a18f8e20154585",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ff57e25391814093b66ae8d0a4953b8b",
            "value": "vocab.txt:‚Äá100%"
          }
        },
        "a1209c6955084e75825b2543df70d05a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca49fad476fb42588d693066d7b3430d",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_892c9f39dd294dc7999aa8f238d2956b",
            "value": 231508
          }
        },
        "2dfae09593b74110abee4b23bd296593": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bb04b9faf414ea899307176cac68775",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ce986e07c66641879dd855c223401b05",
            "value": "‚Äá232k/232k‚Äá[00:00&lt;00:00,‚Äá4.74MB/s]"
          }
        },
        "e2329998b9c242ec9bc029fdd45504bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa28259b002e4272b5a18f8e20154585": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff57e25391814093b66ae8d0a4953b8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca49fad476fb42588d693066d7b3430d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "892c9f39dd294dc7999aa8f238d2956b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0bb04b9faf414ea899307176cac68775": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce986e07c66641879dd855c223401b05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0cb189961f7498aab28dc48bfaaa9c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f1ac80c33c694e60bec91cf7792f0ef9",
              "IPY_MODEL_6dbab34daef745fab5b562c9f3f3ddd6",
              "IPY_MODEL_3f6e9c988ed04d9c878afcfdffd93b8d"
            ],
            "layout": "IPY_MODEL_fcb6e69617d24c38859913d033368d79"
          }
        },
        "f1ac80c33c694e60bec91cf7792f0ef9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f9c480e37cc4fb4ae18ef2ff6abec17",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7798d93baf6f40edad3309abc79bf0d7",
            "value": "tokenizer.json:‚Äá100%"
          }
        },
        "6dbab34daef745fab5b562c9f3f3ddd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2cefb5dcf1984e32bf1da3766a087be9",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b83785b24e62451096a5d2ee2c036f7c",
            "value": 466062
          }
        },
        "3f6e9c988ed04d9c878afcfdffd93b8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_841f5450f6d5457296d07d501ed11dd0",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_72fe72bdaaa74c6db92eb37378e6e4c6",
            "value": "‚Äá466k/466k‚Äá[00:00&lt;00:00,‚Äá7.36MB/s]"
          }
        },
        "fcb6e69617d24c38859913d033368d79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f9c480e37cc4fb4ae18ef2ff6abec17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7798d93baf6f40edad3309abc79bf0d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2cefb5dcf1984e32bf1da3766a087be9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b83785b24e62451096a5d2ee2c036f7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "841f5450f6d5457296d07d501ed11dd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72fe72bdaaa74c6db92eb37378e6e4c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "849cdb60d82e4b7791e8f2d358f6de6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d54516313cd4219a53917faea814fa6",
              "IPY_MODEL_64036bf22a754950a5d040a69e2a7fff",
              "IPY_MODEL_c8923806df584cef99097642ed4ad311"
            ],
            "layout": "IPY_MODEL_afc48583a4754a64943333ffa832a458"
          }
        },
        "5d54516313cd4219a53917faea814fa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a406f2013fcd4369bea824dbef6b29de",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_226f742b3ddf438299d072ae4cb7570a",
            "value": "model.safetensors:‚Äá100%"
          }
        },
        "64036bf22a754950a5d040a69e2a7fff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2dfdd48cd10b4868a72455e2d52f757b",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_95ac8ffb68364f8c837d420fc234f430",
            "value": 440449768
          }
        },
        "c8923806df584cef99097642ed4ad311": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79c5fb06d986491eb41a8a333c70d821",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8167bcf40e81479980d8fa4503102185",
            "value": "‚Äá440M/440M‚Äá[00:02&lt;00:00,‚Äá180MB/s]"
          }
        },
        "afc48583a4754a64943333ffa832a458": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a406f2013fcd4369bea824dbef6b29de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "226f742b3ddf438299d072ae4cb7570a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2dfdd48cd10b4868a72455e2d52f757b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95ac8ffb68364f8c837d420fc234f430": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "79c5fb06d986491eb41a8a333c70d821": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8167bcf40e81479980d8fa4503102185": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}