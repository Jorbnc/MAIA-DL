{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jorbnc/MAIA-DL/blob/master/Mini_Proyecto_3_DL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oa_MJEGQ6jTi",
      "metadata": {
        "id": "oa_MJEGQ6jTi"
      },
      "source": [
        "<img\n",
        "  src=\"data:image/svg+xml;base64,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\"\n",
        "  alt=\"Logo Universidad de los Andes\"\n",
        "  width=\"120\"\n",
        "/>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sl89pic17iPU",
      "metadata": {
        "id": "sl89pic17iPU"
      },
      "source": [
        "<style>\n",
        "@import url('https://fonts.googleapis.com/css2?family=Latin+Modern+Roman:wght@400;700&display=swap');\n",
        "\n",
        "body, p, h1, h2, h3, h4, h5, h6, li {\n",
        "  font-family: 'Latin Modern Roman', serif;\n",
        "}\n",
        "code, pre {\n",
        "  font-family: 'Fira Mono', monospace;\n",
        "}\n",
        "</style>\n",
        "\n",
        "***\n",
        "\n",
        "# **Miniproyecto 3 -Técnicas de *Deep Learning*- Clasificación Multi-Clase de Artículos de Noticias de la BBC Usando Transformers**\n",
        "\n",
        "## **Descripción del Problema**\n",
        "\n",
        "En este miniproyecto se plantea la **clasificación multi-clase** de artículos de noticias de la BBC aprovechando la capacidad de los modelos *transformer* para capturar relaciones contextuales complejas. Cada artículo puede pertenecer a una de varias categorías temáticas (e.g., *Sport, Business, Politics, Tech*).\n",
        "\n",
        "## **Objetivo**\n",
        "\n",
        "Desarrollar e implementar dos modelos de clasificación multi-clase basado en transformers ( **BERT** y **RoBERTa**) que, tras un preprocesamiento del texto y la adaptación de la capa de salida, sea capaz de predecir con alta exactitud, precisión, *recall* y *F1-score* las categorías de los artículos de la BBC."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SiCS5j-HAbCB",
      "metadata": {
        "id": "SiCS5j-HAbCB"
      },
      "source": [
        "***\n",
        "\n",
        "**Este proyecto es realizado por Andrés Felipe Ñungo y Jordan Bryan Núñez Campos para entrega el 20 de mayo de 2025.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8VqTMx7TYgjH",
      "metadata": {
        "id": "8VqTMx7TYgjH"
      },
      "source": [
        "\n",
        "***\n",
        "# **Índice**\n",
        "\n",
        "El *notebook* aborda el proyecto con la siguiente estructura:\n",
        "\n",
        "| 🔹 | Sección        |\n",
        "|----|----------------|\n",
        "| 1️⃣. | **Instalación y carga de librerías** |\n",
        "| 1️⃣.1️⃣. | **Configuraciones adicionales** |\n",
        "| 2️⃣. | **Análisis exploratorio y preparación de los datos**       |\n",
        "| 2️⃣.1️⃣. | **Carga y estadísticas generales**       |\n",
        "| 2️⃣.2️⃣. | **Limpieza de los datos**       |\n",
        "| 3️⃣. | **Definición de *pipelines* de procesamiento**          |\n",
        "| 3️⃣.1️⃣. | **Pipeline de preprocesamiento**   |\n",
        "| 4️⃣. | **Preparación para el desarrollo de los modelos**   |\n",
        "| 4️⃣.1️⃣. | **Partición y funciones de apoyo para los DataLoaders**   |\n",
        "| 4️⃣.2️⃣. | **Función de entrenamiento y preparación para la evaluación**   |\n",
        "| 4️⃣.3️⃣. | **Entrenamiento, validación y prueba**   |\n",
        "| 5️⃣. | **Análisis de resultados y discusión**   |\n",
        "| 6️⃣. | **Conclusión**   |\n",
        "| 7️⃣. | **Referencias**   |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cyVuwlHB_W3",
      "metadata": {
        "id": "2cyVuwlHB_W3"
      },
      "source": [
        "***\n",
        "\n",
        "# 1. Instalación y carga de librerías"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Antes de proceder con la carga de las librerías, se instalan para efectos de un correcto funcionamiento en ambientes como *Coursera* o *Google Colab*: **`kagglehub langdetect matplotlib scikit-learn plotly`**.\n"
      ],
      "metadata": {
        "id": "DkjBiBB5rU6t"
      },
      "id": "DkjBiBB5rU6t"
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalación de librerías necesarias para correr en Colab/Coursera\n",
        "!pip -q install kagglehub langdetect matplotlib scikit-learn plotly"
      ],
      "metadata": {
        "id": "l26426jMLCxE",
        "outputId": "d2150cb8-5ffc-46e3-a4b2-efc42ca4f7f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "l26426jMLCxE",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este bloque se importan utilidades de sistema como **`os`**, **`random`**, **`gc`**, **`time`** y **`Path`**, junto con las librerías de datos **`numpy`** y **`pandas`**, la descarga de *datasets* vía **`kagglehub`**, limpieza de texto con **`detect`** y **`re`**, preprocesamiento y partición con scikit-learn (**`LabelEncoder`**, **`train_test_split`**), herramientas de *transformers* (**`AutoTokenizer`**, **`AutoModelForSequenceClassification`**, **`AutoModel`**), componentes de PyTorch (**`Dataset`**, **`DataLoader`**, **`AdamW`**), métricas de evaluación (**`accuracy_score`**, **`f1_score`**, **`classification_report`**), y reducción de dimensión y visualización con  **`TSNE`**, **`matplotlib`** y **`ConfusionMatrixDisplay`**.  "
      ],
      "metadata": {
        "id": "2q7l4Q6t4ITO"
      },
      "id": "2q7l4Q6t4ITO"
    },
    {
      "cell_type": "code",
      "source": [
        "# Librerías comunes\n",
        "import os, random, gc, time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "# Descarga de datasets y de embeddings\n",
        "import kagglehub\n",
        "\n",
        "# Limpieza y preparación de los textos\n",
        "from langdetect import detect\n",
        "import re\n",
        "\n",
        "# Preprocesamiento y herramientas de PLN\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from transformers import get_linear_schedule_with_warmup,AutoTokenizer, AutoModelForSequenceClassification, AutoModel\n",
        "\n",
        "# Modelado\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "\n",
        "# Evaluación\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
        "\n",
        "# Librerías para visualizaciones\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from IPython.display import display"
      ],
      "metadata": {
        "id": "osjmTJMvtxua"
      },
      "id": "osjmTJMvtxua",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este bloque se establecen los **parámetros globales** que controlan el entrenamiento y la configuración del modelo: **`TEXT_COL`** y **`LABEL_COL`** definen las columnas de texto y categoría en el *DataFrame*, **`MAX_LEN`** fija la longitud máxima de secuencia para la tokenización, **`BATCH_SIZE`**, **`EPOCHS`** y **`PATIENCE`** regulan el tamaño de los lotes, el número de iteraciones y la detención temprana, mientras que **`UNFREEZE_PER_EPOCH`** determina cuántas capas del transformador se liberan progresivamente, **`DROPOUT`** que nos permitirá incluir un *dropout* extra a los *transformers* y **`SEED`** asegura que los experimentos sean reproducibles.  \n",
        "\n",
        "El valor de la mayoría de estos parámetros globales se toman a partir del Anexo A.3 del *paper* original de **BERT** [¹] (se utilizan estos mismos valores para **RoBERTa** no necesariamente porque sean \"óptimos\", sino más por efectos comparativos), donde se sugiere:\n",
        "\n",
        "*   **Batch size:** 16, 32\n",
        "*   **Learning rate (Adam):** 5e-5, 3e-5, 2e-5\n",
        "*   **Number of epochs:** 2, 3, 4"
      ],
      "metadata": {
        "id": "OeOXzQpOa-Lz"
      },
      "id": "OeOXzQpOa-Lz"
    },
    {
      "cell_type": "code",
      "source": [
        "# Parámetros globales de configuración del modelo\n",
        "TEXT_COL   = \"text\"  # nombre de la columna de los artículos\n",
        "LABEL_COL  = \"labels\" # nombre de la columna con la categoría\n",
        "MAX_LEN    = 256  # longitud máxima de cada secuencia de tokens\n",
        "BATCH_SIZE = 16   # número de muestras por lote de entrenamiento\n",
        "EPOCHS     = 4\n",
        "LEARNING_RATE = 2e-5\n",
        "PATIENCE   = 2    # Usado para early stopping\n",
        "UNFREEZE_PER_EPOCH = 2   # número de capas del modelo a descongelar\n",
        "DROPOUT = 0.3\n",
        "SEED = 13"
      ],
      "metadata": {
        "id": "afgVSw4d1AIw"
      },
      "id": "afgVSw4d1AIw",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1. Configuraciones adicionales\n",
        "\n",
        "Con el siguiente bloque se detecta si el entorno dispone de GPU y selecciona el **`device`** apropiado para PyTorch.  \n",
        "\n",
        "Primero se llama a **`is_available()`**, que devuelve *True* si se ha asignado una GPU CUDA al *runtime* de Colab. Según el resultado se imprime un mensaje informativo. Posteriormente, se construye el objeto **`device`**, que será pasado a la red y a los tensores de entrada para que se ubiquen en la GPU cuando sea posible. Por último se muestra en pantalla el dispositivo elegido."
      ],
      "metadata": {
        "id": "uOceAejmVjqF"
      },
      "id": "uOceAejmVjqF"
    },
    {
      "cell_type": "code",
      "source": [
        "# Devuelve asignación de GPU\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Dispositivo activo → {DEVICE}\")"
      ],
      "metadata": {
        "id": "LksJ95qEPWVr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df11fd1c-bbd9-4ad5-f474-3a18a875d755"
      },
      "id": "LksJ95qEPWVr",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dispositivo activo → cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adicionalmente se ocultan avisos para mantener limpias algunas salidas del *notebook*; y se imprimen las versiones de un conjunto de librerías clave ( **`numpy`**, **`pandas`**, **`torch`**, **`scikit-learn`**, **`kagglehub`**, **`matplotlib`**). Mostrar estas versiones al inicio del *notebook* facilita la reproducibilidad y ayuda a depurar posibles conflictos de dependencias."
      ],
      "metadata": {
        "id": "pfXxKk09Vulp"
      },
      "id": "pfXxKk09Vulp"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "LSwlUgjUjtR_",
      "metadata": {
        "id": "LSwlUgjUjtR_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96b5e47e-6419-4100-8623-909e9a99ef98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numpy :  2.0.2\n",
            "pandas :  2.2.2\n",
            "torch :  2.6.0+cu124\n",
            "scikit-learn :  1.6.1\n",
            "kagglehub :  0.3.12\n",
            "matplotlib :  3.10.0\n",
            "langdetect :  1.0.9\n",
            "transformers :  4.51.3\n",
            "plotly :  5.24.1\n"
          ]
        }
      ],
      "source": [
        "# Ignorar las warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Versiones utilizadas\n",
        "from importlib.metadata import version\n",
        "librerias = [\"numpy\",\"pandas\",\"torch\",\"scikit-learn\", \"kagglehub\",\n",
        "            \"matplotlib\", \"langdetect\",\"transformers\",\"plotly\"]\n",
        "for library in librerias:\n",
        "  print(library, \": \", version(library))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este bloque se fija la reproducibilidad del experimento asignando la semilla **`SEED`** a los generadores de números aleatorios de **Python**, **`NumPy`** y **`PyTorch`** (CPU y GPU), y configurando **`CUDNN`** para que opere de forma determinista y sin usar su *benchmark* automático, garantizando resultados consistentes en cada ejecución a costa de un posible descenso en el rendimiento."
      ],
      "metadata": {
        "id": "ok4F_5E1njTi"
      },
      "id": "ok4F_5E1njTi"
    },
    {
      "cell_type": "code",
      "source": [
        "# Definición del random state y seeds\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "torch.backends.cudnn.deterministic = True  # Forzar comportamiento determinista en CUDNN\n",
        "torch.backends.cudnn.benchmark = False     # Desactivar optimizaciones no deterministas en CUDNN"
      ],
      "metadata": {
        "id": "xdgcOt7gznvJ"
      },
      "id": "xdgcOt7gznvJ",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "qK311OLFzPep",
      "metadata": {
        "id": "qK311OLFzPep"
      },
      "source": [
        "***\n",
        "\n",
        "# 2. Análisis exploratorio y preparación de los datos\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "## 2.1. Carga y estadísticas generales"
      ],
      "metadata": {
        "id": "4KxKy7H1eID-"
      },
      "id": "4KxKy7H1eID-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se descarga el conjunto de datos de reseñas de noticias de la BBC de **`kagglehub`**. La función **`dataset_download`** guarda los archivos de manera local y devuelve la ruta absoluta, que se almacena en **`path`** y se muestra en pantalla mediante **`print`** para confirmar dónde quedaron los datos."
      ],
      "metadata": {
        "id": "yHwealvATakn"
      },
      "id": "yHwealvATakn"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "K4yOzyWKJbov",
      "metadata": {
        "id": "K4yOzyWKJbov",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db3f3be6-52db-446b-98ce-e5c9f38453b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datos descargados en: /kaggle/input/bbc-articles-dataset\n",
            "Dataset descargado en: /kaggle/input/bbc-articles-dataset/bbc_news_text_complexity_summarization.csv\n",
            "Filas totales: 2127\n"
          ]
        }
      ],
      "source": [
        "# Descarga del conjunto de datos\n",
        "path = kagglehub.dataset_download(\"jacopoferretti/bbc-articles-dataset\")\n",
        "print(\"Datos descargados en:\", path)\n",
        "\n",
        "CSV_PATH = os.path.join(path, \"bbc_news_text_complexity_summarization.csv\")\n",
        "print(f\"Dataset descargado en: {CSV_PATH}\")\n",
        "\n",
        "# Verificar número de datos\n",
        "data_raw = pd.read_csv(CSV_PATH)\n",
        "print(\"Filas totales:\", len(data_raw))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CNfurSnbmf79",
      "metadata": {
        "id": "CNfurSnbmf79"
      },
      "source": [
        "***\n",
        "\n",
        "## 2.2. Limpieza de los datos\n",
        "\n",
        "En estas sección identificamos y corregimos:\n",
        "\n",
        "* Valores faltantes\n",
        "* Textos duplicados\n",
        "* Textos en otros idiomas distintos al inglés"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verificamos que **no** hay datos faltantes o en \"N/A\", ni tampoco datos duplicados."
      ],
      "metadata": {
        "id": "_QbNFIVK9Y9J"
      },
      "id": "_QbNFIVK9Y9J"
    },
    {
      "cell_type": "code",
      "source": [
        "# Validación de datos faltantes\n",
        "data_raw.isna().sum()"
      ],
      "metadata": {
        "id": "2r0P2t_Ysjbq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "outputId": "58ce19ab-f5be-4678-dc66-d540bfea424a"
      },
      "id": "2r0P2t_Ysjbq",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text                            0\n",
              "labels                          0\n",
              "no_sentences                    0\n",
              "Flesch Reading Ease Score       0\n",
              "Dale-Chall Readability Score    0\n",
              "text_rank_summary               0\n",
              "lsa_summary                     0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>text</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>labels</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>no_sentences</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Flesch Reading Ease Score</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dale-Chall Readability Score</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>text_rank_summary</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lsa_summary</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Validación de duplicados\n",
        "data_raw.duplicated().sum()"
      ],
      "metadata": {
        "id": "m3IgmRbWskuE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05ee01e9-9b90-451f-bdd9-98f63a2860ea"
      },
      "id": "m3IgmRbWskuE",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int64(0)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copia de los datos por seguridad\n",
        "data = data_raw.copy()"
      ],
      "metadata": {
        "id": "fJETbmzSRX7o"
      },
      "id": "fJETbmzSRX7o",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se utiliza **`LabelEncoder`** para transformar la columna de categorías de texto en una nueva columna **`label_id`** con valores numéricos, se calcula el total de clases únicas a través de **`NUM_LABELS`**, y se generan dos diccionarios (**`id2label`** y **`label2id`**) que permiten convertir de manera sencilla entre los identificadores numéricos y las etiquetas de texto durante las fases de entrenamiento e inferencia."
      ],
      "metadata": {
        "id": "P80Y-mWg_2rm"
      },
      "id": "P80Y-mWg_2rm"
    },
    {
      "cell_type": "code",
      "source": [
        "# Codificación de etiquetas\n",
        "le = LabelEncoder()\n",
        "data[\"label_id\"] = le.fit_transform(data[LABEL_COL])\n",
        "\n",
        "NUM_LABELS = len(le.classes_)# Número total de clases únicas\n",
        "print(f\"Numéro de clases únicas {NUM_LABELS}\")\n",
        "\n",
        "# Mapea cada ID a su etiqueta original\n",
        "id2label = {i: lbl for i, lbl in enumerate(le.classes_)}\n",
        "# Mapea cada etiqueta a su ID correspondiente\n",
        "label2id = {v: k for k, v in id2label.items()}\n",
        "\n",
        "class_names = le.classes_.tolist()\n",
        "print(f\"Clases en el dataset {class_names}\")\n"
      ],
      "metadata": {
        "id": "XU6qAVkrjUo3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e117f456-6a64-4317-bfef-b5ad24264b3b"
      },
      "id": "XU6qAVkrjUo3",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numéro de clases únicas 5\n",
            "Clases en el dataset ['business', 'entertainment', 'politics', 'sport', 'tech']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "También se verifica el número promedio de palabras de los artículos noticiosos, con el objetivo de conocer cuán extensos pueden llegar a ser, esto también nos da una mejor idea de la ventana de atención que pueden llegar a tener nuestros *transformers*"
      ],
      "metadata": {
        "id": "X0XZFalUXVQl"
      },
      "id": "X0XZFalUXVQl"
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular número de palabras por texto\n",
        "word_counts = data[TEXT_COL].str.split().str.len()\n",
        "\n",
        "# Calcular promedio\n",
        "avg_word_count = word_counts.mean()\n",
        "print(f\"El número promedio de palabras por texto es: {avg_word_count:.2f}\")"
      ],
      "metadata": {
        "id": "nztVsxAvXUa8"
      },
      "id": "nztVsxAvXUa8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se gráfica con la función **`plot_class_distribution`** la distribución del *dataset* en las diferentes clases. En principio, no se observa un desbalance de los datos significativo. Sin embargo, tampoco se puede afirmar que el conjunto de datos está completamente balanceado, observando por ejemplo, una leve sub-representación de la clase entretenimiento y *tech*. Razón por la cual, puede cobrar sentido más adelante entrenar el modelo con balanceo sencillo de las clases y observar métricas de evaluación ponderadas por clase (\"macro\") para poder tener un análisis adecuado."
      ],
      "metadata": {
        "id": "quPKwoSZB_Hw"
      },
      "id": "quPKwoSZB_Hw"
    },
    {
      "cell_type": "code",
      "source": [
        "# Mapeo de la distribución de las clases\n",
        "def plot_class_distribution(data: pd.DataFrame, label_col: str = \"label_id\", class_names: List[str] = None) -> None:\n",
        "\n",
        "    # Preparar datos\n",
        "    counts = data[label_col].value_counts().sort_index()\n",
        "    labels = class_names if class_names is not None else counts.index.astype(str)\n",
        "\n",
        "    # Normalizamos los valores para mapearlos a la paleta\n",
        "    norm = plt.Normalize(counts.min(), counts.max())\n",
        "    colors = cm.viridis(norm(counts.values))\n",
        "\n",
        "    # Crear la figura y barras\n",
        "    fig, ax = plt.subplots(figsize=(8, 5))\n",
        "    bars = ax.bar(labels, counts.values, color=colors)\n",
        "\n",
        "    # Etiquetas de ejes y título\n",
        "    ax.set_xlabel(\"Clase\")\n",
        "    ax.set_ylabel(\"Número de artículos\")\n",
        "    ax.set_title(\"Distribución de clases en el dataset\")\n",
        "\n",
        "    # Rotar etiquetas del eje x de forma segura\n",
        "    ax.set_xticks(range(len(labels)))\n",
        "    ax.set_xticklabels(labels, rotation=45, ha=\"right\")\n",
        "\n",
        "    # Etiquetas a las barras\n",
        "    ax.bar_label(bars, labels=[f\"{c:,}\" for c in counts.values], padding=3)\n",
        "\n",
        "    fig.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_class_distribution(data, class_names = class_names )"
      ],
      "metadata": {
        "id": "1TQpLnbwan5r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "outputId": "5d9b9384-c0fa-46cc-e81b-ff24ee4099f7"
      },
      "id": "1TQpLnbwan5r",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aquí se define **`detectar_idiomas`**, que emplea la función **`detect`** de **`langdetect`** para identificar el idioma de cada texto en la columna elegida. Si la detección falla o el texto está vacío, se conserva 'desconocido'. Tras procesar todos los textos, se filtran los que no sean inglés e imprime hasta cinco ejemplos con su índice y fragmento para revisión, devolviendo finalmente el DataFrame actualizado con la nueva información de idioma. Corroboramos que todos los textos se encuentran en inglés."
      ],
      "metadata": {
        "id": "LHdSWxhRDoR8"
      },
      "id": "LHdSWxhRDoR8"
    },
    {
      "cell_type": "code",
      "source": [
        "# Validación de los idiomas en los artículos\n",
        "def detectar_idiomas(data: pd.DataFrame, col_texto: str = 'text') -> pd.DataFrame:\n",
        "    # Inicializamos con 'desconocido'\n",
        "    data['idioma'] = 'desconocido'\n",
        "\n",
        "    # Función auxiliar segura\n",
        "    def _detectar(texto):\n",
        "        if isinstance(texto, str) and texto.strip():\n",
        "            try:\n",
        "                return detect(texto)\n",
        "            except Exception:\n",
        "                return 'desconocido'\n",
        "        return 'desconocido'\n",
        "\n",
        "    # Aplicamos detección\n",
        "    data['idioma'] = data[col_texto].apply(_detectar)\n",
        "\n",
        "    # Filtramos los que no son inglés\n",
        "    mask = data['idioma'] != 'en'\n",
        "    idx_no_en = data[mask].index\n",
        "\n",
        "    if len(idx_no_en) > 0:\n",
        "        print(f\"Se encontraron {len(idx_no_en)} textos NO en inglés (ejemplos):\")\n",
        "        # Mostramos hasta 5 ejemplos (si es que se encuentran)\n",
        "        for i in idx_no_en[:5]:\n",
        "            print(f\" • Índice {i}: [{data.at[i,'idioma']}] {data.at[i,col_texto][:100]}...\")\n",
        "    else:\n",
        "        print(\"Todos los textos están detectados como inglés.\")\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "_WQ5tiJps-bO"
      },
      "id": "_WQ5tiJps-bO",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = detectar_idiomas(data, col_texto='text')"
      ],
      "metadata": {
        "id": "DpTn9HpSW6V9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49467786-4989-4477-8dd7-69748d4a45b1"
      },
      "id": "DpTn9HpSW6V9",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Todos los textos están detectados como inglés.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_ypyorGqwmRl",
      "metadata": {
        "id": "_ypyorGqwmRl"
      },
      "source": [
        "***\n",
        "\n",
        "# 3. Definición de *pipelines* de procesamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4370a607-ad43-4c5d-bddd-1a9370469409",
      "metadata": {
        "id": "4370a607-ad43-4c5d-bddd-1a9370469409"
      },
      "source": [
        "***\n",
        "\n",
        "## 3.1. *Pipeline* de preprocesamiento\n",
        "\n",
        "En esta ocasión el *pipeline* de preprocesamiento será muy corto, precisamente por el modo en el que los tokenizadores de los *transformers* operan. La función **`clean_text`** normaliza cada cadena eliminando espacios redundantes con una expresión regular, descartando carácteres que no sean letras, números o puntuación básica. Se cree que esta es la mejor aproximación para el problema ya que carácteres especiales (a excepción de las importantes en el inglés como el apóstrofe) o emojis no creemos que puedan aportar a la clasificación de estos textos. También la tokenización más adelante se va encargar de pasos como el *lowercasting* por lo que esta limpieza inicial no es necesario. Posteriormente, se recorre el conjunto de columnas **`text`**, **`text_rank_summary`** y **`lsa_summary`** en **`data`**, convirtiendo sus valores en texto y aplicando esta limpieza para estandarizar todos los contenidos antes de procesarlos."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Limpieza básica\n",
        "def clean_text(text: str) -> str:\n",
        "    # colapsa múltiples espacios en blanco\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "    # elimina caracteres no alfanuméricos ni puntuación básica\n",
        "    text = re.sub(r\"[^\\w.,;:!?()¿¡' ]+\", \"\", text)\n",
        "    # elimina espacios al inicio y al final\n",
        "    return text.strip()\n",
        "\n",
        "for col in (\"text\", \"text_rank_summary\", \"lsa_summary\"):\n",
        "    if col in data.columns:\n",
        "        data[col] = data[col].astype(str).apply(clean_text)"
      ],
      "metadata": {
        "id": "tK_D4XVsnk6c"
      },
      "id": "tK_D4XVsnk6c",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "G6-RrjwuxYEw",
      "metadata": {
        "id": "G6-RrjwuxYEw"
      },
      "source": [
        "***\n",
        "\n",
        "# 4. Preparación para el desarrollo de los modelos\n",
        "\n",
        "En esta ocasión no es necesario definir una clase para crear cada una de las capas de las redes neuronales a entrenar. Como se ha visto en clase, los *transformers* pre-entrenados como **BERT** ya vienen casi listos con toda la etapa de preparación de los datos y la estructura de la red. Por tal motivo, en esta sección se dejan las funciones y clases definidas para preparar los últimos detalles de los datos antes de pasarlos por cada uno de los modelos y generamos la función de entrenamiento. Adicionalmente, se incluyé una función que nos permitirá complementar la red con una capa de normalización para estabilizar la salida, explicará esto con mayor profundidad más adelante."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "## 4.1. Partición y funciones de apoyo para los *DataLoaders*\n",
        "\n",
        "Se usa **`train_test_split`** para separar el DataFrame **`data`** en **`train_data`** y **`test_data`** (10% para *test*, 10% para validación y 80% para entrenamiento) manteniendo la distribución de **`label_id`** mediante estratificación (y que así las particiones reflejen el leve \"desequilibrio\" de clases).\n",
        "\n",
        "Hay que recordar que el conjunto de datos es de tan solo **2.127** datos. Un poco pequeño para lo que solemos estar acostumbrados, razón por la cuál no podemos tomar un conjunto *test* o de validación muy grandes ya que nos quedamos facilmente sin una cantidad representativa de datos de entrenamiento.\n"
      ],
      "metadata": {
        "id": "YbTzASG6GdSr"
      },
      "id": "YbTzASG6GdSr"
    },
    {
      "cell_type": "code",
      "source": [
        "# División en train_data y test_data\n",
        "train_data, test_data = train_test_split(data, test_size=0.10, stratify=data[\"label_id\"], random_state=SEED)\n",
        "# A partir de train_data se extrae un conjunto de validación val_data\n",
        "train_data, val_data = train_test_split(train_data, test_size=0.10, stratify=train_data[\"label_id\"], random_state=SEED)\n",
        "# Mostramos el tamaño de cada partición\n",
        "print(\"Tamaños – Train / Val / Test:\", len(train_data), len(val_data), len(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6QJGsVGvoIK",
        "outputId": "d178e45c-de02-4bfc-c6fa-966511430e4f"
      },
      "id": "L6QJGsVGvoIK",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaños – Train / Val / Test: 1722 192 213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se toma como base la preparación de los datos usada en algunos *notebooks* públicos [²] y se crea la clase **`BBCDataset`**, que se hereda de **`Dataset`** de PyTorch y \"encapsula\" el procesamiento de cada muestra. Se guarda listas de textos y etiquetas junto con el **`tokenizer`**, la longitud máxima **`max_len`** y la opción **`return_idx`**; **`__len__`** devuelve la cantidad de ejemplos disponibles; **`__getitem__`** se hace la preparación de secuencias mediante  la tokenización del texto, con truncamiento y *padding* a tamaño fijo (el tokenizador que se va a usar, **`AutoTokenizer`**, ya hace estos pasos por nosotros razón por la cuál no se hizo en la etapa de pre-procesamiento), se elimina la dimensión extra resultante, añade la etiqueta como tensor (**`return_tensors=\"pt\"`**) y retorna también el texto original, incluyendo opcionalmente el índice de la muestra para análisis posteriores, lo que facilita la integración directa con un *DataLoader* y mantiene trazabilidad de los ejemplos durante el entrenamiento y la evaluación.\n",
        "\n",
        "En conjunto, este bloque es el “preparador de secuencias”: convierte texto crudo en el lote de tensores que el *encoder transformer* necesita para producir *embeddings* y, finalmente, la predicción de clase."
      ],
      "metadata": {
        "id": "wqy-xlwJ2zMS"
      },
      "id": "wqy-xlwJ2zMS"
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataset para la clasificación de noticias de la BBC\n",
        "class BBCDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_len, *, return_idx: bool = False):\n",
        "        self.texts  = data[TEXT_COL].tolist() # lista de textos crudos\n",
        "        self.labels = data[\"label_id\"].tolist()  # lista de IDs de etiqueta\n",
        "        self.tok    = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.return_idx = return_idx\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts) # número total de muestras\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        enc = self.tok(self.texts[idx], truncation=True, padding=\"max_length\", max_length=self.max_len, return_tensors=\"pt\")\n",
        "        item = {k: v.squeeze(0) for k, v in enc.items()}  # elimina la dimensión batch=1\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long) # convierte etiqueta a tensor\n",
        "        item[\"text\"] = self.texts[idx] # conserva el texto original\n",
        "        if self.return_idx:\n",
        "            item[\"idx\"] = torch.tensor(idx)   # incluye índice si se solicita\n",
        "        return item"
      ],
      "metadata": {
        "id": "zfp-stYtEt71"
      },
      "id": "zfp-stYtEt71",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este *collate* primero se extrae y guarda los textos crudos antes de apilar todos los tensores que el modelo requiere, y luego los reincorpora junto con los tensores resultantes de **`input_ids`**, **`attention_mask`**, **`labels`** y, si está presente, **`idx`**. Así, cada lote entregado al modelo incluye tanto los datos numéricos optimizados para el entrenamiento como el texto original y los índices necesarios para cualquier análisis o diagnóstico posterior dentro del proyecto (sección de \"**5. Análisis de resultados y discusión**\")."
      ],
      "metadata": {
        "id": "Is0sZqHd0LAB"
      },
      "id": "Is0sZqHd0LAB"
    },
    {
      "cell_type": "code",
      "source": [
        "# Además de apilar los tensores, se preserve el texto original y el índice de cada muestra\n",
        "def collate_with_text(batch):\n",
        "    # Extrae y elimina temporalmente el campo text\n",
        "    texts  = [b.pop(\"text\") for b in batch]\n",
        "\n",
        "    # Apila labels con dtype y forma correctos\n",
        "    labels = torch.stack([b[\"labels\"] for b in batch]).long()\n",
        "    # Validación de dimensionalidad\n",
        "    if labels.dim() == 2:\n",
        "        labels = labels.squeeze(1)\n",
        "    # Apila el resto de tensores\n",
        "    keys = [k for k in batch[0].keys() if k != \"labels\"]\n",
        "    out  = {k: torch.stack([b[k] for b in batch]) for k in keys}\n",
        "    out[\"labels\"] = labels\n",
        "    out[\"text\"] = texts\n",
        "    # Si cada muestra trae un índice idx, lo apila también\n",
        "    if \"idx\" in batch[0]:\n",
        "        out[\"idx\"] = torch.stack([b[\"idx\"] for b in batch])\n",
        "    return out"
      ],
      "metadata": {
        "id": "zPBwOr5LvZBH"
      },
      "id": "zPBwOr5LvZBH",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**`Make_loader`** construye y devuelve un *DataLoader* configurado para el dataset BBC."
      ],
      "metadata": {
        "id": "93fcx-bj1RLZ"
      },
      "id": "93fcx-bj1RLZ"
    },
    {
      "cell_type": "code",
      "source": [
        " # Crea y retorna el DataLoader configurado\n",
        "def make_loader(data, tokenizer, split, batch_size, max_len, return_idx=False, num_workers=2):\n",
        "    # Instancia el dataset personalizado BBCDataset\n",
        "    ds = BBCDataset(data, tokenizer, max_len, return_idx=return_idx)\n",
        "    return DataLoader(ds, batch_size=batch_size, shuffle=(split==\"train\"), num_workers=num_workers, pin_memory=True, collate_fn=collate_with_text)"
      ],
      "metadata": {
        "id": "3bPJ2rdm_v46"
      },
      "id": "3bPJ2rdm_v46",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La técnica acontinuación ya se había aplicado anteriormente en el **Miniproyecto 2** [³]. Esta permite *congelar* o *descongelar* gradientes de capas del *encoder* de un modelo, lo cual ayuda a (i) conservar características generales útiles, (ii) adaptar con seguridad las capas superiores y (iii) mejorar la precisión sin sobre-ajustar, sobre todo en conjuntos de datos pequeños o medianos."
      ],
      "metadata": {
        "id": "T4sMR5EA4ldE"
      },
      "id": "T4sMR5EA4ldE"
    },
    {
      "cell_type": "code",
      "source": [
        "# Congela/descongela capas del encoder\n",
        "def freeze_layers(model, freeze: bool = True, last_n: int = None) -> None:\n",
        "    # Hay modelos donde el encoder vive en .transformer, se revisa\n",
        "    if isinstance(model, nn.Sequential):\n",
        "        # RobertaModel está en model[0]\n",
        "        encoder = model[0].encoder\n",
        "    else:\n",
        "        encoder = getattr(model.base_model, \"encoder\", None) \\\n",
        "                  or getattr(model.base_model, \"transformer\", None)\n",
        "\n",
        "    if encoder is None:\n",
        "        # Si no tiene encoder explícito, congelamos todo el base_model\n",
        "        base_model = model[0] if isinstance(model, nn.Sequential) else model.base_model\n",
        "        for p in base_model.parameters():\n",
        "            p.requires_grad = not freeze\n",
        "        return\n",
        "\n",
        "    # Congela/libera todas las capas del encoder\n",
        "    for param in encoder.parameters():\n",
        "        param.requires_grad = not freeze\n",
        "\n",
        "    # Libera específicamente las últimas last_n capas (si se especifica)\n",
        "    if last_n is not None and last_n > 0:\n",
        "        layers = encoder.layer if hasattr(encoder, 'layer') else encoder.layers\n",
        "        for layer in layers[-last_n:]:\n",
        "            for param in layer.parameters():\n",
        "                param.requires_grad = True"
      ],
      "metadata": {
        "id": "qudFCuoD0Gw_"
      },
      "id": "qudFCuoD0Gw_",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para hacer *fine-tuning* a los modelos que se correrán se define la siguiente función que incorpora una capa de normalización, basado en un *paper* donde se mejora con esta técnica a **RoBERTa** [⁴]. Aplicar esta función antes de la capa lineal logra estabilizar la distribución de activaciones que recibe la cabeza de la red, reduciendo el *internal covariate shift*, un problema conocido en el mundo de los *transformers* por generar variación continua en la distribución de las activaciones internas de una red neuronal durante el entrenamiento. Esta reducción, suele traducirse en convergencias más estables y entre +0.3 y +0.7 pp de mejora en *accuracy* [⁴]. Esto se logra mediante un *dropout* extra (en este caso de  0.3) , lo que mitiga el *overfitting* cuando el conjunto de entrenamiento es pequeño (como lo es este caso); a diferencia del *dropout* interno (p ≈ 0.1) que **BERT**/**RoBERTa** implementa. Finalmente, se inicializa la nueva capa con *Xavier* + bias = 0   (también llamado **Glorot init**) [⁴] lo cual asigna pesos con varianza ajustada, manteniendo la magnitud de los gradientes a través de la red y evitando desplazamientos iniciales hacia clases concretas, lo que acelera las primeras épocas de *fine-tuning*."
      ],
      "metadata": {
        "id": "c-o_--ASKSM4"
      },
      "id": "c-o_--ASKSM4"
    },
    {
      "cell_type": "code",
      "source": [
        "# Sustituye la cabeza de clasificación por una capa de normalización\n",
        "def add_norm_dropout_head(model, dropout_p: float = 0.3):\n",
        "\n",
        "    hidden = model.config.hidden_size\n",
        "    num_lbl = model.config.num_labels\n",
        "\n",
        "    new_head = nn.Sequential(nn.LayerNorm(hidden, eps=model.config.layer_norm_eps),\n",
        "                              nn.Dropout(dropout_p), nn.Linear(hidden, num_lbl))\n",
        "\n",
        "    # Inicialización recomendada\n",
        "    nn.init.xavier_uniform_(new_head[-1].weight)\n",
        "    nn.init.constant_(new_head[-1].bias, 0.)\n",
        "\n",
        "    # Algunos modelos exponen la cabeza como .classifier, otros como .score\n",
        "    if hasattr(model, \"classifier\"):\n",
        "        # Manejar estructura especial de RoBERTa por defecto\n",
        "        if isinstance(model.classifier, nn.Sequential):\n",
        "            model.classifier = new_head\n",
        "        else:\n",
        "            model.classifier = new_head\n",
        "\n",
        "    elif hasattr(model, \"score\"):\n",
        "        model.score = new_head\n",
        "    else:\n",
        "        raise AttributeError(\"No se encontró la cabeza de clasificación\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "1y1KOsCMKK_V"
      },
      "id": "1y1KOsCMKK_V",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "## 4.2. Función de entrenamiento y preparación para la evaluación\n",
        "\n",
        "Esta función es tal vez la más importante de todo el *notebook*, donde se basa todo el *fine-tuning* y evaluación del modelo. Empieza cargando el tokenizador y el modelo. Note que en este proyecto se está probando en un mismo *pipeline* a **BERT** y para **RoBERTa**, por lo que es necesario cargar ambos *items* con **`AutoTokenizer`** y **`AutoModelForSequenceClassification`**. Más adelante se habla un poco más del tokenizador. Adicionalmente, con el objetivo de \"jugar\" con el modelo se añade la capa de normalización extra que como objetivo tendrá mejorar la generalización de ambos modelos.\n",
        "\n",
        "A continuación, se calcula los pesos de clase y  se crean los *DataLoaders* llamando a **`make_loader`** para los *splits* **`train`**,**`val`** y **`test`**. Adicionalmente, se configura el optimizador **`AdamW`** junto al *scheduler*. En esta ocasión se usa **`AdamW`**, que permite aplicar un *weight decay* para evitar sobre-ajuste. Adicionalmente, se usa el *scheduler* que gestiona dinámicamente la tasa de aprendizaje a lo largo del entrenamiento siguiendo dos fases: 1. *Warm-up* -incremento gradual en los primeros pasos y 2. Decaimiento lineal -descenso de forma lineal hasta 0 [⁵]. Finalmente se define la función de pérdida con **`CrossEntropyLoss`**.\n",
        "\n",
        "En cada *epoch* se recorre un *split* completo para acumular pérdidas, predicciones y etiquetas verdaderas y así calcular métricas como *accuracy* y *F1*. Esto se hace descongelando gradualmente capas. Adicionalmente se aplica *early stopping* y guardando el mejor modelo en **`best_path`**. Tras el entrenamiento, se carga el mejor estado con **`torch.load`** y desde esta etapa se evalúa en *test* generando precisión, *recall* y el *classification_report*. Se limpia memoria con **`gc.collect()`** y **`torch.cuda.empty_cache()`**, y finalmente retorna un diccionario con todas las métricas, el modelo entrenado, el **`tokenizer`**, el **`test_loader`** y el historial de entrenamiento.\n",
        "\n",
        "Ahora se explica con más detalle AutoTokenizer [⁶]:\n",
        "\n",
        "**`AutoTokenizer`** simplifica y unifica el preprocesamiento de texto para distintos modelos (**BERT**, **RoBERTa**, **DistilBERT,** etc.), detectando automáticamente la clase de *tokenizer* adecuada y eliminando la necesidad de múltiples importaciones o bloques *if/else*. Durante la tokenización, descompone el texto y añade los special tokens ([CLS], [SEP]), convierte cada *token* a su *input_id*, crea la *attention_mask* para diferenciar texto real de *padding*, y aplica truncado y relleno hasta MAX_LEN para generar lotes uniformes."
      ],
      "metadata": {
        "id": "JzIcaKUzJHl8"
      },
      "id": "JzIcaKUzJHl8"
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(model_name: str, train_data, val_data, test_data):\n",
        "    print(f\"\\nEntrenando {model_name} ...\")\n",
        "\n",
        "    start = time.time()\n",
        "    # Tokenizer + modelo\n",
        "    if \"roberta\" in model_name:\n",
        "        # Carga RobertaModel sin cabeza de clasificación original\n",
        "        base_model = AutoModel.from_pretrained(model_name).to(DEVICE)\n",
        "\n",
        "        # Crea cabeza propia desde cero\n",
        "        model = nn.Sequential( base_model, nn.LayerNorm(base_model.config.hidden_size),\n",
        "            nn.Dropout(DROPOUT), nn.Linear(base_model.config.hidden_size, NUM_LABELS)).to(DEVICE)\n",
        "\n",
        "    else:\n",
        "        # Para BERT usamos modelo estándar con cabeza simple\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=NUM_LABELS, id2label=id2label,\n",
        "            label2id=label2id).to(DEVICE)\n",
        "        model = add_norm_dropout_head(model, dropout_p=DROPOUT).to(DEVICE)\n",
        "    #Tokenizador, igual para ambas\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "    # Congelar encoder completo y luego liberar gradualmente\n",
        "    freeze_layers(model)\n",
        "\n",
        "    # Pesos de clase balanceados\n",
        "    class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.arange(NUM_LABELS), y=train_data[\"label_id\"])\n",
        "    class_weights = torch.tensor(class_weights, dtype=torch.float32, device=DEVICE)\n",
        "\n",
        "    # DataLoaders\n",
        "    loaders = {\n",
        "        \"train\": make_loader(train_data, tokenizer, \"train\", BATCH_SIZE, MAX_LEN),\n",
        "        \"val\":   make_loader(val_data,   tokenizer, \"val\",   BATCH_SIZE, MAX_LEN),\n",
        "        \"test\":  make_loader(test_data,  tokenizer, \"test\",  BATCH_SIZE, MAX_LEN),\n",
        "    }\n",
        "\n",
        "    # Optimizador & scheduler\n",
        "    total_steps = len(loaders[\"train\"]) * EPOCHS\n",
        "    optimizer   = AdamW(model.parameters(), lr= LEARNING_RATE, weight_decay=1e-2)\n",
        "    scheduler   = get_linear_schedule_with_warmup(optimizer,\n",
        "                                                  #6%  de los pasos para hacer warm-up\n",
        "                                                  num_warmup_steps=int(0.06 * total_steps),\n",
        "                                                  num_training_steps=total_steps)\n",
        "    # Criterio de pérdida\n",
        "    criterion   = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "    best_f1, patience_cnt = 0.0, 0\n",
        "    best_path = f\"best_{model_name.split('-')[0]}_bbc.pt\"\n",
        "\n",
        "    # Función interna para una pasada por un split\n",
        "    def epoch_pass(split):\n",
        "        # Determina si se trata de entrenamiento (\"train\") o evaluación (\"val\" o \"test\")\n",
        "        is_train = split == \"train\"\n",
        "        model.train() if is_train else model.eval()\n",
        "        losses, preds_all, trues_all = [], [], []\n",
        "        # Recorre los lotes del DataLoader correspondiente al split actual\n",
        "        for batch in loaders[split]:\n",
        "            batch = {k: (v.to(DEVICE) if torch.is_tensor(v) else v) for k,v in batch.items()}\n",
        "            with torch.set_grad_enabled(is_train):\n",
        "                inputs = {k: v for k, v in batch.items() if k not in [\"labels\", \"text\", \"idx\"]}\n",
        "                # Llama explícitamente RobertaModel\n",
        "                if \"roberta\" in model_name:\n",
        "                    base_outputs = model[0](**inputs)\n",
        "                    cls_embedding = base_outputs.pooler_output\n",
        "                    # pasa por LayerNorm, Dropout y Linear\n",
        "                    logits = model[1:](cls_embedding)\n",
        "                else:\n",
        "                    outputs = model(**inputs)\n",
        "                    logits = outputs.logits\n",
        "                # Obtiene las etiquetas verdaderas del batch\n",
        "                labels = batch[\"labels\"].to(DEVICE)\n",
        "                labels = labels.long()\n",
        "                # Calcula la pérdida entre las predicciones\n",
        "                loss = criterion(logits, labels)\n",
        "                 # Si se está entrenando, realiza el paso de optimización\n",
        "                if is_train:\n",
        "                    loss.backward()\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "                    optimizer.step(); scheduler.step(); optimizer.zero_grad()\n",
        "            # Acumular métricas\n",
        "            losses.append(loss.item())\n",
        "            preds_all.extend(logits.argmax(dim=-1).cpu().numpy())\n",
        "            trues_all.extend(labels.cpu().numpy())\n",
        "\n",
        "        acc = accuracy_score(trues_all, preds_all)\n",
        "        f1_macro = f1_score(trues_all, preds_all, average=\"macro\", zero_division=0)\n",
        "        f1_micro = f1_score(trues_all, preds_all, average=\"micro\", zero_division=0)\n",
        "        return np.mean(losses), acc, f1_macro, f1_micro\n",
        "\n",
        "    # Bucle de entrenamiento con early stopping\n",
        "    hist = {k: [] for k in [\"epoch\",\"train_loss\",\"val_loss\",\n",
        "                        \"train_acc\",\"val_acc\",\"train_f1\",\"val_f1\"]}\n",
        "    for epoch in range(1, EPOCHS + 1):\n",
        "       # Descongela progresivamente las últimas capas\n",
        "        freeze_layers(model, freeze=False,last_n=epoch * UNFREEZE_PER_EPOCH)\n",
        "        # Ejecuta una pasada por el conjunto de entrenamiento y obtiene métricas\n",
        "        train_loss, train_acc, train_f1_macro, train_f1_micro = epoch_pass(\"train\")\n",
        "        # Ejecuta una pasada por el conjunto de validación y obtiene métricas\n",
        "        val_loss,   val_acc,   val_f1_macro,   val_f1_micro   = epoch_pass(\"val\")\n",
        "        hist[\"epoch\"].append(epoch)\n",
        "        hist[\"train_loss\"].append(train_loss); hist[\"val_loss\"].append(val_loss)\n",
        "        hist[\"train_acc\"].append(train_acc);   hist[\"val_acc\"].append(val_acc)\n",
        "        hist[\"train_f1\"].append(train_f1_macro);    hist[\"val_f1\"].append(val_f1_macro)\n",
        "        # Imprime resumen de la época: pérdida y F1/accuracy de validación\n",
        "        print(f\"Ep {epoch:02d}: \\tTL {train_loss:.4f} / VL {val_loss:.4f} | \"\n",
        "              f\"F1_macro {val_f1_macro:.3f}  Acc {val_acc:.3f}\")\n",
        "         # Si se mejora el mejor F1 de validación, guarda el modelo y reinicia paciencia\n",
        "        if val_f1_macro > best_f1:\n",
        "            best_f1 = val_f1_macro\n",
        "            patience_cnt = 0\n",
        "            torch.save(model.state_dict(), best_path)\n",
        "        else:\n",
        "            # Si no mejora, incrementa el contador de paciencia\n",
        "            patience_cnt += 1\n",
        "             # Si se alcanza el umbral de paciencia, detiene el entrenamiento\n",
        "            if patience_cnt == PATIENCE:\n",
        "                print(\"Early stopping ↯\\n\")\n",
        "                break\n",
        "\n",
        "    #  Evaluación sobre test\n",
        "    model.load_state_dict(torch.load(best_path))\n",
        "    test_loss, test_acc, test_f1_macro, test_f1_micro = epoch_pass(\"test\")\n",
        "\n",
        "    y_true, y_pred = [], []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in loaders[\"test\"]:\n",
        "            batch = {k: (v.to(DEVICE) if torch.is_tensor(v) else v) for k,v in batch.items()}\n",
        "            inputs = {k: v for k, v in batch.items() if k not in [\"labels\", \"text\", \"idx\"]}\n",
        "            labels = batch[\"labels\"].to(DEVICE).long()\n",
        "            if \"roberta\" in model_name:\n",
        "                base_outputs = model[0](**inputs)\n",
        "                cls_embedding = base_outputs.pooler_output\n",
        "                logits = model[1:](cls_embedding)\n",
        "            else:\n",
        "                outputs = model(**inputs)\n",
        "                logits = outputs.logits\n",
        "            y_true.extend(labels.cpu().numpy())\n",
        "            y_pred.extend(logits.argmax(dim=-1).cpu().numpy())\n",
        "\n",
        "    # Precisión y recall (macro / micro)\n",
        "    prec_macro = precision_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
        "    prec_micro = precision_score(y_true, y_pred, average=\"micro\", zero_division=0)\n",
        "    rec_macro  = recall_score   (y_true, y_pred, average=\"macro\", zero_division=0)\n",
        "    rec_micro  = recall_score   (y_true, y_pred, average=\"micro\", zero_division=0)\n",
        "\n",
        "    report = classification_report(y_true, y_pred,labels=list(range(NUM_LABELS)),\n",
        "                                  target_names=le.classes_.tolist(),\n",
        "                                  digits=3,\n",
        "                                  zero_division=0)\n",
        "\n",
        "    # Limpieza explícita\n",
        "    test_loader_ref = loaders[\"test\"]    # referencia antes de borrar\n",
        "    del loaders, optimizer, scheduler, criterion\n",
        "    gc.collect(); torch.cuda.empty_cache()\n",
        "    # Retorno de resultados\n",
        "    metrics: dict[str, Any] = {\"model\": model_name,\n",
        "                              \"test_acc\": test_acc,\n",
        "                              \"test_precision_macro\": prec_macro,\n",
        "                              \"test_precision_micro\": prec_micro,\n",
        "                              \"test_recall_macro\": rec_macro,\n",
        "                              \"test_recall_micro\": rec_micro,\n",
        "                              \"test_f1_macro\": test_f1_macro,\n",
        "                              \"test_f1_micro\": test_f1_micro,\n",
        "                              \"report\":  report,\n",
        "                              \"history\": hist,\n",
        "                              \"trained_model\": model,\n",
        "                              \"test_loader\": test_loader_ref}\n",
        "\n",
        "    print(f\"\\n Duración total: {(time.time()-start)/60:.1f} min\")\n",
        "    return metrics, model, tokenizer, test_loader_ref , hist"
      ],
      "metadata": {
        "id": "yod5PSrpEXcq"
      },
      "id": "yod5PSrpEXcq",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "## 4.3. Entrenamiento, validación y prueba\n",
        "\n",
        "En el bloque final de esta sección, se comprueba que el *script* se ejecute como programa principal (*main*), se establece el diccionario **`MODELS`** con las arquitecturas de **BERT** y **RoBERTa** a evaluar. A continuación se inicializan los contenedores **`results`**, **`models`**, **`loaders`** e **`histories`**, y se recorre cada entrada de **`MODELS`** invocando la función **`train_and_evaluate`** sobre los conjuntos de entrenamiento, validación y prueba, guardando los informes detallados y los objetos asociados a cada modelo. Tras entrenar ambos, se imprime una tabla comparativa con las métricas finales de *accuracy*, *precision*, *recall* y *F1* macro para cada modelo.\n",
        "\n",
        "**BERT** es un modelo *transformer* bidireccional [¹] de gran escala entrenado con tareas de *masked language modeling y Next Sentence Prediction*, lo que le permite captar el contexto completo de una secuencia de texto. Su arquitectura profunda (en este caso de 12 capas de atención, pero algunas variantes las llevas hasra 24) facilita el pre-entrenamiento y el *fine-tuning* eficientes en diversas tareas de NLP [¹]. El modelo **`bert-base-uncased`** corresponde a la configuración base de **BERT** y, de forma muy resumida, su arquitectura es [¹]:\n",
        "\n",
        "* **`num_hidden_layers`**: **12**\n",
        "* **`hidden_size`**: **768**\n",
        "* **`num_attention_heads`**: **12**\n",
        "* **`intermediate_size`**: **3072**\n",
        "* **`max_position_embeddings`**: **512**\n",
        "* **`vocab_size`**: **30.522**\n",
        "\n",
        "Además emplea tokenización *WordPiece* sin distinguir mayúsculas/minúsculas\n",
        "\n",
        "Por otro lado, **RoBERTa** es una variante de **BERT** que optimiza el pre-entrenamiento eliminando la tarea de *Next Sentence Prediction* (NSP), usando enmascaramiento dinámico, secuencias más largas y mayor volumen de datos, lo cual mejora la robustez y la precisión sin cambiar la arquitectura base [⁷]. La única diferencia principal está en el tamaño del vocabulario (**`vocab_size`**), que es de **30.522** en BERT base y de **50.265** en RoBERTa.\n",
        "\n",
        "Para el Miniproyecto 3, que requiere clasificar en diferentes temáticas a artículos de la **BBC**, ambos modelos son ideales porque capturan dependencias contextuales complejas sin procesar token por token, lo que acelera el entrenamiento en GPU. Además, manejan la clasificación multi-clase de manera nativa al añadir una capa de salida con función softmax.\n",
        "\n",
        "Frente a las RNNs, los transformers permiten paralelizar el cómputo (y de hecho el tiempo de procesamiento es notablemente mejor, respecto al Miniproyecto 2), evitar el desvanecimiento de gradientes en secuencias largas y lograr mayor precisión y eficiencia en tareas de clasificación de texto."
      ],
      "metadata": {
        "id": "oz4ZPXG44a8W"
      },
      "id": "oz4ZPXG44a8W"
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    start_main = time.time()\n",
        "    # Define el diccionario de arquitecturas a comparar\n",
        "    MODELS = { \"bert-base-uncased\": \"BERT\",\n",
        "                \"roberta-base\": \"RoBERTa\" }\n",
        "\n",
        "    results =[]\n",
        "    models, loaders, histories = {}, {}, {}\n",
        "    # Itera sobre cada modelo, entrena y evalúa\n",
        "    for mdl_name, label in MODELS.items():\n",
        "        m, mol, tok, tl, h  = train_and_evaluate(mdl_name, train_data, val_data, test_data)\n",
        "        results.append(m)\n",
        "        models[mdl_name]   = mol\n",
        "        loaders[mdl_name]  = tl\n",
        "        histories[mdl_name]= h\n",
        "        print(\"\\n>>> Reporte detallado\")\n",
        "        print(m[\"report\"])\n",
        "        print(\"=\"*60)\n",
        "\n",
        "    # Imprime la comparación final de métricas\n",
        "    print(\"\\n======= Comparativa final =======\")\n",
        "    for res in results:\n",
        "        print(f\"{MODELS[res['model']]:9s} | \"\n",
        "        f\"Acc {res['test_acc']:.3f} | \"\n",
        "        f\"P_macro {res['test_precision_macro']:.3f} | \"\n",
        "        f\"R_macro {res['test_recall_macro']:.3f} | \"\n",
        "        f\"F1_macro {res['test_f1_macro']:.3f}\")\n",
        "\n",
        "    dur = (time.time() - start_main) / 60\n",
        "    print(f\"\\nTiempo total: {dur:.1f} min\\n\")"
      ],
      "metadata": {
        "id": "JAtN1d5G21to",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660,
          "referenced_widgets": [
            "0f0ce8e0159b45daa0814bd5f3982e42",
            "5f16c71c7f7e44669633fd2d102c209f",
            "4de8b2a548574e58a69fe7860802d615",
            "969d0326e4c649d3bf480a254237ab8e",
            "4de6a05bc47441328634592ee12c12d2",
            "be0f09b97bb040a299d06f6773b638ff",
            "5c17754546904e3eb3b3a2e01bc14d02",
            "92b12c1ec11445f09b5b3b673ebed576",
            "bc09b46e1c844942be4e33c055274b65",
            "2b136352fe454db49316949983d8afe9",
            "35446bd68bca47b4a71479ca8c969603",
            "a003ac9c9f3d4af491447a2697689307",
            "3664d2d1d8824c23bc2724368dec2284",
            "9d190941051d4564a3536da001e45695",
            "ec8144f2296c41dca36f3610866af933",
            "0239c36dee0c4117af2fda59f59a970d",
            "e12fa2ea1e924a0a8f7e6e8eb11b4147",
            "3f9ecfb8da2b49a5901cdb5ddd3d322c",
            "7661f20e7f4d4766b1377646f86bdbdd",
            "addf26abfc234651b4511dc630835413",
            "27257ae00d6a42a9be5cdf4a067f6b61",
            "0c0485a3b5454fbc8fd852d770e28fe3",
            "7d8e3932c1494d90b7e186334fb0d5b6",
            "9bb49b17d0cf4b9781e852021c4ebc4b",
            "9a7094fed2af43a7a30dfda30a639a7e",
            "fc8c5ee1f0df488cb250540bcdd5216f",
            "6b4836fafac74bce948fc4ba2034c0e1",
            "7676c0c6d22b42ac9bcf9f681cfd12cc",
            "416d52832cd0401bae88377fcaf4c66f",
            "ea9b769f59b24315bf0f2b8855d56fb5",
            "ee6e3806094041a0a9fb3ccefc9415ff",
            "078efec8d309486e9f4140ebae5305d7",
            "b3440950bbc94abfbf4a4184705d6485",
            "64d69d89a9e446dd8bcd96b06e8200a0",
            "33ef8923393143e58df5a626af23a84f",
            "f6d8f2e1e8434d42999e99fa5cfaeea7",
            "c7040529ff1e493e813a8da187d4f6d4",
            "96e16d50b4b148b180eb46f5ed107538",
            "e0bf4e9453ae4c438ad1806a615b0bec",
            "179bbd822f9a4cbf914c75f26694fe94",
            "06e719aeabd3431991941482322dbe56",
            "1c9834e77cf142d9ab1144a8d007f1e9",
            "5c0a7cdce7b44a8bb316273840436119",
            "6e048751ceb74ad1bbfccbfbd1280370",
            "8bf12dd8d29d4809a2157f60fc16d682",
            "cc015a2f45e44a479eababda9a1bad71",
            "35c536718dca49cb87cdb6c938880074",
            "edd785be52314f4eb45387a9bd2e1208",
            "2847e47b0e2348d28c01122b9370f8a0",
            "8c592f9a4f994f558e5865975f1789c7",
            "055cdbf6c8f842849f2ed0f0a7e1ecc7",
            "4f8e22ac8f4245a3ac77dbae76de2faa",
            "adcb450edf75446b8a8424848bf99384",
            "e23e85a29b364f3dab6690040fc1cff4",
            "757722c814874fe490f089cbcee4fe32"
          ]
        },
        "outputId": "af41ba11-d6ba-472c-eb85-7c09632f6a4b"
      },
      "id": "JAtN1d5G21to",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Entrenando bert-base-uncased ...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f0ce8e0159b45daa0814bd5f3982e42"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a003ac9c9f3d4af491447a2697689307"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7d8e3932c1494d90b7e186334fb0d5b6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "64d69d89a9e446dd8bcd96b06e8200a0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8bf12dd8d29d4809a2157f60fc16d682"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-7e4bdc335bf6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Itera sobre cada modelo, entrena y evalúa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmdl_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mMODELS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmdl_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmdl_name\u001b[0m\u001b[0;34m]\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mmol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-ecc83f97df03>\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(model_name, train_data, val_data, test_data)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mfreeze_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreeze\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlast_n\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mUNFREEZE_PER_EPOCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;31m# Ejecuta una pasada por el conjunto de entrenamiento y obtiene métricas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_f1_macro\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_f1_micro\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;31m# Ejecuta una pasada por el conjunto de validación y obtiene métricas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0mval_f1_macro\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0mval_f1_micro\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mepoch_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"val\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-ecc83f97df03>\u001b[0m in \u001b[0;36mepoch_pass\u001b[0;34m(split)\u001b[0m\n\u001b[1;32m     65\u001b[0m                     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_embedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m                     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0;31m# Obtiene las etiquetas verdaderas del batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1673\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1675\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1676\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1677\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1142\u001b[0m         \u001b[0mhead_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1144\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1145\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    693\u001b[0m                 )\n\u001b[1;32m    694\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    696\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    586\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    522\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         )\n\u001b[0;32m--> 524\u001b[0;31m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# add attentions if we output them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/dropout.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1423\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"dropout probability has to be between 0 and 1, but got {p}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m     return (\n\u001b[0;32m-> 1425\u001b[0;31m         \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1426\u001b[0m     )\n\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sobre las métricas vale la pena precisar que según lo revisado en algunos *notebooks* públicos [⁸], se recomienda el uso de métricas \"macro\", es decir ponderadas por el peso de las clases, para una comparación justa entre modelos cuando hay minorías. Útil incluso con este *dataset* de la BBC (donde no hay desbalanceo significativo) para evidenciar si alguna categoría -“*tech*”, “*sport*”- se queda atrás."
      ],
      "metadata": {
        "id": "wFt2XQ0PcZIJ"
      },
      "id": "wFt2XQ0PcZIJ"
    },
    {
      "cell_type": "markdown",
      "id": "7JgtiyyfIyMM",
      "metadata": {
        "id": "7JgtiyyfIyMM"
      },
      "source": [
        "***\n",
        "\n",
        "\n",
        "# 5. Análisis de resultados y discusión"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se realizaron 3 corridas para calcular la media y desviación de cada métrica:\n",
        "\n",
        "| Modelo      | Métrica       | Promedio | Desviación | **`Tiempo total`** |\n",
        "|-------------|---------------|----------|------------|--------------------|\n",
        "| **BERT**    | **`Acc`**         | 0.981    | 0.005      | ≈ 1.5 *min*        |\n",
        "|             | **`Recall`**      | 0.981    | 0.004      |                    |\n",
        "|             | **`Precisión`**   | 0.980    | 0.005      |                    |\n",
        "|             | **`F1_macro`**    | 0.981    | 0.004      |                    |\n",
        "| **RoBERTa** | **`Acc`**         | 0.981    | 0.005      | ≈ 3.5 *min*        |\n",
        "|             | **`Recall`**      | 0.981    | 0.005      |                    |\n",
        "|             | **`Precisión`**   | 0.981    | 0.007      |                    |\n",
        "|             | **`F1_macro`**    | 0.981    | 0.006      |                    |"
      ],
      "metadata": {
        "id": "w_gK-vxu7m2G"
      },
      "id": "w_gK-vxu7m2G"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se puede observar que **RoBERTa** se desempeña de manera similar a **BERT** con *accuracy*, *recall* y *F1* promedio de 0.981 y y solo *precisión* es un poco diferente siendo de 0.980, con desviaciones entre 0.004 y 0.007. Esto hace pensar que no hay una ventaja particular de uno u otro modelo, sin embargo, el tiempo de entrenamiento **RoBERTa** es un poco mayor.\n",
        "\n",
        "Analizando el detalle por clase, ambos modelos muestran su punto débil en *business* y *politics* (*F1* = 0.950-0.970). Esto indica que ambas arquitecturas aún enfrentan desafíos con categorías que tienen similitud semantica."
      ],
      "metadata": {
        "id": "xnCpSQ0hs0Ri"
      },
      "id": "xnCpSQ0hs0Ri"
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación, se define la función **`predict_proba`** decorada con **`@torch.no_grad()`** lo que evita durante la ejecución que se construya o almacene el grafo de cómputo y también que se calculen gradientes para las operaciones, ahorrando memoria y evitando la sobrecarga del *Autograd*.\n",
        "\n",
        "Se ejecuta el modelo en modo evaluación para un lote de datos y devuelve las probabilidades de cada clase, esto nos ayudará más adelante para el análisis y evaluación de los modelos."
      ],
      "metadata": {
        "id": "6iOJO_3X5xw9"
      },
      "id": "6iOJO_3X5xw9"
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcula y devuelve las probabilidades de cada clase para un lote\n",
        "@torch.no_grad()\n",
        "def predict_proba(model, batch, *, device):\n",
        "    model.eval()\n",
        "    # Prepara inputs excluyendo campos no necesarios y moviéndolos a device\n",
        "    inputs = {k: v.to(device) for k, v in batch.items() if k not in [\"labels\", \"text\", \"idx\"]}\n",
        "    # Obtiene logits del modelo\n",
        "    logits = model(**inputs).logits\n",
        "    # Convierte logits a probabilidades vía softmax\n",
        "    probs  = F.softmax(logits, dim=-1)\n",
        "    return probs.cpu()"
      ],
      "metadata": {
        "id": "s6UVvASWngOQ"
      },
      "id": "s6UVvASWngOQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La función **`plot_model_diagnostics`** centraliza la visualización de las métricas de entrenamiento y la matriz de confusión en una sola figura, adaptando el número de filas de *subplots* según los datos disponibles."
      ],
      "metadata": {
        "id": "qJZ_NDzdjQ7G"
      },
      "id": "qJZ_NDzdjQ7G"
    },
    {
      "cell_type": "code",
      "source": [
        "# Diagnósticos de entrenamiento y matriz de confusión\n",
        "def plot_model_diagnostics( history: dict = None, model = None, test_loader = None, class_names = None, device = DEVICE, title: str = \"\") -> None:\n",
        "    # Valida cuántos subgráficos se necesitan según los argumentos recibidos\n",
        "    n_rows = 0\n",
        "    if history is not None:\n",
        "        n_rows += 2                # Loss y Accuracy\n",
        "    if model is not None and test_loader is not None and class_names is not None:\n",
        "        n_rows += 1                # Matriz de confusión\n",
        "    if n_rows == 0:\n",
        "        raise ValueError(\"Debes pasar `history` o (`model`, `test_loader`, `class_names`).\")\n",
        "\n",
        "    plt.figure(figsize=(7, 4 * n_rows))\n",
        "    plot_idx = 1\n",
        "\n",
        "    # Si hay historial, traza curvas de pérdida y accuracy\n",
        "    if history is not None:\n",
        "        epochs = range(1, len(history[\"train_loss\"]) + 1)\n",
        "\n",
        "        # Loss\n",
        "        plt.subplot(n_rows, 1, plot_idx)\n",
        "        plt.plot(epochs, history[\"train_loss\"], label=\"Train Loss\")\n",
        "        plt.plot(epochs, history[\"val_loss\"],   label=\"Val Loss\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.title(f\"{title} – Loss\")\n",
        "        plt.legend()\n",
        "        plot_idx += 1\n",
        "\n",
        "        # Accuracy\n",
        "        plt.subplot(n_rows, 1, plot_idx)\n",
        "        plt.plot(epochs, history[\"train_acc\"], label=\"Train Acc\")\n",
        "        plt.plot(epochs, history[\"val_acc\"],   label=\"Val Acc\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"Accuracy\")\n",
        "        plt.title(f\"{title} – Accuracy\")\n",
        "        plt.legend()\n",
        "        plot_idx += 1\n",
        "\n",
        "    #  Metriz de Confusión\n",
        "    if model is not None and test_loader is not None and class_names is not None:\n",
        "        model.eval()\n",
        "        y_true, y_pred = [], []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in test_loader:\n",
        "\n",
        "                labels = batch[\"labels\"]\n",
        "                inputs = {k: v.to(device) for k, v in batch.items() if k not in [\"labels\", \"text\", \"idx\"]}\n",
        "                # Validación específica par RoBERTa, ya que está en modo sequential\n",
        "                if isinstance(model, nn.Sequential):\n",
        "                    base_outputs = model[0](**inputs)\n",
        "                    cls_embedding = base_outputs.pooler_output\n",
        "                    logits = model[1:](cls_embedding)\n",
        "                else:\n",
        "                    outputs = model(**inputs)\n",
        "                    logits = outputs.logits\n",
        "                probs = F.softmax(logits, dim=-1)\n",
        "                preds = torch.argmax(probs, dim=1)\n",
        "\n",
        "                y_true.extend(labels.cpu().tolist())\n",
        "                y_pred.extend(preds.cpu().tolist())\n",
        "\n",
        "        cm = confusion_matrix(y_true, y_pred)\n",
        "        plt.subplot(n_rows, 1, plot_idx)\n",
        "        disp = ConfusionMatrixDisplay(cm, display_labels=class_names)\n",
        "        disp.plot(ax=plt.gca(), cmap=\"Blues\", colorbar=False)\n",
        "        plt.title(f\"{title} – Confusion Matrix\")\n",
        "        plt.xlabel(\"Predicted\")\n",
        "        plt.ylabel(\"True\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "uaauR7IpagRo"
      },
      "id": "uaauR7IpagRo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot para BERT\n",
        "plot_model_diagnostics( history     = histories[\"bert-base-uncased\"],\n",
        "                        model       = models[\"bert-base-uncased\"],\n",
        "                        test_loader = loaders[\"bert-base-uncased\"],\n",
        "                        class_names = le.classes_.tolist(),\n",
        "                        title       = \"BERT\")\n",
        "\n",
        "# Plot para RoBERTa\n",
        "plot_model_diagnostics( history     = histories[\"roberta-base\"],\n",
        "                        model       = models[\"roberta-base\"],\n",
        "                        test_loader = loaders[\"roberta-base\"],\n",
        "                        class_names = le.classes_.tolist(),\n",
        "                        title       = \"RoBERTa\")"
      ],
      "metadata": {
        "id": "KWYnrx5nGZtR"
      },
      "id": "KWYnrx5nGZtR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En la **época 1**, **RoBERTa** inicia con **`Val Loss`** ≈ 0.20 y **`Val Acc`** ≈ 0.96, mejor que **BERT** (**`Val Loss`** ≈ 0.30, **`Val Acc`** ≈ 0.95). Ambos convergen antes de la época 3 a **`Val Loss`** ≈ 0.03 y **`Val Acc`** ≈ 0.995. La matriz de confusión raticia posiblemente un similitud semántica entre las temáticas: política y negocios.\n"
      ],
      "metadata": {
        "id": "31FtpC80J-zG"
      },
      "id": "31FtpC80J-zG"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "***\n",
        "Ahora vamos a generar una vista de donde se están equivocando los modelos. Para ello, se define la función **`collect_fn_fp_examples`** que recorre el **`test_loader`** para generar las predicciones del **`model`** sin calcular gradientes y agrupa los textos, etiquetas reales y predichas en un **`DataFrame`**. Luego clasifica cada instancia como **FN** (*false negative*), **FP** (*false positive*) o **TP** (*true positive*) comparando **`true`** vs **`pred`**, y selecciona hasta **`k`** ejemplos de cada tipo por clase."
      ],
      "metadata": {
        "id": "9nQZGOzLJlaw"
      },
      "id": "9nQZGOzLJlaw"
    },
    {
      "cell_type": "code",
      "source": [
        "#  Ejemplos FN / FP por clase  (código simplificado)\n",
        "def collect_fn_fp_examples(model, test_loader, class_names, device=DEVICE, k: int = 5) -> pd.DataFrame:\n",
        "\n",
        "    # Establece el modelo en modo evaluación y prepara listas para textos y etiquetas\n",
        "    model.eval()\n",
        "    texts, y_true, y_pred = [], [], []\n",
        "    # Recorre el loader sin graficar gradientes, recopilando predicciones y textos\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            labels = batch[\"labels\"]\n",
        "            inputs = {k:v.to(device) for k,v in batch.items()\n",
        "                      if k not in [\"labels\",\"text\",\"idx\"]}\n",
        "            # Validación para RoBERTa\n",
        "            if isinstance(model, nn.Sequential):\n",
        "                base_outputs = model[0](**inputs)\n",
        "                cls_embedding = base_outputs.pooler_output\n",
        "                logits = model[1:](cls_embedding)\n",
        "            else:\n",
        "                outputs = model(**inputs)\n",
        "                logits = outputs.logits\n",
        "            probs  = F.softmax(logits, dim=-1)\n",
        "            preds  = torch.argmax(probs, dim=1)\n",
        "\n",
        "            y_true.extend(labels.cpu().tolist())\n",
        "            y_pred.extend(preds.cpu().tolist())\n",
        "            texts.extend(batch[\"text\"])\n",
        "    # Construye DataFrame base con texto\n",
        "    data = pd.DataFrame({\"text\": texts,\n",
        "                          \"true\": y_true,\n",
        "                          \"pred\": y_pred })\n",
        "    data[\"type\"] = \"UNDEF\"\n",
        "    # Para cada clase, etiqueta FN, FP y TP según compara true v\n",
        "    out_rows = []\n",
        "    rows=[]\n",
        "    for cls in range(len(class_names)):\n",
        "        data.loc[(data.true==cls) & (data.pred!=cls), \"type\"] = \"FN\"\n",
        "        data.loc[(data.pred==cls) & (data.true!=cls), \"type\"] = \"FP\"\n",
        "        data.loc[(data.true==cls) & (data.pred==cls), \"type\"] = \"TP\"\n",
        "        # Selecciona hasta k ejemplos de FN y FP\n",
        "        fn = data[(data.true==cls)&(data.pred!=cls)].head(k)\n",
        "        fp = data[(data.pred==cls)&(data.true!=cls)].head(k)\n",
        "        rows.extend(fn.assign(tipo=\"FN\", clase=class_names[cls]).to_dict(\"records\"))\n",
        "        rows.extend(fp.assign(tipo=\"FP\", clase=class_names[cls]).to_dict(\"records\"))\n",
        "    return pd.DataFrame(rows)"
      ],
      "metadata": {
        "id": "VrcMKrQPGt2J"
      },
      "id": "VrcMKrQPGt2J",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Corre primero la inferencia sobre test_loader\n",
        "data_err_bert = collect_fn_fp_examples(models[\"bert-base-uncased\"], loaders[\"bert-base-uncased\"],\n",
        "                                     le.classes_.tolist(), k=3)\n",
        "\n",
        "data_err_roberta = collect_fn_fp_examples( models[\"roberta-base\"], loaders[\"roberta-base\"],\n",
        "                                     le.classes_.tolist(), k=3)\n",
        "# Luego visualiza\n",
        "display(data_err_bert[[\"text\",\"true\",\"pred\",\"tipo\"]].head(10))\n",
        "display(data_err_roberta[[\"text\",\"true\",\"pred\",\"tipo\"]].head(10))"
      ],
      "metadata": {
        "id": "I80o-UdGG4SO"
      },
      "id": "I80o-UdGG4SO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En la última corrida, según la matriz de confusión, **RoBERTa** reduce los errores totales (3 vs 4) y mejora especialmente una posible equivación en la clase **`tech`**, aunque ambas arquitecturas siguen confundiendo más la categoría **`business`**. Se puede ver que potencialmente las noticias manejan un nivel de ambigüedad alto especialmente entre **`politics`**  y **`business`** . Por ejemplo en el caso del texto donde se menciona la agenda de Davos, el cual está categorizado como una noticia de negocios, pero claramente este evento puede llegar un alto tinte político.\n"
      ],
      "metadata": {
        "id": "MtU03ySJLJ_q"
      },
      "id": "MtU03ySJLJ_q"
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "Para finalizar esta sección de análisis de resultados, se sefine **`tsne_cls`** que extrae primero los embeddings de la posición [CLS] del modelo sobre el **`test_loader`** y, si ya existe un archivo en **`save_path`**, reutiliza la proyección en 2D para ahorrar **`time`**. De lo contrario, consolida todos los vectores CLS y sus etiquetas, calcula dinámicamente la *perplexity* en función del tamaño de muestra para garantizar una proyección estable en t-SNE, y guarda el resultado en disco. Por último, genera un gráfico dispersión en el que cada punto se colorea según su clase, permitiendo visualizar cómo el modelo separa las instancias en el espacio de embeddings."
      ],
      "metadata": {
        "id": "4-IWPpYxM8Cw"
      },
      "id": "4-IWPpYxM8Cw"
    },
    {
      "cell_type": "code",
      "source": [
        "# Proyecta embeddings [CLS] en 2D usando t-SNE\n",
        "def tsne_cls(model, test_loader, class_names, device, save_path = None):\n",
        "    # Obtener o cargar los vectores\n",
        "    if save_path and os.path.isfile(save_path):\n",
        "        print(f\"t-SNE cargado de {save_path}\")\n",
        "        data = np.load(save_path)\n",
        "        X_2d, y = data[:, :2], data[:, 2].astype(int)\n",
        "    else:\n",
        "         # Modo evaluación y recolección de embeddings CLS y etiquetas\n",
        "        model.eval()\n",
        "        reps, labels = [], []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in test_loader:\n",
        "                inputs = {k: v.to(device) for k, v in batch.items()\n",
        "                          if k not in [\"labels\", \"text\"]}\n",
        "                out = model(**inputs, output_hidden_states=True)\n",
        "                # Nuevamente verificación exclusivo para RoBERTa\n",
        "                if isinstance(model, nn.Sequential):\n",
        "                    base_outputs = model[0](**inputs, output_hidden_states=True)\n",
        "                    cls = base_outputs.hidden_states[-1][:, 0, :]\n",
        "                else:\n",
        "                    outputs = model(**inputs, output_hidden_states=True)\n",
        "                    cls = outputs.hidden_states[-1][:, 0, :]\n",
        "\n",
        "                reps.append(cls.cpu())\n",
        "                labels.extend(batch[\"labels\"].tolist())\n",
        "\n",
        "        X = torch.cat(reps).numpy()\n",
        "        y = np.array(labels)\n",
        "\n",
        "        # Ajusta perplexity en función de n_samples para estabilidad\n",
        "        n_samples   = X.shape[0]\n",
        "        perplexity  = max(5, min(40, n_samples // 10))\n",
        "        print(f\"→ n_samples={n_samples} | perplexity={perplexity}\")\n",
        "\n",
        "        tsne = TSNE(n_components=2, perplexity=perplexity, init=\"random\",\n",
        "            learning_rate=\"auto\", random_state= SEED, n_iter=1000)\n",
        "        X_2d = tsne.fit_transform(X)\n",
        "\n",
        "        # Guarda la proyección para futuras ejecuciones\n",
        "        if save_path:\n",
        "            np.save(save_path, np.c_[X_2d, y])\n",
        "            print(f\"Guardado en {save_path}\")\n",
        "\n",
        "    # Visualiza los puntos proyectados, uno por clase\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    for cls_id, cls_name in enumerate(class_names):\n",
        "        pts = X_2d[y == cls_id]\n",
        "        plt.scatter(pts[:, 0], pts[:, 1], alpha=0.6, label=cls_name, s=15)\n",
        "\n",
        "    plt.title(\"t-SNE de embeddings CLS\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "1jB6JKlLVoQG"
      },
      "id": "1jB6JKlLVoQG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tsne_cls(model       = models[\"bert-base-uncased\"] ,\n",
        "          test_loader = loaders[\"bert-base-uncased\"],\n",
        "          class_names = le.classes_.tolist(),\n",
        "          device      = DEVICE,\n",
        "          save_path   = Path(\"tsne_cls_bert.npy\"))"
      ],
      "metadata": {
        "id": "EWyptqdMhynP"
      },
      "id": "EWyptqdMhynP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tsne_cls(model       = models[\"roberta-base\"],\n",
        "          test_loader = loaders[\"roberta-base\"],\n",
        "          class_names = le.classes_.tolist(),\n",
        "          device      = DEVICE,\n",
        "          save_path   = Path(\"tsne_cls_roberta.npy\"))"
      ],
      "metadata": {
        "id": "Nd0y6qt7ZRqa"
      },
      "id": "Nd0y6qt7ZRqa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ambos modelos forman cinco *clusters* bien definidos para **business**, **entertainment**, **politics**, **sport** y **tech**. Con ambos modelos, se aprecia cierta sobre-posición entre **business** y **politics**, y un punto aislado de **tech** que sugiere mayor dispersión en esa clase. En el caso de **RoBERTa**, los *clusters* son más compactos y mejor separados; especialmente **politics** y **tech** muestran mayor cohesión interna. En ambos modelos, **sport** y **entertainment** quedan claramente aislados, y como se mencionó anteriomente a través de las diferentes corridas no se observan diferencias significativas entre ambos modelos."
      ],
      "metadata": {
        "id": "R9OsihFCOxI2"
      },
      "id": "R9OsihFCOxI2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "\n",
        "# 6. Conclusión\n",
        "\n",
        "El problema de clasificar artículos de la **BBC** en cinco categorías se abordó con modelos *transformer* —**`bert-base-uncased`** y **`roberta-base`**— entrenados con *fine-tuning* en GPU. Ambos convergieron  alrededor de las 2 épocas gracias a *early-stopping*, y obtienen métricas similares de desempeño pero **RoBERTa** tienen un tiempo de procesamiento ligeramente mayor.\n",
        "\n",
        "En ambos modelos se observa:\n",
        "\n",
        "* **Errores**: la clase **`politics`** concentró la mayoría de FN/FP.\n",
        "* **Confusion matrices**: **RoBERTa** logró 100 % en **`sport`** y **`tech`**, mostrando separabilidad casi perfecta.  \n",
        "* **t-SNE** de *embeddings* CLS: Ambos modelos generaron *clusters* compactos y con un nivel de solapamiento menor.\n",
        "\n",
        " Se recomienda, para este problema en particular adoptar **BERT** como modelo final por tiempo de procesamiento. Sin embargo, hay que priorizar la revisión de datos de **`politics`** / **`business`**  (posible ambigüedad temática) y para futuros trabajos considerar técnicas de *data augmentation* para afinar esa categoría."
      ],
      "metadata": {
        "id": "uDjo26cIk10k"
      },
      "id": "uDjo26cIk10k"
    },
    {
      "cell_type": "markdown",
      "id": "DwUWQIAE3O0o",
      "metadata": {
        "id": "DwUWQIAE3O0o"
      },
      "source": [
        "***\n",
        "\n",
        "\n",
        "# 7. Referencias"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BoLDjBS03xiQ",
      "metadata": {
        "id": "BoLDjBS03xiQ"
      },
      "source": [
        "[¹] **BERT: Pre-training of Deep Bidirectional Transformers for\n",
        "Language Understanding  Google AI Language**  \n",
        "Disponible en: [arxiv.org](https://arxiv.org/abs/1810.04805)\n",
        "\n",
        "[²] **Documents Classification using BERT on BBC Dataset**  \n",
        "Disponible en: [kaggle.com](https://www.kaggle.com/code/ouardasakram/documents-classification-using-bert-on-bbc-dataset)\n",
        "\n",
        "[³] **Transfer Learning: Why We Freeze and Unfreeze Model Layers**  \n",
        "Disponible en: [medium.com](https://medium.com/data-science-collective/transfer-learning-why-we-freeze-and-unfreeze-model-layers-0e0b8f9837ec)\n",
        "\n",
        "[⁴] **LayerNorm: A key component in parameter-efficient fine-tuning**  \n",
        "Disponible en: [arxiv.org](https://arxiv.org/html/2403.20284v1)\n",
        "\n",
        "[⁵] **Transformers: Optimization**  \n",
        "Disponible en: [huggingface.co](https://huggingface.co/docs/transformers/en/main_classes/optimizer_schedules?utm_source=chatgpt.com)\n",
        "\n",
        "[⁶] **Transformers: Auto Classes**  \n",
        "Disponible en: [huggingface.co](https://huggingface.co/docs/transformers/en/model_doc/auto?utm_source=chatgpt.com)\n",
        "\n",
        "[⁷] **RoBERTa: A Robustly Optimized BERT Pretraining Approach**  \n",
        "Disponible en: [arxiv.org](https://arxiv.org/abs/1907.11692)\n",
        "\n",
        "[⁸] **Bert-Classification-BBC-News**  \n",
        "Disponible en: [github.com](https://github.com/bymi15/Bert-Classification-BBC-News/blob/main/bert_classification_bbc_news.ipynb)\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0f0ce8e0159b45daa0814bd5f3982e42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5f16c71c7f7e44669633fd2d102c209f",
              "IPY_MODEL_4de8b2a548574e58a69fe7860802d615",
              "IPY_MODEL_969d0326e4c649d3bf480a254237ab8e"
            ],
            "layout": "IPY_MODEL_4de6a05bc47441328634592ee12c12d2"
          }
        },
        "5f16c71c7f7e44669633fd2d102c209f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be0f09b97bb040a299d06f6773b638ff",
            "placeholder": "​",
            "style": "IPY_MODEL_5c17754546904e3eb3b3a2e01bc14d02",
            "value": "config.json: 100%"
          }
        },
        "4de8b2a548574e58a69fe7860802d615": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92b12c1ec11445f09b5b3b673ebed576",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc09b46e1c844942be4e33c055274b65",
            "value": 570
          }
        },
        "969d0326e4c649d3bf480a254237ab8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b136352fe454db49316949983d8afe9",
            "placeholder": "​",
            "style": "IPY_MODEL_35446bd68bca47b4a71479ca8c969603",
            "value": " 570/570 [00:00&lt;00:00, 47.6kB/s]"
          }
        },
        "4de6a05bc47441328634592ee12c12d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be0f09b97bb040a299d06f6773b638ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c17754546904e3eb3b3a2e01bc14d02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92b12c1ec11445f09b5b3b673ebed576": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc09b46e1c844942be4e33c055274b65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2b136352fe454db49316949983d8afe9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35446bd68bca47b4a71479ca8c969603": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a003ac9c9f3d4af491447a2697689307": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3664d2d1d8824c23bc2724368dec2284",
              "IPY_MODEL_9d190941051d4564a3536da001e45695",
              "IPY_MODEL_ec8144f2296c41dca36f3610866af933"
            ],
            "layout": "IPY_MODEL_0239c36dee0c4117af2fda59f59a970d"
          }
        },
        "3664d2d1d8824c23bc2724368dec2284": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e12fa2ea1e924a0a8f7e6e8eb11b4147",
            "placeholder": "​",
            "style": "IPY_MODEL_3f9ecfb8da2b49a5901cdb5ddd3d322c",
            "value": "model.safetensors: 100%"
          }
        },
        "9d190941051d4564a3536da001e45695": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7661f20e7f4d4766b1377646f86bdbdd",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_addf26abfc234651b4511dc630835413",
            "value": 440449768
          }
        },
        "ec8144f2296c41dca36f3610866af933": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27257ae00d6a42a9be5cdf4a067f6b61",
            "placeholder": "​",
            "style": "IPY_MODEL_0c0485a3b5454fbc8fd852d770e28fe3",
            "value": " 440M/440M [00:02&lt;00:00, 205MB/s]"
          }
        },
        "0239c36dee0c4117af2fda59f59a970d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e12fa2ea1e924a0a8f7e6e8eb11b4147": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f9ecfb8da2b49a5901cdb5ddd3d322c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7661f20e7f4d4766b1377646f86bdbdd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "addf26abfc234651b4511dc630835413": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "27257ae00d6a42a9be5cdf4a067f6b61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c0485a3b5454fbc8fd852d770e28fe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d8e3932c1494d90b7e186334fb0d5b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9bb49b17d0cf4b9781e852021c4ebc4b",
              "IPY_MODEL_9a7094fed2af43a7a30dfda30a639a7e",
              "IPY_MODEL_fc8c5ee1f0df488cb250540bcdd5216f"
            ],
            "layout": "IPY_MODEL_6b4836fafac74bce948fc4ba2034c0e1"
          }
        },
        "9bb49b17d0cf4b9781e852021c4ebc4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7676c0c6d22b42ac9bcf9f681cfd12cc",
            "placeholder": "​",
            "style": "IPY_MODEL_416d52832cd0401bae88377fcaf4c66f",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "9a7094fed2af43a7a30dfda30a639a7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea9b769f59b24315bf0f2b8855d56fb5",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ee6e3806094041a0a9fb3ccefc9415ff",
            "value": 48
          }
        },
        "fc8c5ee1f0df488cb250540bcdd5216f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_078efec8d309486e9f4140ebae5305d7",
            "placeholder": "​",
            "style": "IPY_MODEL_b3440950bbc94abfbf4a4184705d6485",
            "value": " 48.0/48.0 [00:00&lt;00:00, 4.27kB/s]"
          }
        },
        "6b4836fafac74bce948fc4ba2034c0e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7676c0c6d22b42ac9bcf9f681cfd12cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "416d52832cd0401bae88377fcaf4c66f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea9b769f59b24315bf0f2b8855d56fb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee6e3806094041a0a9fb3ccefc9415ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "078efec8d309486e9f4140ebae5305d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3440950bbc94abfbf4a4184705d6485": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64d69d89a9e446dd8bcd96b06e8200a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_33ef8923393143e58df5a626af23a84f",
              "IPY_MODEL_f6d8f2e1e8434d42999e99fa5cfaeea7",
              "IPY_MODEL_c7040529ff1e493e813a8da187d4f6d4"
            ],
            "layout": "IPY_MODEL_96e16d50b4b148b180eb46f5ed107538"
          }
        },
        "33ef8923393143e58df5a626af23a84f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0bf4e9453ae4c438ad1806a615b0bec",
            "placeholder": "​",
            "style": "IPY_MODEL_179bbd822f9a4cbf914c75f26694fe94",
            "value": "vocab.txt: 100%"
          }
        },
        "f6d8f2e1e8434d42999e99fa5cfaeea7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06e719aeabd3431991941482322dbe56",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1c9834e77cf142d9ab1144a8d007f1e9",
            "value": 231508
          }
        },
        "c7040529ff1e493e813a8da187d4f6d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c0a7cdce7b44a8bb316273840436119",
            "placeholder": "​",
            "style": "IPY_MODEL_6e048751ceb74ad1bbfccbfbd1280370",
            "value": " 232k/232k [00:00&lt;00:00, 4.39MB/s]"
          }
        },
        "96e16d50b4b148b180eb46f5ed107538": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0bf4e9453ae4c438ad1806a615b0bec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "179bbd822f9a4cbf914c75f26694fe94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06e719aeabd3431991941482322dbe56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c9834e77cf142d9ab1144a8d007f1e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5c0a7cdce7b44a8bb316273840436119": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e048751ceb74ad1bbfccbfbd1280370": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8bf12dd8d29d4809a2157f60fc16d682": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cc015a2f45e44a479eababda9a1bad71",
              "IPY_MODEL_35c536718dca49cb87cdb6c938880074",
              "IPY_MODEL_edd785be52314f4eb45387a9bd2e1208"
            ],
            "layout": "IPY_MODEL_2847e47b0e2348d28c01122b9370f8a0"
          }
        },
        "cc015a2f45e44a479eababda9a1bad71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c592f9a4f994f558e5865975f1789c7",
            "placeholder": "​",
            "style": "IPY_MODEL_055cdbf6c8f842849f2ed0f0a7e1ecc7",
            "value": "tokenizer.json: 100%"
          }
        },
        "35c536718dca49cb87cdb6c938880074": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f8e22ac8f4245a3ac77dbae76de2faa",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_adcb450edf75446b8a8424848bf99384",
            "value": 466062
          }
        },
        "edd785be52314f4eb45387a9bd2e1208": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e23e85a29b364f3dab6690040fc1cff4",
            "placeholder": "​",
            "style": "IPY_MODEL_757722c814874fe490f089cbcee4fe32",
            "value": " 466k/466k [00:00&lt;00:00, 11.5MB/s]"
          }
        },
        "2847e47b0e2348d28c01122b9370f8a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c592f9a4f994f558e5865975f1789c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "055cdbf6c8f842849f2ed0f0a7e1ecc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f8e22ac8f4245a3ac77dbae76de2faa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adcb450edf75446b8a8424848bf99384": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e23e85a29b364f3dab6690040fc1cff4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "757722c814874fe490f089cbcee4fe32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}