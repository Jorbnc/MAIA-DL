{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jorbnc/MAIA-DL/blob/master/Mini_Proyecto_3_DL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oa_MJEGQ6jTi",
      "metadata": {
        "id": "oa_MJEGQ6jTi"
      },
      "source": [
        "<img\n",
        "  src=\"data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iVVRGLTgiPz4KPHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjYxIiB3aWR0aD0iMjIwIiB2ZXJzaW9uPSIxLjEiPgogPHBhdGggc3R5bGU9ImZpbGw6I2ZkZjIxYyIgZD0ibSAxMDAuNzcxLDI1OS45NjkgYyAtMjIuMDM1LC0yLjIyMSAtMzAuMzg3LC00LjgxNyAtNDMuNzEwLC04Ljc3MSAtNC4zOTAsLTEuMzAzIC0xMC40OTUsLTIuNzg1IC0xMy41MjksLTMuNzgxIEMgMjUuNjczLDI0MS41NTcgNy41NzksMjI3LjIyNyAyLjQ0NywyMTYuMjA5IDAuNTMwLDIxMi4wOTQgMC41MTYsMjExLjQzNSAwLjI3MSwxMTMuMDAyIDAuMDc3LDMzLjkwNCAwLjI2MSwxMy43NDYgMS4xOTEsMTIuOTgyIDMuNjMwLDEwLjk4MSA1MC4wNzcsNC40NjkgNzguMjgwLDIuMTczIGMgMzAuMTEyLC0yLjQ1MCA1NS4zODAsLTEuNTY2IDkzLjcwMCwzLjI3NyAxNy4xMTAsMi4xNjIgNDMuNzUzLDYuMTYyIDQ2LjIxNyw2LjkzOCAxLjU0NywwLjQ4NiAxLjYxNSw1LjQ5NiAxLjM3OCwxMDAuNTU0IGwgLTAuMjQ4LDEwMC4wNDEgLTIuNzI0LDUuMzg0IGMgLTMuMzc5LDYuNjc3IC05LjIzMiwxMi4wMzQgLTE5LjcxNywxOC4wNDEgLTI5LjU4NSwxNi45NTIgLTY3Ljc2MCwyNi40MTIgLTk2LjExNCwyMy41NTMgeiIvPgogPHBhdGggc3R5bGU9ImZpbGw6IzAwMDAwMCIgZD0ibSAxMTIuMDY5LDI2MC4yNzMgYyAtMC4zODIsLTAuNDAwIC0wLjY5NiwtNS4wODAgLTAuNjk2LC0xMC40MDAgMCwwIC0xLjIxNSwtNi42ODUgMCwtOS42NzEgMC45MTMsLTIuMjQyIDUuMDc1LC01LjE5OCA1LjA3NSwtNS4xOTggMy41MDUsLTMuNTg5IDUuODM2LC03LjA4MiA3LjUzNSwtMTEuMjg3IDIuNzczLC02Ljg2NiAyLjc4NywwLjEwMyAtMC4xMTYsLTU4Ljk5MSAtMS45NTEsLTM5LjcyOCAtNC40NDcsLTYyLjUwNCAtOC44ODQsLTgxLjA5NCAtMS41MDcsLTYuMzE2IC0zLjc0MSwtMTguMzYyIC00Ljk2MiwtMjYuNzY4IC0yLjA4MCwtMTQuMzIwIC0yLjY4OCwtMTYuOTQ2IC0zLjY5MiwtMTUuOTQzIC0xLjI2NSwxLjI2NSAtNS41NDAsMzIuMzcxIC0xNC44NDcsMTA4LjAyOSAtMi4yNTksMTguMzc2IC00LjM5MCwzNC4xNDAgLTQuNzM0LDM1LjAzMSAtMC44NjAsMi4yMjcgLTIuMTEzLDEuMjIzIC0xLjcwMSwtMS4zNjQgMC4xODQsLTEuMTYwIDEuNTg3LC0yNC4yNDUgMy4xMTcsLTUxLjMwMCA0LjIzOSwtNzQuOTY0IDYuMTEzLC04OS4wMjYgMTQuMzQ3LC0xMDcuNjQ0IDEuMjQ1LC0yLjgxNiAyLjc2MywtNS4xMjEgMy4zNzMsLTUuMTIxIDMuMzMxLDAgOC45NDYsMTIuMjY3IDEzLjU5MiwyOS42OTkgMTAuMjAxLDM4LjI3MiA5Ljk2MywzNy4xOTkgMTQuNjc0LDY2LjM1OSAxLjIzNiw3LjY1NyAzLjA4NSwxOC41MTYgNC4xMDYsMjQuMTMxIDMuMDExLDE2LjU1MiAyLjQ2OSw1OS4wMjkgLTAuOTcyLDc2LjI4MiAtMC43MjIsMy42MjAgLTIuMjE0LDYuMzg1IC02LjAwOSwxMS4xMzcgLTYuNzI2LDguNDE5IC04Ljc2NCwxMi45MzkgLTguNzY0LDE5LjQzMyAwLDMuOTA1IDAuNDEzLDUuNTU4IDEuNjI0LDYuNDc3IDIuMzk5LDEuODIwIDEzLjYxMiwxLjU4NSAyMC4xODYsLTAuNDI1IDE1LjMyNCwtNC42ODcgMzcuNDUyLC0xNi43MjQgNDQuMDg2LC0yMy45ODIgNy45MTksLTguNjY1IDcuNDIzLC0xLjUzNSA3LjQyMywtMTA2LjY4OCAwLC04OC4yNzUgLTAuMDg0LC05My4xMjMgLTEuNjUxLC05My45NjEgLTIuMDQ5LC0xLjA5NyAtMjIuMzg1LC02Ljc5OSAtMzEuNzYwLC04LjkwNiAtNDIuNzY3LC05LjYxNyAtNjguMzMyLC05LjI5OCAtMTEwLjQ0OCwxLjM2OCAtNy45MTIsMi4wMDMgLTE3LjMwOSw0LjU5OCAtMjAuODgyLDUuNzY3IGwgLTYuNDk2LDIuMTIzIC0wLjI0MCw5Mi44MDkgYyAtMC4yMDcsODAuMzE1IC0wLjA0OCw5My44MzggMS4xODcsMTAwLjQ1MyAxLjYxMyw4LjYzNiAzLjc4OCwxNC4yODUgNy4wNjUsMTguMzQ5IDQuOTYxLDYuMTUyIDQuOTQ5LDYuMTMxIDMuMDIyLDUuNDE2IEMgMzEuNDI5LDI0Mi44MzQgMjAuNTgzLDIzNi41NTEgMTUuMTM5LDIzMi41MjEgOC43ODEsMjI3LjgxNSAyLjc1NywyMjAuNDkxIDEuMDU0LDIxNS4zOTcgMC4yOTMsMjEzLjExOSAwLDE4NC40MjUgMCwxMTIuMTYyIEwgMCwxMi4wODEgMi4wODcsMTEuNjI0IEMgMjUuOTk3LDYuMzkwIDg1LjQxOCwtMC4wMzkgMTA5LjQ5NiwxLjg0ODY0NjdlLTQgMTI1LjIxNywwLjAyNSAxNTcuNjczLDIuNjMwIDE3OS4xMjUsNS41ODggYyAxNi45MzYsMi4zMzUgMzguNjE3LDUuODMwIDM5LjcwMiw2LjQwMSAwLjk1MSwwLjQ5OSAxLjE4MiwyMC40ODUgMS4xNzEsMTAxLjExMSAtMC4wMTMsOTguMzE3IC0wLjA1MywxMDAuNTc4IC0xLjg2MSwxMDQuNjY4IC00LjA4Nyw5LjI0MiAtMTEuMzI4LDE1LjIzNiAtMjkuNDc5LDI0LjQwMyAtMjEuMDM2LDEwLjYyNSAtNDQuODI2LDE3LjI1NyAtNjUuNjg0LDE4LjMxMiAtNS42MTUsMC4yODQgLTEwLjUyMiwwLjE4OCAtMTAuOTA1LC0wLjIxMSB6Ii8+Cjwvc3ZnPgo=\"\n",
        "  alt=\"Logo Universidad de los Andes\"\n",
        "  width=\"120\"\n",
        "/>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sl89pic17iPU",
      "metadata": {
        "id": "sl89pic17iPU"
      },
      "source": [
        "<style>\n",
        "@import url('https://fonts.googleapis.com/css2?family=Latin+Modern+Roman:wght@400;700&display=swap');\n",
        "\n",
        "body, p, h1, h2, h3, h4, h5, h6, li {\n",
        "  font-family: 'Latin Modern Roman', serif;\n",
        "}\n",
        "code, pre {\n",
        "  font-family: 'Fira Mono', monospace;\n",
        "}\n",
        "</style>\n",
        "\n",
        "***\n",
        "\n",
        "# **Miniproyecto 3 -T√©cnicas de *Deep Learning*- Clasificaci√≥n Multi-Clase de Art√≠culos de Noticias de la BBC Usando Transformers**\n",
        "\n",
        "## **Descripci√≥n del Problema**\n",
        "\n",
        "En este miniproyecto se plantea la **clasificaci√≥n multi-clase** de art√≠culos de noticias de la BBC aprovechando la capacidad de los modelos *transformer* para capturar relaciones contextuales complejas. Cada art√≠culo puede pertenecer a una de varias categor√≠as tem√°ticas (e.g., *Sport, Business, Politics, Tech*).\n",
        "\n",
        "## **Objetivo**\n",
        "\n",
        "Desarrollar e implementar dos modelos de clasificaci√≥n multi-clase basado en transformers ( **BERT** y **RoBERTa**) que, tras un preprocesamiento del texto y la adaptaci√≥n de la capa de salida, sea capaz de predecir con alta exactitud, precisi√≥n, *recall* y *F1-score* las categor√≠as de los art√≠culos de la BBC."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SiCS5j-HAbCB",
      "metadata": {
        "id": "SiCS5j-HAbCB"
      },
      "source": [
        "***\n",
        "\n",
        "**Este proyecto es realizado por Andr√©s Felipe √ëungo y Jordan Bryan N√∫√±ez Campos para entrega el 20 de mayo de 2025.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8VqTMx7TYgjH",
      "metadata": {
        "id": "8VqTMx7TYgjH"
      },
      "source": [
        "\n",
        "***\n",
        "# **√çndice**\n",
        "\n",
        "El *notebook* aborda el proyecto con la siguiente estructura:\n",
        "\n",
        "| üîπ | Secci√≥n        |\n",
        "|----|----------------|\n",
        "| 1Ô∏è‚É£. | **Instalaci√≥n y carga de librer√≠as** |\n",
        "| 1Ô∏è‚É£.1Ô∏è‚É£. | **Configuraciones adicionales** |\n",
        "| 2Ô∏è‚É£. | **An√°lisis exploratorio y preparaci√≥n de los datos**       |\n",
        "| 2Ô∏è‚É£.1Ô∏è‚É£. | **Carga y estad√≠sticas generales**       |\n",
        "| 2Ô∏è‚É£.2Ô∏è‚É£. | **Limpieza de los datos**       |\n",
        "| 3Ô∏è‚É£. | **Definici√≥n de *pipelines* de procesamiento**          |\n",
        "| 3Ô∏è‚É£.1Ô∏è‚É£. | **Pipeline de preprocesamiento**   |\n",
        "| 4Ô∏è‚É£. | **Preparaci√≥n para el desarrollo de los modelos**   |\n",
        "| 4Ô∏è‚É£.1Ô∏è‚É£. | **Partici√≥n y funciones de apoyo para los DataLoaders**   |\n",
        "| 4Ô∏è‚É£.2Ô∏è‚É£. | **Funci√≥n de entrenamiento y preparaci√≥n para la evaluaci√≥n**   |\n",
        "| 4Ô∏è‚É£.3Ô∏è‚É£. | **Entrenamiento, validaci√≥n y prueba**   |\n",
        "| 5Ô∏è‚É£. | **An√°lisis de resultados y discusi√≥n**   |\n",
        "| 6Ô∏è‚É£. | **Conclusi√≥n**   |\n",
        "| 7Ô∏è‚É£. | **Referencias**   |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cyVuwlHB_W3",
      "metadata": {
        "id": "2cyVuwlHB_W3"
      },
      "source": [
        "***\n",
        "\n",
        "# 1. Instalaci√≥n y carga de librer√≠as"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Antes de proceder con la carga de las librer√≠as, se instalan para efectos de un correcto funcionamiento en ambientes como *Coursera* o *Google Colab*: **`kagglehub langdetect matplotlib scikit-learn plotly`**.\n"
      ],
      "metadata": {
        "id": "DkjBiBB5rU6t"
      },
      "id": "DkjBiBB5rU6t"
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalaci√≥n de librer√≠as necesarias para correr en Colab/Coursera\n",
        "!pip -q install kagglehub langdetect matplotlib scikit-learn plotly"
      ],
      "metadata": {
        "id": "l26426jMLCxE",
        "outputId": "d2150cb8-5ffc-46e3-a4b2-efc42ca4f7f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "l26426jMLCxE",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este bloque se importan utilidades de sistema como **`os`**, **`random`**, **`gc`**, **`time`** y **`Path`**, junto con las librer√≠as de datos **`numpy`** y **`pandas`**, la descarga de *datasets* v√≠a **`kagglehub`**, limpieza de texto con **`detect`** y **`re`**, preprocesamiento y partici√≥n con scikit-learn (**`LabelEncoder`**, **`train_test_split`**), herramientas de *transformers* (**`AutoTokenizer`**, **`AutoModelForSequenceClassification`**, **`AutoModel`**), componentes de PyTorch (**`Dataset`**, **`DataLoader`**, **`AdamW`**), m√©tricas de evaluaci√≥n (**`accuracy_score`**, **`f1_score`**, **`classification_report`**), y reducci√≥n de dimensi√≥n y visualizaci√≥n con  **`TSNE`**, **`matplotlib`** y **`ConfusionMatrixDisplay`**.  "
      ],
      "metadata": {
        "id": "2q7l4Q6t4ITO"
      },
      "id": "2q7l4Q6t4ITO"
    },
    {
      "cell_type": "code",
      "source": [
        "# Librer√≠as comunes\n",
        "import os, random, gc, time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "# Descarga de datasets y de embeddings\n",
        "import kagglehub\n",
        "\n",
        "# Limpieza y preparaci√≥n de los textos\n",
        "from langdetect import detect\n",
        "import re\n",
        "\n",
        "# Preprocesamiento y herramientas de PLN\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from transformers import get_linear_schedule_with_warmup,AutoTokenizer, AutoModelForSequenceClassification, AutoModel\n",
        "\n",
        "# Modelado\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "\n",
        "# Evaluaci√≥n\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
        "\n",
        "# Librer√≠as para visualizaciones\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from IPython.display import display"
      ],
      "metadata": {
        "id": "osjmTJMvtxua"
      },
      "id": "osjmTJMvtxua",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este bloque se establecen los **par√°metros globales** que controlan el entrenamiento y la configuraci√≥n del modelo: **`TEXT_COL`** y **`LABEL_COL`** definen las columnas de texto y categor√≠a en el *DataFrame*, **`MAX_LEN`** fija la longitud m√°xima de secuencia para la tokenizaci√≥n, **`BATCH_SIZE`**, **`EPOCHS`** y **`PATIENCE`** regulan el tama√±o de los lotes, el n√∫mero de iteraciones y la detenci√≥n temprana, mientras que **`UNFREEZE_PER_EPOCH`** determina cu√°ntas capas del transformador se liberan progresivamente, **`DROPOUT`** que nos permitir√° incluir un *dropout* extra a los *transformers* y **`SEED`** asegura que los experimentos sean reproducibles.  \n",
        "\n",
        "El valor de la mayor√≠a de estos par√°metros globales se toman a partir del Anexo A.3 del *paper* original de **BERT** [¬π] (se utilizan estos mismos valores para **RoBERTa** no necesariamente porque sean \"√≥ptimos\", sino m√°s por efectos comparativos), donde se sugiere:\n",
        "\n",
        "*   **Batch size:** 16, 32\n",
        "*   **Learning rate (Adam):** 5e-5, 3e-5, 2e-5\n",
        "*   **Number of epochs:** 2, 3, 4"
      ],
      "metadata": {
        "id": "OeOXzQpOa-Lz"
      },
      "id": "OeOXzQpOa-Lz"
    },
    {
      "cell_type": "code",
      "source": [
        "# Par√°metros globales de configuraci√≥n del modelo\n",
        "TEXT_COL   = \"text\"  # nombre de la columna de los art√≠culos\n",
        "LABEL_COL  = \"labels\" # nombre de la columna con la categor√≠a\n",
        "MAX_LEN    = 256  # longitud m√°xima de cada secuencia de tokens\n",
        "BATCH_SIZE = 16   # n√∫mero de muestras por lote de entrenamiento\n",
        "EPOCHS     = 4\n",
        "LEARNING_RATE = 2e-5\n",
        "PATIENCE   = 2    # Usado para early stopping\n",
        "UNFREEZE_PER_EPOCH = 2   # n√∫mero de capas del modelo a descongelar\n",
        "DROPOUT = 0.3\n",
        "SEED = 13"
      ],
      "metadata": {
        "id": "afgVSw4d1AIw"
      },
      "id": "afgVSw4d1AIw",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1. Configuraciones adicionales\n",
        "\n",
        "Con el siguiente bloque se detecta si el entorno dispone de GPU y selecciona el **`device`** apropiado para PyTorch.  \n",
        "\n",
        "Primero se llama a **`is_available()`**, que devuelve *True* si se ha asignado una GPU CUDA al *runtime* de Colab. Seg√∫n el resultado se imprime un mensaje informativo. Posteriormente, se construye el objeto **`device`**, que ser√° pasado a la red y a los tensores de entrada para que se ubiquen en la GPU cuando sea posible. Por √∫ltimo se muestra en pantalla el dispositivo elegido."
      ],
      "metadata": {
        "id": "uOceAejmVjqF"
      },
      "id": "uOceAejmVjqF"
    },
    {
      "cell_type": "code",
      "source": [
        "# Devuelve asignaci√≥n de GPU\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Dispositivo activo ‚Üí {DEVICE}\")"
      ],
      "metadata": {
        "id": "LksJ95qEPWVr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df11fd1c-bbd9-4ad5-f474-3a18a875d755"
      },
      "id": "LksJ95qEPWVr",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dispositivo activo ‚Üí cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adicionalmente se ocultan avisos para mantener limpias algunas salidas del *notebook*; y se imprimen las versiones de un conjunto de librer√≠as clave ( **`numpy`**, **`pandas`**, **`torch`**, **`scikit-learn`**, **`kagglehub`**, **`matplotlib`**). Mostrar estas versiones al inicio del *notebook* facilita la reproducibilidad y ayuda a depurar posibles conflictos de dependencias."
      ],
      "metadata": {
        "id": "pfXxKk09Vulp"
      },
      "id": "pfXxKk09Vulp"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "LSwlUgjUjtR_",
      "metadata": {
        "id": "LSwlUgjUjtR_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96b5e47e-6419-4100-8623-909e9a99ef98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numpy :  2.0.2\n",
            "pandas :  2.2.2\n",
            "torch :  2.6.0+cu124\n",
            "scikit-learn :  1.6.1\n",
            "kagglehub :  0.3.12\n",
            "matplotlib :  3.10.0\n",
            "langdetect :  1.0.9\n",
            "transformers :  4.51.3\n",
            "plotly :  5.24.1\n"
          ]
        }
      ],
      "source": [
        "# Ignorar las warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Versiones utilizadas\n",
        "from importlib.metadata import version\n",
        "librerias = [\"numpy\",\"pandas\",\"torch\",\"scikit-learn\", \"kagglehub\",\n",
        "            \"matplotlib\", \"langdetect\",\"transformers\",\"plotly\"]\n",
        "for library in librerias:\n",
        "  print(library, \": \", version(library))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este bloque se fija la reproducibilidad del experimento asignando la semilla **`SEED`** a los generadores de n√∫meros aleatorios de **Python**, **`NumPy`** y **`PyTorch`** (CPU y GPU), y configurando **`CUDNN`** para que opere de forma determinista y sin usar su *benchmark* autom√°tico, garantizando resultados consistentes en cada ejecuci√≥n a costa de un posible descenso en el rendimiento."
      ],
      "metadata": {
        "id": "ok4F_5E1njTi"
      },
      "id": "ok4F_5E1njTi"
    },
    {
      "cell_type": "code",
      "source": [
        "# Definici√≥n del random state y seeds\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "torch.backends.cudnn.deterministic = True  # Forzar comportamiento determinista en CUDNN\n",
        "torch.backends.cudnn.benchmark = False     # Desactivar optimizaciones no deterministas en CUDNN"
      ],
      "metadata": {
        "id": "xdgcOt7gznvJ"
      },
      "id": "xdgcOt7gznvJ",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "qK311OLFzPep",
      "metadata": {
        "id": "qK311OLFzPep"
      },
      "source": [
        "***\n",
        "\n",
        "# 2. An√°lisis exploratorio y preparaci√≥n de los datos\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "## 2.1. Carga y estad√≠sticas generales"
      ],
      "metadata": {
        "id": "4KxKy7H1eID-"
      },
      "id": "4KxKy7H1eID-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se descarga el conjunto de datos de rese√±as de noticias de la BBC de **`kagglehub`**. La funci√≥n **`dataset_download`** guarda los archivos de manera local y devuelve la ruta absoluta, que se almacena en **`path`** y se muestra en pantalla mediante **`print`** para confirmar d√≥nde quedaron los datos."
      ],
      "metadata": {
        "id": "yHwealvATakn"
      },
      "id": "yHwealvATakn"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "K4yOzyWKJbov",
      "metadata": {
        "id": "K4yOzyWKJbov",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db3f3be6-52db-446b-98ce-e5c9f38453b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datos descargados en: /kaggle/input/bbc-articles-dataset\n",
            "Dataset descargado en: /kaggle/input/bbc-articles-dataset/bbc_news_text_complexity_summarization.csv\n",
            "Filas totales: 2127\n"
          ]
        }
      ],
      "source": [
        "# Descarga del conjunto de datos\n",
        "path = kagglehub.dataset_download(\"jacopoferretti/bbc-articles-dataset\")\n",
        "print(\"Datos descargados en:\", path)\n",
        "\n",
        "CSV_PATH = os.path.join(path, \"bbc_news_text_complexity_summarization.csv\")\n",
        "print(f\"Dataset descargado en: {CSV_PATH}\")\n",
        "\n",
        "# Verificar n√∫mero de datos\n",
        "data_raw = pd.read_csv(CSV_PATH)\n",
        "print(\"Filas totales:\", len(data_raw))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CNfurSnbmf79",
      "metadata": {
        "id": "CNfurSnbmf79"
      },
      "source": [
        "***\n",
        "\n",
        "## 2.2. Limpieza de los datos\n",
        "\n",
        "En estas secci√≥n identificamos y corregimos:\n",
        "\n",
        "* Valores faltantes\n",
        "* Textos duplicados\n",
        "* Textos en otros idiomas distintos al ingl√©s"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verificamos que **no** hay datos faltantes o en \"N/A\", ni tampoco datos duplicados."
      ],
      "metadata": {
        "id": "_QbNFIVK9Y9J"
      },
      "id": "_QbNFIVK9Y9J"
    },
    {
      "cell_type": "code",
      "source": [
        "# Validaci√≥n de datos faltantes\n",
        "data_raw.isna().sum()"
      ],
      "metadata": {
        "id": "2r0P2t_Ysjbq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "outputId": "58ce19ab-f5be-4678-dc66-d540bfea424a"
      },
      "id": "2r0P2t_Ysjbq",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text                            0\n",
              "labels                          0\n",
              "no_sentences                    0\n",
              "Flesch Reading Ease Score       0\n",
              "Dale-Chall Readability Score    0\n",
              "text_rank_summary               0\n",
              "lsa_summary                     0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>text</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>labels</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>no_sentences</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Flesch Reading Ease Score</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dale-Chall Readability Score</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>text_rank_summary</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lsa_summary</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Validaci√≥n de duplicados\n",
        "data_raw.duplicated().sum()"
      ],
      "metadata": {
        "id": "m3IgmRbWskuE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05ee01e9-9b90-451f-bdd9-98f63a2860ea"
      },
      "id": "m3IgmRbWskuE",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int64(0)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copia de los datos por seguridad\n",
        "data = data_raw.copy()"
      ],
      "metadata": {
        "id": "fJETbmzSRX7o"
      },
      "id": "fJETbmzSRX7o",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se utiliza **`LabelEncoder`** para transformar la columna de categor√≠as de texto en una nueva columna **`label_id`** con valores num√©ricos, se calcula el total de clases √∫nicas a trav√©s de **`NUM_LABELS`**, y se generan dos diccionarios (**`id2label`** y **`label2id`**) que permiten convertir de manera sencilla entre los identificadores num√©ricos y las etiquetas de texto durante las fases de entrenamiento e inferencia."
      ],
      "metadata": {
        "id": "P80Y-mWg_2rm"
      },
      "id": "P80Y-mWg_2rm"
    },
    {
      "cell_type": "code",
      "source": [
        "# Codificaci√≥n de etiquetas\n",
        "le = LabelEncoder()\n",
        "data[\"label_id\"] = le.fit_transform(data[LABEL_COL])\n",
        "\n",
        "NUM_LABELS = len(le.classes_)# N√∫mero total de clases √∫nicas\n",
        "print(f\"Num√©ro de clases √∫nicas {NUM_LABELS}\")\n",
        "\n",
        "# Mapea cada ID a su etiqueta original\n",
        "id2label = {i: lbl for i, lbl in enumerate(le.classes_)}\n",
        "# Mapea cada etiqueta a su ID correspondiente\n",
        "label2id = {v: k for k, v in id2label.items()}\n",
        "\n",
        "class_names = le.classes_.tolist()\n",
        "print(f\"Clases en el dataset {class_names}\")\n"
      ],
      "metadata": {
        "id": "XU6qAVkrjUo3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e117f456-6a64-4317-bfef-b5ad24264b3b"
      },
      "id": "XU6qAVkrjUo3",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num√©ro de clases √∫nicas 5\n",
            "Clases en el dataset ['business', 'entertainment', 'politics', 'sport', 'tech']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tambi√©n se verifica el n√∫mero promedio de palabras de los art√≠culos noticiosos, con el objetivo de conocer cu√°n extensos pueden llegar a ser, esto tambi√©n nos da una mejor idea de la ventana de atenci√≥n que pueden llegar a tener nuestros *transformers*"
      ],
      "metadata": {
        "id": "X0XZFalUXVQl"
      },
      "id": "X0XZFalUXVQl"
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular n√∫mero de palabras por texto\n",
        "word_counts = data[TEXT_COL].str.split().str.len()\n",
        "\n",
        "# Calcular promedio\n",
        "avg_word_count = word_counts.mean()\n",
        "print(f\"El n√∫mero promedio de palabras por texto es: {avg_word_count:.2f}\")"
      ],
      "metadata": {
        "id": "nztVsxAvXUa8"
      },
      "id": "nztVsxAvXUa8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se gr√°fica con la funci√≥n **`plot_class_distribution`** la distribuci√≥n del *dataset* en las diferentes clases. En principio, no se observa un desbalance de los datos significativo. Sin embargo, tampoco se puede afirmar que el conjunto de datos est√° completamente balanceado, observando por ejemplo, una leve sub-representaci√≥n de la clase entretenimiento y *tech*. Raz√≥n por la cual, puede cobrar sentido m√°s adelante entrenar el modelo con balanceo sencillo de las clases y observar m√©tricas de evaluaci√≥n ponderadas por clase (\"macro\") para poder tener un an√°lisis adecuado."
      ],
      "metadata": {
        "id": "quPKwoSZB_Hw"
      },
      "id": "quPKwoSZB_Hw"
    },
    {
      "cell_type": "code",
      "source": [
        "# Mapeo de la distribuci√≥n de las clases\n",
        "def plot_class_distribution(data: pd.DataFrame, label_col: str = \"label_id\", class_names: List[str] = None) -> None:\n",
        "\n",
        "    # Preparar datos\n",
        "    counts = data[label_col].value_counts().sort_index()\n",
        "    labels = class_names if class_names is not None else counts.index.astype(str)\n",
        "\n",
        "    # Normalizamos los valores para mapearlos a la paleta\n",
        "    norm = plt.Normalize(counts.min(), counts.max())\n",
        "    colors = cm.viridis(norm(counts.values))\n",
        "\n",
        "    # Crear la figura y barras\n",
        "    fig, ax = plt.subplots(figsize=(8, 5))\n",
        "    bars = ax.bar(labels, counts.values, color=colors)\n",
        "\n",
        "    # Etiquetas de ejes y t√≠tulo\n",
        "    ax.set_xlabel(\"Clase\")\n",
        "    ax.set_ylabel(\"N√∫mero de art√≠culos\")\n",
        "    ax.set_title(\"Distribuci√≥n de clases en el dataset\")\n",
        "\n",
        "    # Rotar etiquetas del eje x de forma segura\n",
        "    ax.set_xticks(range(len(labels)))\n",
        "    ax.set_xticklabels(labels, rotation=45, ha=\"right\")\n",
        "\n",
        "    # Etiquetas a las barras\n",
        "    ax.bar_label(bars, labels=[f\"{c:,}\" for c in counts.values], padding=3)\n",
        "\n",
        "    fig.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_class_distribution(data, class_names = class_names )"
      ],
      "metadata": {
        "id": "1TQpLnbwan5r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "outputId": "5d9b9384-c0fa-46cc-e81b-ff24ee4099f7"
      },
      "id": "1TQpLnbwan5r",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqu√≠ se define **`detectar_idiomas`**, que emplea la funci√≥n **`detect`** de **`langdetect`** para identificar el idioma de cada texto en la columna elegida. Si la detecci√≥n falla o el texto est√° vac√≠o, se conserva 'desconocido'. Tras procesar todos los textos, se filtran los que no sean ingl√©s e imprime hasta cinco ejemplos con su √≠ndice y fragmento para revisi√≥n, devolviendo finalmente el DataFrame actualizado con la nueva informaci√≥n de idioma. Corroboramos que todos los textos se encuentran en ingl√©s."
      ],
      "metadata": {
        "id": "LHdSWxhRDoR8"
      },
      "id": "LHdSWxhRDoR8"
    },
    {
      "cell_type": "code",
      "source": [
        "# Validaci√≥n de los idiomas en los art√≠culos\n",
        "def detectar_idiomas(data: pd.DataFrame, col_texto: str = 'text') -> pd.DataFrame:\n",
        "    # Inicializamos con 'desconocido'\n",
        "    data['idioma'] = 'desconocido'\n",
        "\n",
        "    # Funci√≥n auxiliar segura\n",
        "    def _detectar(texto):\n",
        "        if isinstance(texto, str) and texto.strip():\n",
        "            try:\n",
        "                return detect(texto)\n",
        "            except Exception:\n",
        "                return 'desconocido'\n",
        "        return 'desconocido'\n",
        "\n",
        "    # Aplicamos detecci√≥n\n",
        "    data['idioma'] = data[col_texto].apply(_detectar)\n",
        "\n",
        "    # Filtramos los que no son ingl√©s\n",
        "    mask = data['idioma'] != 'en'\n",
        "    idx_no_en = data[mask].index\n",
        "\n",
        "    if len(idx_no_en) > 0:\n",
        "        print(f\"Se encontraron {len(idx_no_en)} textos NO en ingl√©s (ejemplos):\")\n",
        "        # Mostramos hasta 5 ejemplos (si es que se encuentran)\n",
        "        for i in idx_no_en[:5]:\n",
        "            print(f\" ‚Ä¢ √çndice {i}: [{data.at[i,'idioma']}] {data.at[i,col_texto][:100]}...\")\n",
        "    else:\n",
        "        print(\"Todos los textos est√°n detectados como ingl√©s.\")\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "_WQ5tiJps-bO"
      },
      "id": "_WQ5tiJps-bO",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = detectar_idiomas(data, col_texto='text')"
      ],
      "metadata": {
        "id": "DpTn9HpSW6V9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49467786-4989-4477-8dd7-69748d4a45b1"
      },
      "id": "DpTn9HpSW6V9",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Todos los textos est√°n detectados como ingl√©s.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_ypyorGqwmRl",
      "metadata": {
        "id": "_ypyorGqwmRl"
      },
      "source": [
        "***\n",
        "\n",
        "# 3. Definici√≥n de *pipelines* de procesamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4370a607-ad43-4c5d-bddd-1a9370469409",
      "metadata": {
        "id": "4370a607-ad43-4c5d-bddd-1a9370469409"
      },
      "source": [
        "***\n",
        "\n",
        "## 3.1. *Pipeline* de preprocesamiento\n",
        "\n",
        "En esta ocasi√≥n el *pipeline* de preprocesamiento ser√° muy corto, precisamente por el modo en el que los tokenizadores de los *transformers* operan. La funci√≥n **`clean_text`** normaliza cada cadena eliminando espacios redundantes con una expresi√≥n regular, descartando car√°cteres que no sean letras, n√∫meros o puntuaci√≥n b√°sica. Se cree que esta es la mejor aproximaci√≥n para el problema ya que car√°cteres especiales (a excepci√≥n de las importantes en el ingl√©s como el ap√≥strofe) o emojis no creemos que puedan aportar a la clasificaci√≥n de estos textos. Tambi√©n la tokenizaci√≥n m√°s adelante se va encargar de pasos como el *lowercasting* por lo que esta limpieza inicial no es necesario. Posteriormente, se recorre el conjunto de columnas **`text`**, **`text_rank_summary`** y **`lsa_summary`** en **`data`**, convirtiendo sus valores en texto y aplicando esta limpieza para estandarizar todos los contenidos antes de procesarlos."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Limpieza b√°sica\n",
        "def clean_text(text: str) -> str:\n",
        "    # colapsa m√∫ltiples espacios en blanco\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "    # elimina caracteres no alfanum√©ricos ni puntuaci√≥n b√°sica\n",
        "    text = re.sub(r\"[^\\w.,;:!?()¬ø¬°' ]+\", \"\", text)\n",
        "    # elimina espacios al inicio y al final\n",
        "    return text.strip()\n",
        "\n",
        "for col in (\"text\", \"text_rank_summary\", \"lsa_summary\"):\n",
        "    if col in data.columns:\n",
        "        data[col] = data[col].astype(str).apply(clean_text)"
      ],
      "metadata": {
        "id": "tK_D4XVsnk6c"
      },
      "id": "tK_D4XVsnk6c",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "G6-RrjwuxYEw",
      "metadata": {
        "id": "G6-RrjwuxYEw"
      },
      "source": [
        "***\n",
        "\n",
        "# 4. Preparaci√≥n para el desarrollo de los modelos\n",
        "\n",
        "En esta ocasi√≥n no es necesario definir una clase para crear cada una de las capas de las redes neuronales a entrenar. Como se ha visto en clase, los *transformers* pre-entrenados como **BERT** ya vienen casi listos con toda la etapa de preparaci√≥n de los datos y la estructura de la red. Por tal motivo, en esta secci√≥n se dejan las funciones y clases definidas para preparar los √∫ltimos detalles de los datos antes de pasarlos por cada uno de los modelos y generamos la funci√≥n de entrenamiento. Adicionalmente, se incluy√© una funci√≥n que nos permitir√° complementar la red con una capa de normalizaci√≥n para estabilizar la salida, explicar√° esto con mayor profundidad m√°s adelante."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "## 4.1. Partici√≥n y funciones de apoyo para los *DataLoaders*\n",
        "\n",
        "Se usa **`train_test_split`** para separar el DataFrame **`data`** en **`train_data`** y **`test_data`** (10% para *test*, 10% para validaci√≥n y 80% para entrenamiento) manteniendo la distribuci√≥n de **`label_id`** mediante estratificaci√≥n (y que as√≠ las particiones reflejen el leve \"desequilibrio\" de clases).\n",
        "\n",
        "Hay que recordar que el conjunto de datos es de tan solo **2.127** datos. Un poco peque√±o para lo que solemos estar acostumbrados, raz√≥n por la cu√°l no podemos tomar un conjunto *test* o de validaci√≥n muy grandes ya que nos quedamos facilmente sin una cantidad representativa de datos de entrenamiento.\n"
      ],
      "metadata": {
        "id": "YbTzASG6GdSr"
      },
      "id": "YbTzASG6GdSr"
    },
    {
      "cell_type": "code",
      "source": [
        "# Divisi√≥n en train_data y test_data\n",
        "train_data, test_data = train_test_split(data, test_size=0.10, stratify=data[\"label_id\"], random_state=SEED)\n",
        "# A partir de train_data se extrae un conjunto de validaci√≥n val_data\n",
        "train_data, val_data = train_test_split(train_data, test_size=0.10, stratify=train_data[\"label_id\"], random_state=SEED)\n",
        "# Mostramos el tama√±o de cada partici√≥n\n",
        "print(\"Tama√±os ‚Äì¬†Train / Val / Test:\", len(train_data), len(val_data), len(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6QJGsVGvoIK",
        "outputId": "d178e45c-de02-4bfc-c6fa-966511430e4f"
      },
      "id": "L6QJGsVGvoIK",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tama√±os ‚Äì¬†Train / Val / Test: 1722 192 213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se toma como base la preparaci√≥n de los datos usada en algunos *notebooks* p√∫blicos [¬≤] y se crea la clase **`BBCDataset`**, que se hereda de **`Dataset`** de PyTorch y \"encapsula\" el procesamiento de cada muestra. Se guarda listas de textos y etiquetas junto con el **`tokenizer`**, la longitud m√°xima **`max_len`** y la opci√≥n **`return_idx`**; **`__len__`** devuelve la cantidad de ejemplos disponibles; **`__getitem__`** se hace la preparaci√≥n de secuencias mediante  la tokenizaci√≥n del texto, con truncamiento y *padding* a tama√±o fijo (el tokenizador que se va a usar, **`AutoTokenizer`**, ya hace estos pasos por nosotros raz√≥n por la cu√°l no se hizo en la etapa de pre-procesamiento), se elimina la dimensi√≥n extra resultante, a√±ade la etiqueta como tensor (**`return_tensors=\"pt\"`**) y retorna tambi√©n el texto original, incluyendo opcionalmente el √≠ndice de la muestra para an√°lisis posteriores, lo que facilita la integraci√≥n directa con un *DataLoader* y mantiene trazabilidad de los ejemplos durante el entrenamiento y la evaluaci√≥n.\n",
        "\n",
        "En conjunto, este bloque es el ‚Äúpreparador de secuencias‚Äù: convierte texto crudo en el lote de tensores que el *encoder transformer* necesita para producir *embeddings* y, finalmente, la predicci√≥n de clase."
      ],
      "metadata": {
        "id": "wqy-xlwJ2zMS"
      },
      "id": "wqy-xlwJ2zMS"
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataset para la clasificaci√≥n de noticias de la BBC\n",
        "class BBCDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_len, *, return_idx: bool = False):\n",
        "        self.texts  = data[TEXT_COL].tolist() # lista de textos crudos\n",
        "        self.labels = data[\"label_id\"].tolist()  # lista de IDs de etiqueta\n",
        "        self.tok    = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.return_idx = return_idx\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts) # n√∫mero total de muestras\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        enc = self.tok(self.texts[idx], truncation=True, padding=\"max_length\", max_length=self.max_len, return_tensors=\"pt\")\n",
        "        item = {k: v.squeeze(0) for k, v in enc.items()}  # elimina la dimensi√≥n batch=1\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long) # convierte etiqueta a tensor\n",
        "        item[\"text\"] = self.texts[idx] # conserva el texto original\n",
        "        if self.return_idx:\n",
        "            item[\"idx\"] = torch.tensor(idx)   # incluye √≠ndice si se solicita\n",
        "        return item"
      ],
      "metadata": {
        "id": "zfp-stYtEt71"
      },
      "id": "zfp-stYtEt71",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este *collate* primero se extrae y guarda los textos crudos antes de apilar todos los tensores que el modelo requiere, y luego los reincorpora junto con los tensores resultantes de **`input_ids`**, **`attention_mask`**, **`labels`** y, si est√° presente, **`idx`**. As√≠, cada lote entregado al modelo incluye tanto los datos num√©ricos optimizados para el entrenamiento como el texto original y los √≠ndices necesarios para cualquier an√°lisis o diagn√≥stico posterior dentro del proyecto (secci√≥n de \"**5. An√°lisis de resultados y discusi√≥n**\")."
      ],
      "metadata": {
        "id": "Is0sZqHd0LAB"
      },
      "id": "Is0sZqHd0LAB"
    },
    {
      "cell_type": "code",
      "source": [
        "# Adem√°s de apilar los tensores, se preserve el texto original y el √≠ndice de cada muestra\n",
        "def collate_with_text(batch):\n",
        "    # Extrae y elimina temporalmente el campo text\n",
        "    texts  = [b.pop(\"text\") for b in batch]\n",
        "\n",
        "    # Apila labels con dtype y forma correctos\n",
        "    labels = torch.stack([b[\"labels\"] for b in batch]).long()\n",
        "    # Validaci√≥n de dimensionalidad\n",
        "    if labels.dim() == 2:\n",
        "        labels = labels.squeeze(1)\n",
        "    # Apila el resto de tensores\n",
        "    keys = [k for k in batch[0].keys() if k != \"labels\"]\n",
        "    out  = {k: torch.stack([b[k] for b in batch]) for k in keys}\n",
        "    out[\"labels\"] = labels\n",
        "    out[\"text\"] = texts\n",
        "    # Si cada muestra trae un √≠ndice idx, lo apila tambi√©n\n",
        "    if \"idx\" in batch[0]:\n",
        "        out[\"idx\"] = torch.stack([b[\"idx\"] for b in batch])\n",
        "    return out"
      ],
      "metadata": {
        "id": "zPBwOr5LvZBH"
      },
      "id": "zPBwOr5LvZBH",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**`Make_loader`** construye y devuelve un *DataLoader* configurado para el dataset BBC."
      ],
      "metadata": {
        "id": "93fcx-bj1RLZ"
      },
      "id": "93fcx-bj1RLZ"
    },
    {
      "cell_type": "code",
      "source": [
        " # Crea y retorna el DataLoader configurado\n",
        "def make_loader(data, tokenizer, split, batch_size, max_len, return_idx=False, num_workers=2):\n",
        "    # Instancia el dataset personalizado BBCDataset\n",
        "    ds = BBCDataset(data, tokenizer, max_len, return_idx=return_idx)\n",
        "    return DataLoader(ds, batch_size=batch_size, shuffle=(split==\"train\"), num_workers=num_workers, pin_memory=True, collate_fn=collate_with_text)"
      ],
      "metadata": {
        "id": "3bPJ2rdm_v46"
      },
      "id": "3bPJ2rdm_v46",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La t√©cnica acontinuaci√≥n ya se hab√≠a aplicado anteriormente en el **Miniproyecto 2** [¬≥]. Esta permite *congelar* o *descongelar* gradientes de capas del *encoder* de un modelo, lo cual ayuda a (i) conservar caracter√≠sticas generales √∫tiles, (ii) adaptar con seguridad las capas superiores y (iii) mejorar la precisi√≥n sin sobre-ajustar, sobre todo en conjuntos de datos peque√±os o medianos."
      ],
      "metadata": {
        "id": "T4sMR5EA4ldE"
      },
      "id": "T4sMR5EA4ldE"
    },
    {
      "cell_type": "code",
      "source": [
        "# Congela/descongela capas del encoder\n",
        "def freeze_layers(model, freeze: bool = True, last_n: int = None) -> None:\n",
        "    # Hay modelos donde el encoder vive en .transformer, se revisa\n",
        "    if isinstance(model, nn.Sequential):\n",
        "        # RobertaModel est√° en model[0]\n",
        "        encoder = model[0].encoder\n",
        "    else:\n",
        "        encoder = getattr(model.base_model, \"encoder\", None) \\\n",
        "                  or getattr(model.base_model, \"transformer\", None)\n",
        "\n",
        "    if encoder is None:\n",
        "        # Si no tiene encoder expl√≠cito, congelamos todo el base_model\n",
        "        base_model = model[0] if isinstance(model, nn.Sequential) else model.base_model\n",
        "        for p in base_model.parameters():\n",
        "            p.requires_grad = not freeze\n",
        "        return\n",
        "\n",
        "    # Congela/libera todas las capas del encoder\n",
        "    for param in encoder.parameters():\n",
        "        param.requires_grad = not freeze\n",
        "\n",
        "    # Libera espec√≠ficamente las √∫ltimas last_n capas (si se especifica)\n",
        "    if last_n is not None and last_n > 0:\n",
        "        layers = encoder.layer if hasattr(encoder, 'layer') else encoder.layers\n",
        "        for layer in layers[-last_n:]:\n",
        "            for param in layer.parameters():\n",
        "                param.requires_grad = True"
      ],
      "metadata": {
        "id": "qudFCuoD0Gw_"
      },
      "id": "qudFCuoD0Gw_",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para hacer *fine-tuning* a los modelos que se correr√°n se define la siguiente funci√≥n que incorpora una capa de normalizaci√≥n, basado en un *paper* donde se mejora con esta t√©cnica a **RoBERTa** [‚Å¥]. Aplicar esta funci√≥n antes de la capa lineal logra estabilizar la distribuci√≥n de activaciones que recibe la cabeza de la red, reduciendo el *internal covariate shift*, un problema conocido en el mundo de los *transformers* por generar variaci√≥n continua en la distribuci√≥n de las activaciones internas de una red neuronal durante el entrenamiento. Esta reducci√≥n, suele traducirse en convergencias m√°s estables y entre +0.3 y +0.7 pp de mejora en *accuracy* [‚Å¥]. Esto se logra mediante un *dropout* extra (en este caso de  0.3) , lo que mitiga el *overfitting* cuando el conjunto de entrenamiento es peque√±o (como lo es este caso); a diferencia del *dropout* interno (p ‚âà 0.1) que **BERT**/**RoBERTa** implementa. Finalmente, se inicializa la nueva capa con *Xavier* + bias = 0   (tambi√©n llamado **Glorot init**) [‚Å¥] lo cual asigna pesos con varianza ajustada, manteniendo la magnitud de los gradientes a trav√©s de la red y evitando desplazamientos iniciales hacia clases concretas, lo que acelera las primeras √©pocas de *fine-tuning*."
      ],
      "metadata": {
        "id": "c-o_--ASKSM4"
      },
      "id": "c-o_--ASKSM4"
    },
    {
      "cell_type": "code",
      "source": [
        "# Sustituye la cabeza de clasificaci√≥n por una capa de normalizaci√≥n\n",
        "def add_norm_dropout_head(model, dropout_p: float = 0.3):\n",
        "\n",
        "    hidden = model.config.hidden_size\n",
        "    num_lbl = model.config.num_labels\n",
        "\n",
        "    new_head = nn.Sequential(nn.LayerNorm(hidden, eps=model.config.layer_norm_eps),\n",
        "                              nn.Dropout(dropout_p), nn.Linear(hidden, num_lbl))\n",
        "\n",
        "    # Inicializaci√≥n recomendada\n",
        "    nn.init.xavier_uniform_(new_head[-1].weight)\n",
        "    nn.init.constant_(new_head[-1].bias, 0.)\n",
        "\n",
        "    # Algunos modelos exponen la cabeza como .classifier, otros como .score\n",
        "    if hasattr(model, \"classifier\"):\n",
        "        # Manejar estructura especial de RoBERTa por defecto\n",
        "        if isinstance(model.classifier, nn.Sequential):\n",
        "            model.classifier = new_head\n",
        "        else:\n",
        "            model.classifier = new_head\n",
        "\n",
        "    elif hasattr(model, \"score\"):\n",
        "        model.score = new_head\n",
        "    else:\n",
        "        raise AttributeError(\"No se encontr√≥ la cabeza de clasificaci√≥n\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "1y1KOsCMKK_V"
      },
      "id": "1y1KOsCMKK_V",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "## 4.2. Funci√≥n de entrenamiento y preparaci√≥n para la evaluaci√≥n\n",
        "\n",
        "Esta funci√≥n es tal vez la m√°s importante de todo el *notebook*, donde se basa todo el *fine-tuning* y evaluaci√≥n del modelo. Empieza cargando el tokenizador y el modelo. Note que en este proyecto se est√° probando en un mismo *pipeline* a **BERT** y para **RoBERTa**, por lo que es necesario cargar ambos *items* con **`AutoTokenizer`** y **`AutoModelForSequenceClassification`**. M√°s adelante se habla un poco m√°s del tokenizador. Adicionalmente, con el objetivo de \"jugar\" con el modelo se a√±ade la capa de normalizaci√≥n extra que como objetivo tendr√° mejorar la generalizaci√≥n de ambos modelos.\n",
        "\n",
        "A continuaci√≥n, se calcula los pesos de clase y  se crean los *DataLoaders* llamando a **`make_loader`** para los *splits* **`train`**,**`val`** y **`test`**. Adicionalmente, se configura el optimizador **`AdamW`** junto al *scheduler*. En esta ocasi√≥n se usa **`AdamW`**, que permite aplicar un *weight decay* para evitar sobre-ajuste. Adicionalmente, se usa el *scheduler* que gestiona din√°micamente la tasa de aprendizaje a lo largo del entrenamiento siguiendo dos fases: 1. *Warm-up* -incremento gradual en los primeros pasos y 2. Decaimiento lineal -descenso de forma lineal hasta 0 [‚Åµ]. Finalmente se define la funci√≥n de p√©rdida con **`CrossEntropyLoss`**.\n",
        "\n",
        "En cada *epoch* se recorre un *split* completo para acumular p√©rdidas, predicciones y etiquetas verdaderas y as√≠ calcular m√©tricas como *accuracy* y *F1*. Esto se hace descongelando gradualmente capas. Adicionalmente se aplica *early stopping* y guardando el mejor modelo en **`best_path`**. Tras el entrenamiento, se carga el mejor estado con **`torch.load`** y desde esta etapa se eval√∫a en *test* generando precisi√≥n, *recall* y el *classification_report*. Se limpia memoria con **`gc.collect()`** y **`torch.cuda.empty_cache()`**, y finalmente retorna un diccionario con todas las m√©tricas, el modelo entrenado, el **`tokenizer`**, el **`test_loader`** y el historial de entrenamiento.\n",
        "\n",
        "Ahora se explica con m√°s detalle AutoTokenizer [‚Å∂]:\n",
        "\n",
        "**`AutoTokenizer`** simplifica y unifica el preprocesamiento de texto para distintos modelos (**BERT**, **RoBERTa**, **DistilBERT,** etc.), detectando autom√°ticamente la clase de *tokenizer* adecuada y eliminando la necesidad de m√∫ltiples importaciones o bloques *if/else*. Durante la tokenizaci√≥n, descompone el texto y a√±ade los special tokens ([CLS], [SEP]), convierte cada *token* a su *input_id*, crea la *attention_mask* para diferenciar texto real de *padding*, y aplica truncado y relleno hasta MAX_LEN para generar lotes uniformes."
      ],
      "metadata": {
        "id": "JzIcaKUzJHl8"
      },
      "id": "JzIcaKUzJHl8"
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(model_name: str, train_data, val_data, test_data):\n",
        "    print(f\"\\nEntrenando {model_name} ...\")\n",
        "\n",
        "    start = time.time()\n",
        "    # Tokenizer + modelo\n",
        "    if \"roberta\" in model_name:\n",
        "        # Carga RobertaModel sin cabeza de clasificaci√≥n original\n",
        "        base_model = AutoModel.from_pretrained(model_name).to(DEVICE)\n",
        "\n",
        "        # Crea cabeza propia desde cero\n",
        "        model = nn.Sequential( base_model, nn.LayerNorm(base_model.config.hidden_size),\n",
        "            nn.Dropout(DROPOUT), nn.Linear(base_model.config.hidden_size, NUM_LABELS)).to(DEVICE)\n",
        "\n",
        "    else:\n",
        "        # Para BERT usamos modelo est√°ndar con cabeza simple\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=NUM_LABELS, id2label=id2label,\n",
        "            label2id=label2id).to(DEVICE)\n",
        "        model = add_norm_dropout_head(model, dropout_p=DROPOUT).to(DEVICE)\n",
        "    #Tokenizador, igual para ambas\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "    # Congelar encoder completo y luego liberar gradualmente\n",
        "    freeze_layers(model)\n",
        "\n",
        "    # Pesos de clase balanceados\n",
        "    class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.arange(NUM_LABELS), y=train_data[\"label_id\"])\n",
        "    class_weights = torch.tensor(class_weights, dtype=torch.float32, device=DEVICE)\n",
        "\n",
        "    # DataLoaders\n",
        "    loaders = {\n",
        "        \"train\": make_loader(train_data, tokenizer, \"train\", BATCH_SIZE, MAX_LEN),\n",
        "        \"val\":   make_loader(val_data,   tokenizer, \"val\",   BATCH_SIZE, MAX_LEN),\n",
        "        \"test\":  make_loader(test_data,  tokenizer, \"test\",  BATCH_SIZE, MAX_LEN),\n",
        "    }\n",
        "\n",
        "    # Optimizador & scheduler\n",
        "    total_steps = len(loaders[\"train\"]) * EPOCHS\n",
        "    optimizer   = AdamW(model.parameters(), lr= LEARNING_RATE, weight_decay=1e-2)\n",
        "    scheduler   = get_linear_schedule_with_warmup(optimizer,\n",
        "                                                  #6%  de los pasos para hacer warm-up\n",
        "                                                  num_warmup_steps=int(0.06 * total_steps),\n",
        "                                                  num_training_steps=total_steps)\n",
        "    # Criterio de p√©rdida\n",
        "    criterion   = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "    best_f1, patience_cnt = 0.0, 0\n",
        "    best_path = f\"best_{model_name.split('-')[0]}_bbc.pt\"\n",
        "\n",
        "    # Funci√≥n interna para una pasada por un split\n",
        "    def epoch_pass(split):\n",
        "        # Determina si se trata de entrenamiento (\"train\") o evaluaci√≥n (\"val\" o \"test\")\n",
        "        is_train = split == \"train\"\n",
        "        model.train() if is_train else model.eval()\n",
        "        losses, preds_all, trues_all = [], [], []\n",
        "        # Recorre los lotes del DataLoader correspondiente al split actual\n",
        "        for batch in loaders[split]:\n",
        "            batch = {k: (v.to(DEVICE) if torch.is_tensor(v) else v) for k,v in batch.items()}\n",
        "            with torch.set_grad_enabled(is_train):\n",
        "                inputs = {k: v for k, v in batch.items() if k not in [\"labels\", \"text\", \"idx\"]}\n",
        "                # Llama expl√≠citamente RobertaModel\n",
        "                if \"roberta\" in model_name:\n",
        "                    base_outputs = model[0](**inputs)\n",
        "                    cls_embedding = base_outputs.pooler_output\n",
        "                    # pasa por LayerNorm, Dropout y Linear\n",
        "                    logits = model[1:](cls_embedding)\n",
        "                else:\n",
        "                    outputs = model(**inputs)\n",
        "                    logits = outputs.logits\n",
        "                # Obtiene las etiquetas verdaderas del batch\n",
        "                labels = batch[\"labels\"].to(DEVICE)\n",
        "                labels = labels.long()\n",
        "                # Calcula la p√©rdida entre las predicciones\n",
        "                loss = criterion(logits, labels)\n",
        "                 # Si se est√° entrenando, realiza el paso de optimizaci√≥n\n",
        "                if is_train:\n",
        "                    loss.backward()\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "                    optimizer.step(); scheduler.step(); optimizer.zero_grad()\n",
        "            # Acumular m√©tricas\n",
        "            losses.append(loss.item())\n",
        "            preds_all.extend(logits.argmax(dim=-1).cpu().numpy())\n",
        "            trues_all.extend(labels.cpu().numpy())\n",
        "\n",
        "        acc = accuracy_score(trues_all, preds_all)\n",
        "        f1_macro = f1_score(trues_all, preds_all, average=\"macro\", zero_division=0)\n",
        "        f1_micro = f1_score(trues_all, preds_all, average=\"micro\", zero_division=0)\n",
        "        return np.mean(losses), acc, f1_macro, f1_micro\n",
        "\n",
        "    # Bucle de entrenamiento con early stopping\n",
        "    hist = {k: [] for k in [\"epoch\",\"train_loss\",\"val_loss\",\n",
        "                        \"train_acc\",\"val_acc\",\"train_f1\",\"val_f1\"]}\n",
        "    for epoch in range(1, EPOCHS + 1):\n",
        "       # Descongela progresivamente las √∫ltimas capas\n",
        "        freeze_layers(model, freeze=False,last_n=epoch * UNFREEZE_PER_EPOCH)\n",
        "        # Ejecuta una pasada por el conjunto de entrenamiento y obtiene m√©tricas\n",
        "        train_loss, train_acc, train_f1_macro, train_f1_micro = epoch_pass(\"train\")\n",
        "        # Ejecuta una pasada por el conjunto de validaci√≥n y obtiene m√©tricas\n",
        "        val_loss,   val_acc,   val_f1_macro,   val_f1_micro   = epoch_pass(\"val\")\n",
        "        hist[\"epoch\"].append(epoch)\n",
        "        hist[\"train_loss\"].append(train_loss); hist[\"val_loss\"].append(val_loss)\n",
        "        hist[\"train_acc\"].append(train_acc);   hist[\"val_acc\"].append(val_acc)\n",
        "        hist[\"train_f1\"].append(train_f1_macro);    hist[\"val_f1\"].append(val_f1_macro)\n",
        "        # Imprime resumen de la √©poca: p√©rdida y F1/accuracy de validaci√≥n\n",
        "        print(f\"Ep {epoch:02d}: \\tTL {train_loss:.4f} / VL {val_loss:.4f} | \"\n",
        "              f\"F1_macro {val_f1_macro:.3f}  Acc {val_acc:.3f}\")\n",
        "         # Si se mejora el mejor F1 de validaci√≥n, guarda el modelo y reinicia paciencia\n",
        "        if val_f1_macro > best_f1:\n",
        "            best_f1 = val_f1_macro\n",
        "            patience_cnt = 0\n",
        "            torch.save(model.state_dict(), best_path)\n",
        "        else:\n",
        "            # Si no mejora, incrementa el contador de paciencia\n",
        "            patience_cnt += 1\n",
        "             # Si se alcanza el umbral de paciencia, detiene el entrenamiento\n",
        "            if patience_cnt == PATIENCE:\n",
        "                print(\"Early stopping¬†‚ÜØ\\n\")\n",
        "                break\n",
        "\n",
        "    #  Evaluaci√≥n sobre test\n",
        "    model.load_state_dict(torch.load(best_path))\n",
        "    test_loss, test_acc, test_f1_macro, test_f1_micro = epoch_pass(\"test\")\n",
        "\n",
        "    y_true, y_pred = [], []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in loaders[\"test\"]:\n",
        "            batch = {k: (v.to(DEVICE) if torch.is_tensor(v) else v) for k,v in batch.items()}\n",
        "            inputs = {k: v for k, v in batch.items() if k not in [\"labels\", \"text\", \"idx\"]}\n",
        "            labels = batch[\"labels\"].to(DEVICE).long()\n",
        "            if \"roberta\" in model_name:\n",
        "                base_outputs = model[0](**inputs)\n",
        "                cls_embedding = base_outputs.pooler_output\n",
        "                logits = model[1:](cls_embedding)\n",
        "            else:\n",
        "                outputs = model(**inputs)\n",
        "                logits = outputs.logits\n",
        "            y_true.extend(labels.cpu().numpy())\n",
        "            y_pred.extend(logits.argmax(dim=-1).cpu().numpy())\n",
        "\n",
        "    # Precisi√≥n y recall (macro / micro)\n",
        "    prec_macro = precision_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
        "    prec_micro = precision_score(y_true, y_pred, average=\"micro\", zero_division=0)\n",
        "    rec_macro  = recall_score   (y_true, y_pred, average=\"macro\", zero_division=0)\n",
        "    rec_micro  = recall_score   (y_true, y_pred, average=\"micro\", zero_division=0)\n",
        "\n",
        "    report = classification_report(y_true, y_pred,labels=list(range(NUM_LABELS)),\n",
        "                                  target_names=le.classes_.tolist(),\n",
        "                                  digits=3,\n",
        "                                  zero_division=0)\n",
        "\n",
        "    # Limpieza expl√≠cita\n",
        "    test_loader_ref = loaders[\"test\"]    # referencia antes de borrar\n",
        "    del loaders, optimizer, scheduler, criterion\n",
        "    gc.collect(); torch.cuda.empty_cache()\n",
        "    # Retorno de resultados\n",
        "    metrics: dict[str, Any] = {\"model\": model_name,\n",
        "                              \"test_acc\": test_acc,\n",
        "                              \"test_precision_macro\": prec_macro,\n",
        "                              \"test_precision_micro\": prec_micro,\n",
        "                              \"test_recall_macro\": rec_macro,\n",
        "                              \"test_recall_micro\": rec_micro,\n",
        "                              \"test_f1_macro\": test_f1_macro,\n",
        "                              \"test_f1_micro\": test_f1_micro,\n",
        "                              \"report\":  report,\n",
        "                              \"history\": hist,\n",
        "                              \"trained_model\": model,\n",
        "                              \"test_loader\": test_loader_ref}\n",
        "\n",
        "    print(f\"\\n Duraci√≥n total: {(time.time()-start)/60:.1f} min\")\n",
        "    return metrics, model, tokenizer, test_loader_ref , hist"
      ],
      "metadata": {
        "id": "yod5PSrpEXcq"
      },
      "id": "yod5PSrpEXcq",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "## 4.3. Entrenamiento, validaci√≥n y prueba\n",
        "\n",
        "En el bloque final de esta secci√≥n, se comprueba que el *script* se ejecute como programa principal (*main*), se establece el diccionario **`MODELS`** con las arquitecturas de **BERT** y **RoBERTa** a evaluar. A continuaci√≥n se inicializan los contenedores **`results`**, **`models`**, **`loaders`** e **`histories`**, y se recorre cada entrada de **`MODELS`** invocando la funci√≥n **`train_and_evaluate`** sobre los conjuntos de entrenamiento, validaci√≥n y prueba, guardando los informes detallados y los objetos asociados a cada modelo. Tras entrenar ambos, se imprime una tabla comparativa con las m√©tricas finales de *accuracy*, *precision*, *recall* y *F1* macro para cada modelo.\n",
        "\n",
        "**BERT** es un modelo *transformer* bidireccional [¬π] de gran escala entrenado con tareas de *masked language modeling y Next Sentence Prediction*, lo que le permite captar el contexto completo de una secuencia de texto. Su arquitectura profunda (en este caso de 12 capas de atenci√≥n, pero algunas variantes las llevas hasra 24) facilita el pre-entrenamiento y el *fine-tuning* eficientes en diversas tareas de NLP [¬π]. El modelo **`bert-base-uncased`** corresponde a la configuraci√≥n base de **BERT** y, de forma muy resumida, su arquitectura es [¬π]:\n",
        "\n",
        "* **`num_hidden_layers`**: **12**\n",
        "* **`hidden_size`**: **768**\n",
        "* **`num_attention_heads`**: **12**\n",
        "* **`intermediate_size`**: **3072**\n",
        "* **`max_position_embeddings`**: **512**\n",
        "* **`vocab_size`**: **30.522**\n",
        "\n",
        "Adem√°s emplea tokenizaci√≥n *WordPiece* sin distinguir may√∫sculas/min√∫sculas\n",
        "\n",
        "Por otro lado, **RoBERTa** es una variante de **BERT** que optimiza el pre-entrenamiento eliminando la tarea de *Next Sentence Prediction* (NSP), usando enmascaramiento din√°mico, secuencias m√°s largas y mayor volumen de datos, lo cual mejora la robustez y la precisi√≥n sin cambiar la arquitectura base [‚Å∑]. La √∫nica diferencia principal est√° en el tama√±o del vocabulario (**`vocab_size`**), que es de **30.522** en BERT base y de **50.265** en RoBERTa.\n",
        "\n",
        "Para el Miniproyecto 3, que requiere clasificar en diferentes tem√°ticas a art√≠culos de la **BBC**, ambos modelos son ideales porque capturan dependencias contextuales complejas sin procesar token por token, lo que acelera el entrenamiento en GPU. Adem√°s, manejan la clasificaci√≥n multi-clase de manera nativa al a√±adir una capa de salida con funci√≥n softmax.\n",
        "\n",
        "Frente a las RNNs, los transformers permiten paralelizar el c√≥mputo (y de hecho el tiempo de procesamiento es notablemente mejor, respecto al Miniproyecto 2), evitar el desvanecimiento de gradientes en secuencias largas y lograr mayor precisi√≥n y eficiencia en tareas de clasificaci√≥n de texto."
      ],
      "metadata": {
        "id": "oz4ZPXG44a8W"
      },
      "id": "oz4ZPXG44a8W"
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    start_main = time.time()\n",
        "    # Define el diccionario de arquitecturas a comparar\n",
        "    MODELS = { \"bert-base-uncased\": \"BERT\",\n",
        "                \"roberta-base\": \"RoBERTa\" }\n",
        "\n",
        "    results =[]\n",
        "    models, loaders, histories = {}, {}, {}\n",
        "    # Itera sobre cada modelo, entrena y eval√∫a\n",
        "    for mdl_name, label in MODELS.items():\n",
        "        m, mol, tok, tl, h  = train_and_evaluate(mdl_name, train_data, val_data, test_data)\n",
        "        results.append(m)\n",
        "        models[mdl_name]   = mol\n",
        "        loaders[mdl_name]  = tl\n",
        "        histories[mdl_name]= h\n",
        "        print(\"\\n>>> Reporte detallado\")\n",
        "        print(m[\"report\"])\n",
        "        print(\"=\"*60)\n",
        "\n",
        "    # Imprime la comparaci√≥n final de m√©tricas\n",
        "    print(\"\\n======= Comparativa final =======\")\n",
        "    for res in results:\n",
        "        print(f\"{MODELS[res['model']]:9s} | \"\n",
        "        f\"Acc {res['test_acc']:.3f} | \"\n",
        "        f\"P_macro {res['test_precision_macro']:.3f} | \"\n",
        "        f\"R_macro {res['test_recall_macro']:.3f} | \"\n",
        "        f\"F1_macro {res['test_f1_macro']:.3f}\")\n",
        "\n",
        "    dur = (time.time() - start_main) / 60\n",
        "    print(f\"\\nTiempo total: {dur:.1f} min\\n\")"
      ],
      "metadata": {
        "id": "JAtN1d5G21to",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660,
          "referenced_widgets": [
            "0f0ce8e0159b45daa0814bd5f3982e42",
            "5f16c71c7f7e44669633fd2d102c209f",
            "4de8b2a548574e58a69fe7860802d615",
            "969d0326e4c649d3bf480a254237ab8e",
            "4de6a05bc47441328634592ee12c12d2",
            "be0f09b97bb040a299d06f6773b638ff",
            "5c17754546904e3eb3b3a2e01bc14d02",
            "92b12c1ec11445f09b5b3b673ebed576",
            "bc09b46e1c844942be4e33c055274b65",
            "2b136352fe454db49316949983d8afe9",
            "35446bd68bca47b4a71479ca8c969603",
            "a003ac9c9f3d4af491447a2697689307",
            "3664d2d1d8824c23bc2724368dec2284",
            "9d190941051d4564a3536da001e45695",
            "ec8144f2296c41dca36f3610866af933",
            "0239c36dee0c4117af2fda59f59a970d",
            "e12fa2ea1e924a0a8f7e6e8eb11b4147",
            "3f9ecfb8da2b49a5901cdb5ddd3d322c",
            "7661f20e7f4d4766b1377646f86bdbdd",
            "addf26abfc234651b4511dc630835413",
            "27257ae00d6a42a9be5cdf4a067f6b61",
            "0c0485a3b5454fbc8fd852d770e28fe3",
            "7d8e3932c1494d90b7e186334fb0d5b6",
            "9bb49b17d0cf4b9781e852021c4ebc4b",
            "9a7094fed2af43a7a30dfda30a639a7e",
            "fc8c5ee1f0df488cb250540bcdd5216f",
            "6b4836fafac74bce948fc4ba2034c0e1",
            "7676c0c6d22b42ac9bcf9f681cfd12cc",
            "416d52832cd0401bae88377fcaf4c66f",
            "ea9b769f59b24315bf0f2b8855d56fb5",
            "ee6e3806094041a0a9fb3ccefc9415ff",
            "078efec8d309486e9f4140ebae5305d7",
            "b3440950bbc94abfbf4a4184705d6485",
            "64d69d89a9e446dd8bcd96b06e8200a0",
            "33ef8923393143e58df5a626af23a84f",
            "f6d8f2e1e8434d42999e99fa5cfaeea7",
            "c7040529ff1e493e813a8da187d4f6d4",
            "96e16d50b4b148b180eb46f5ed107538",
            "e0bf4e9453ae4c438ad1806a615b0bec",
            "179bbd822f9a4cbf914c75f26694fe94",
            "06e719aeabd3431991941482322dbe56",
            "1c9834e77cf142d9ab1144a8d007f1e9",
            "5c0a7cdce7b44a8bb316273840436119",
            "6e048751ceb74ad1bbfccbfbd1280370",
            "8bf12dd8d29d4809a2157f60fc16d682",
            "cc015a2f45e44a479eababda9a1bad71",
            "35c536718dca49cb87cdb6c938880074",
            "edd785be52314f4eb45387a9bd2e1208",
            "2847e47b0e2348d28c01122b9370f8a0",
            "8c592f9a4f994f558e5865975f1789c7",
            "055cdbf6c8f842849f2ed0f0a7e1ecc7",
            "4f8e22ac8f4245a3ac77dbae76de2faa",
            "adcb450edf75446b8a8424848bf99384",
            "e23e85a29b364f3dab6690040fc1cff4",
            "757722c814874fe490f089cbcee4fe32"
          ]
        },
        "outputId": "af41ba11-d6ba-472c-eb85-7c09632f6a4b"
      },
      "id": "JAtN1d5G21to",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Entrenando bert-base-uncased ...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f0ce8e0159b45daa0814bd5f3982e42"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a003ac9c9f3d4af491447a2697689307"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7d8e3932c1494d90b7e186334fb0d5b6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "64d69d89a9e446dd8bcd96b06e8200a0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8bf12dd8d29d4809a2157f60fc16d682"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-7e4bdc335bf6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Itera sobre cada modelo, entrena y eval√∫a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmdl_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mMODELS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmdl_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmdl_name\u001b[0m\u001b[0;34m]\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mmol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-ecc83f97df03>\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(model_name, train_data, val_data, test_data)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mfreeze_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreeze\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlast_n\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mUNFREEZE_PER_EPOCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;31m# Ejecuta una pasada por el conjunto de entrenamiento y obtiene m√©tricas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_f1_macro\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_f1_micro\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;31m# Ejecuta una pasada por el conjunto de validaci√≥n y obtiene m√©tricas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0mval_f1_macro\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0mval_f1_micro\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mepoch_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"val\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-ecc83f97df03>\u001b[0m in \u001b[0;36mepoch_pass\u001b[0;34m(split)\u001b[0m\n\u001b[1;32m     65\u001b[0m                     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_embedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m                     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0;31m# Obtiene las etiquetas verdaderas del batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1673\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1675\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1676\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1677\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1142\u001b[0m         \u001b[0mhead_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1144\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1145\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    693\u001b[0m                 )\n\u001b[1;32m    694\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    696\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    586\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    522\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         )\n\u001b[0;32m--> 524\u001b[0;31m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# add attentions if we output them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/dropout.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1423\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"dropout probability has to be between 0 and 1, but got {p}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m     return (\n\u001b[0;32m-> 1425\u001b[0;31m         \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1426\u001b[0m     )\n\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sobre las m√©tricas vale la pena precisar que seg√∫n lo revisado en algunos *notebooks* p√∫blicos [‚Å∏], se recomienda el uso de m√©tricas \"macro\", es decir ponderadas por el peso de las clases, para una comparaci√≥n justa entre modelos cuando hay minor√≠as. √ötil incluso con este *dataset* de la BBC (donde no hay desbalanceo significativo) para evidenciar si alguna categor√≠a -‚Äú*tech*‚Äù, ‚Äú*sport*‚Äù- se queda atr√°s."
      ],
      "metadata": {
        "id": "wFt2XQ0PcZIJ"
      },
      "id": "wFt2XQ0PcZIJ"
    },
    {
      "cell_type": "markdown",
      "id": "7JgtiyyfIyMM",
      "metadata": {
        "id": "7JgtiyyfIyMM"
      },
      "source": [
        "***\n",
        "\n",
        "\n",
        "# 5. An√°lisis de resultados y discusi√≥n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se realizaron 3 corridas para calcular la media y desviaci√≥n de cada m√©trica:\n",
        "\n",
        "| Modelo      | M√©trica       | Promedio | Desviaci√≥n | **`Tiempo total`** |\n",
        "|-------------|---------------|----------|------------|--------------------|\n",
        "| **BERT**    | **`Acc`**         | 0.981    | 0.005      | ‚âà 1.5 *min*        |\n",
        "|             | **`Recall`**      | 0.981    | 0.004      |                    |\n",
        "|             | **`Precisi√≥n`**   | 0.980    | 0.005      |                    |\n",
        "|             | **`F1_macro`**    | 0.981    | 0.004      |                    |\n",
        "| **RoBERTa** | **`Acc`**         | 0.981    | 0.005      | ‚âà 3.5 *min*        |\n",
        "|             | **`Recall`**      | 0.981    | 0.005      |                    |\n",
        "|             | **`Precisi√≥n`**   | 0.981    | 0.007      |                    |\n",
        "|             | **`F1_macro`**    | 0.981    | 0.006      |                    |"
      ],
      "metadata": {
        "id": "w_gK-vxu7m2G"
      },
      "id": "w_gK-vxu7m2G"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se puede observar que **RoBERTa** se desempe√±a de manera similar a **BERT** con *accuracy*, *recall* y *F1* promedio de 0.981 y y solo *precisi√≥n* es un poco diferente siendo de 0.980, con desviaciones entre 0.004 y 0.007. Esto hace pensar que no hay una ventaja particular de uno u otro modelo, sin embargo, el tiempo de entrenamiento **RoBERTa** es un poco mayor.\n",
        "\n",
        "Analizando el detalle por clase, ambos modelos muestran su punto d√©bil en *business* y *politics* (*F1* = 0.950-0.970). Esto indica que ambas arquitecturas a√∫n enfrentan desaf√≠os con categor√≠as que tienen similitud semantica."
      ],
      "metadata": {
        "id": "xnCpSQ0hs0Ri"
      },
      "id": "xnCpSQ0hs0Ri"
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuaci√≥n, se define la funci√≥n **`predict_proba`** decorada con **`@torch.no_grad()`** lo que evita durante la ejecuci√≥n que se construya o almacene el grafo de c√≥mputo y tambi√©n que se calculen gradientes para las operaciones, ahorrando memoria y evitando la sobrecarga del *Autograd*.\n",
        "\n",
        "Se ejecuta el modelo en modo evaluaci√≥n para un lote de datos y devuelve las probabilidades de cada clase, esto nos ayudar√° m√°s adelante para el an√°lisis y evaluaci√≥n de los modelos."
      ],
      "metadata": {
        "id": "6iOJO_3X5xw9"
      },
      "id": "6iOJO_3X5xw9"
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcula y devuelve las probabilidades de cada clase para un lote\n",
        "@torch.no_grad()\n",
        "def predict_proba(model, batch, *, device):\n",
        "    model.eval()\n",
        "    # Prepara inputs excluyendo campos no necesarios y movi√©ndolos a device\n",
        "    inputs = {k: v.to(device) for k, v in batch.items() if k not in [\"labels\", \"text\", \"idx\"]}\n",
        "    # Obtiene logits del modelo\n",
        "    logits = model(**inputs).logits\n",
        "    # Convierte logits a probabilidades v√≠a softmax\n",
        "    probs  = F.softmax(logits, dim=-1)\n",
        "    return probs.cpu()"
      ],
      "metadata": {
        "id": "s6UVvASWngOQ"
      },
      "id": "s6UVvASWngOQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La funci√≥n **`plot_model_diagnostics`** centraliza la visualizaci√≥n de las m√©tricas de entrenamiento y la matriz de confusi√≥n en una sola figura, adaptando el n√∫mero de filas de *subplots* seg√∫n los datos disponibles."
      ],
      "metadata": {
        "id": "qJZ_NDzdjQ7G"
      },
      "id": "qJZ_NDzdjQ7G"
    },
    {
      "cell_type": "code",
      "source": [
        "# Diagn√≥sticos de entrenamiento y matriz de confusi√≥n\n",
        "def plot_model_diagnostics( history: dict = None, model = None, test_loader = None, class_names = None, device = DEVICE, title: str = \"\") -> None:\n",
        "    # Valida cu√°ntos subgr√°ficos se necesitan seg√∫n los argumentos recibidos\n",
        "    n_rows = 0\n",
        "    if history is not None:\n",
        "        n_rows += 2                # Loss y Accuracy\n",
        "    if model is not None and test_loader is not None and class_names is not None:\n",
        "        n_rows += 1                # Matriz de confusi√≥n\n",
        "    if n_rows == 0:\n",
        "        raise ValueError(\"Debes pasar `history` o (`model`, `test_loader`, `class_names`).\")\n",
        "\n",
        "    plt.figure(figsize=(7, 4 * n_rows))\n",
        "    plot_idx = 1\n",
        "\n",
        "    # Si hay historial, traza curvas de p√©rdida y accuracy\n",
        "    if history is not None:\n",
        "        epochs = range(1, len(history[\"train_loss\"]) + 1)\n",
        "\n",
        "        # Loss\n",
        "        plt.subplot(n_rows, 1, plot_idx)\n",
        "        plt.plot(epochs, history[\"train_loss\"], label=\"Train Loss\")\n",
        "        plt.plot(epochs, history[\"val_loss\"],   label=\"Val Loss\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.title(f\"{title} ‚Äì Loss\")\n",
        "        plt.legend()\n",
        "        plot_idx += 1\n",
        "\n",
        "        # Accuracy\n",
        "        plt.subplot(n_rows, 1, plot_idx)\n",
        "        plt.plot(epochs, history[\"train_acc\"], label=\"Train Acc\")\n",
        "        plt.plot(epochs, history[\"val_acc\"],   label=\"Val Acc\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"Accuracy\")\n",
        "        plt.title(f\"{title} ‚Äì Accuracy\")\n",
        "        plt.legend()\n",
        "        plot_idx += 1\n",
        "\n",
        "    #  Metriz de Confusi√≥n\n",
        "    if model is not None and test_loader is not None and class_names is not None:\n",
        "        model.eval()\n",
        "        y_true, y_pred = [], []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in test_loader:\n",
        "\n",
        "                labels = batch[\"labels\"]\n",
        "                inputs = {k: v.to(device) for k, v in batch.items() if k not in [\"labels\", \"text\", \"idx\"]}\n",
        "                # Validaci√≥n espec√≠fica par RoBERTa, ya que est√° en modo sequential\n",
        "                if isinstance(model, nn.Sequential):\n",
        "                    base_outputs = model[0](**inputs)\n",
        "                    cls_embedding = base_outputs.pooler_output\n",
        "                    logits = model[1:](cls_embedding)\n",
        "                else:\n",
        "                    outputs = model(**inputs)\n",
        "                    logits = outputs.logits\n",
        "                probs = F.softmax(logits, dim=-1)\n",
        "                preds = torch.argmax(probs, dim=1)\n",
        "\n",
        "                y_true.extend(labels.cpu().tolist())\n",
        "                y_pred.extend(preds.cpu().tolist())\n",
        "\n",
        "        cm = confusion_matrix(y_true, y_pred)\n",
        "        plt.subplot(n_rows, 1, plot_idx)\n",
        "        disp = ConfusionMatrixDisplay(cm, display_labels=class_names)\n",
        "        disp.plot(ax=plt.gca(), cmap=\"Blues\", colorbar=False)\n",
        "        plt.title(f\"{title} ‚Äì Confusion Matrix\")\n",
        "        plt.xlabel(\"Predicted\")\n",
        "        plt.ylabel(\"True\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "uaauR7IpagRo"
      },
      "id": "uaauR7IpagRo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot para BERT\n",
        "plot_model_diagnostics( history     = histories[\"bert-base-uncased\"],\n",
        "                        model       = models[\"bert-base-uncased\"],\n",
        "                        test_loader = loaders[\"bert-base-uncased\"],\n",
        "                        class_names = le.classes_.tolist(),\n",
        "                        title       = \"BERT\")\n",
        "\n",
        "# Plot para RoBERTa\n",
        "plot_model_diagnostics( history     = histories[\"roberta-base\"],\n",
        "                        model       = models[\"roberta-base\"],\n",
        "                        test_loader = loaders[\"roberta-base\"],\n",
        "                        class_names = le.classes_.tolist(),\n",
        "                        title       = \"RoBERTa\")"
      ],
      "metadata": {
        "id": "KWYnrx5nGZtR"
      },
      "id": "KWYnrx5nGZtR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En la **√©poca 1**, **RoBERTa** inicia con **`Val Loss`** ‚âà 0.20 y **`Val Acc`** ‚âà 0.96, mejor que **BERT** (**`Val Loss`** ‚âà 0.30, **`Val Acc`** ‚âà 0.95). Ambos convergen antes de la √©poca 3 a **`Val Loss`** ‚âà 0.03 y **`Val Acc`** ‚âà 0.995. La matriz de confusi√≥n raticia posiblemente un similitud sem√°ntica entre las tem√°ticas: pol√≠tica y negocios.\n"
      ],
      "metadata": {
        "id": "31FtpC80J-zG"
      },
      "id": "31FtpC80J-zG"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "***\n",
        "Ahora vamos a generar una vista de donde se est√°n equivocando los modelos. Para ello, se define la funci√≥n **`collect_fn_fp_examples`** que recorre el **`test_loader`** para generar las predicciones del **`model`** sin calcular gradientes y agrupa los textos, etiquetas reales y predichas en un **`DataFrame`**. Luego clasifica cada instancia como **FN** (*false negative*), **FP** (*false positive*) o **TP** (*true positive*) comparando **`true`** vs **`pred`**, y selecciona hasta **`k`** ejemplos de cada tipo por clase."
      ],
      "metadata": {
        "id": "9nQZGOzLJlaw"
      },
      "id": "9nQZGOzLJlaw"
    },
    {
      "cell_type": "code",
      "source": [
        "#  Ejemplos FN / FP por clase  (c√≥digo simplificado)\n",
        "def collect_fn_fp_examples(model, test_loader, class_names, device=DEVICE, k: int = 5) -> pd.DataFrame:\n",
        "\n",
        "    # Establece el modelo en modo evaluaci√≥n y prepara listas para textos y etiquetas\n",
        "    model.eval()\n",
        "    texts, y_true, y_pred = [], [], []\n",
        "    # Recorre el loader sin graficar gradientes, recopilando predicciones y textos\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            labels = batch[\"labels\"]\n",
        "            inputs = {k:v.to(device) for k,v in batch.items()\n",
        "                      if k not in [\"labels\",\"text\",\"idx\"]}\n",
        "            # Validaci√≥n para RoBERTa\n",
        "            if isinstance(model, nn.Sequential):\n",
        "                base_outputs = model[0](**inputs)\n",
        "                cls_embedding = base_outputs.pooler_output\n",
        "                logits = model[1:](cls_embedding)\n",
        "            else:\n",
        "                outputs = model(**inputs)\n",
        "                logits = outputs.logits\n",
        "            probs  = F.softmax(logits, dim=-1)\n",
        "            preds  = torch.argmax(probs, dim=1)\n",
        "\n",
        "            y_true.extend(labels.cpu().tolist())\n",
        "            y_pred.extend(preds.cpu().tolist())\n",
        "            texts.extend(batch[\"text\"])\n",
        "    # Construye DataFrame base con texto\n",
        "    data = pd.DataFrame({\"text\": texts,\n",
        "                          \"true\": y_true,\n",
        "                          \"pred\": y_pred })\n",
        "    data[\"type\"] = \"UNDEF\"\n",
        "    # Para cada clase, etiqueta FN, FP y TP seg√∫n compara true v\n",
        "    out_rows = []\n",
        "    rows=[]\n",
        "    for cls in range(len(class_names)):\n",
        "        data.loc[(data.true==cls) & (data.pred!=cls), \"type\"] = \"FN\"\n",
        "        data.loc[(data.pred==cls) & (data.true!=cls), \"type\"] = \"FP\"\n",
        "        data.loc[(data.true==cls) & (data.pred==cls), \"type\"] = \"TP\"\n",
        "        # Selecciona hasta k ejemplos de FN y FP\n",
        "        fn = data[(data.true==cls)&(data.pred!=cls)].head(k)\n",
        "        fp = data[(data.pred==cls)&(data.true!=cls)].head(k)\n",
        "        rows.extend(fn.assign(tipo=\"FN\", clase=class_names[cls]).to_dict(\"records\"))\n",
        "        rows.extend(fp.assign(tipo=\"FP\", clase=class_names[cls]).to_dict(\"records\"))\n",
        "    return pd.DataFrame(rows)"
      ],
      "metadata": {
        "id": "VrcMKrQPGt2J"
      },
      "id": "VrcMKrQPGt2J",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Corre primero la inferencia sobre test_loader\n",
        "data_err_bert = collect_fn_fp_examples(models[\"bert-base-uncased\"], loaders[\"bert-base-uncased\"],\n",
        "                                     le.classes_.tolist(), k=3)\n",
        "\n",
        "data_err_roberta = collect_fn_fp_examples( models[\"roberta-base\"], loaders[\"roberta-base\"],\n",
        "                                     le.classes_.tolist(), k=3)\n",
        "# Luego visualiza\n",
        "display(data_err_bert[[\"text\",\"true\",\"pred\",\"tipo\"]].head(10))\n",
        "display(data_err_roberta[[\"text\",\"true\",\"pred\",\"tipo\"]].head(10))"
      ],
      "metadata": {
        "id": "I80o-UdGG4SO"
      },
      "id": "I80o-UdGG4SO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En la √∫ltima corrida, seg√∫n la matriz de confusi√≥n, **RoBERTa** reduce los errores totales (3 vs 4) y mejora especialmente una posible equivaci√≥n en la clase **`tech`**, aunque ambas arquitecturas siguen confundiendo m√°s la categor√≠a **`business`**. Se puede ver que potencialmente las noticias manejan un nivel de ambig√ºedad alto especialmente entre **`politics`**  y **`business`** . Por ejemplo en el caso del texto donde se menciona la agenda de Davos, el cual est√° categorizado como una noticia de negocios, pero claramente este evento puede llegar un alto tinte pol√≠tico.\n"
      ],
      "metadata": {
        "id": "MtU03ySJLJ_q"
      },
      "id": "MtU03ySJLJ_q"
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "Para finalizar esta secci√≥n de an√°lisis de resultados, se sefine **`tsne_cls`** que extrae primero los embeddings de la posici√≥n [CLS] del modelo sobre el **`test_loader`** y, si ya existe un archivo en **`save_path`**, reutiliza la proyecci√≥n en 2D para ahorrar **`time`**. De lo contrario, consolida todos los vectores CLS y sus etiquetas, calcula din√°micamente la *perplexity* en funci√≥n del tama√±o de muestra para garantizar una proyecci√≥n estable en t-SNE, y guarda el resultado en disco. Por √∫ltimo, genera un gr√°fico dispersi√≥n en el que cada punto se colorea seg√∫n su clase, permitiendo visualizar c√≥mo el modelo separa las instancias en el espacio de embeddings."
      ],
      "metadata": {
        "id": "4-IWPpYxM8Cw"
      },
      "id": "4-IWPpYxM8Cw"
    },
    {
      "cell_type": "code",
      "source": [
        "# Proyecta embeddings [CLS] en 2D usando t-SNE\n",
        "def tsne_cls(model, test_loader, class_names, device, save_path = None):\n",
        "    # Obtener o cargar los vectores\n",
        "    if save_path and os.path.isfile(save_path):\n",
        "        print(f\"t-SNE cargado de {save_path}\")\n",
        "        data = np.load(save_path)\n",
        "        X_2d, y = data[:, :2], data[:, 2].astype(int)\n",
        "    else:\n",
        "         # Modo evaluaci√≥n y recolecci√≥n de embeddings CLS y etiquetas\n",
        "        model.eval()\n",
        "        reps, labels = [], []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in test_loader:\n",
        "                inputs = {k: v.to(device) for k, v in batch.items()\n",
        "                          if k not in [\"labels\", \"text\"]}\n",
        "                out = model(**inputs, output_hidden_states=True)\n",
        "                # Nuevamente verificaci√≥n exclusivo para RoBERTa\n",
        "                if isinstance(model, nn.Sequential):\n",
        "                    base_outputs = model[0](**inputs, output_hidden_states=True)\n",
        "                    cls = base_outputs.hidden_states[-1][:, 0, :]\n",
        "                else:\n",
        "                    outputs = model(**inputs, output_hidden_states=True)\n",
        "                    cls = outputs.hidden_states[-1][:, 0, :]\n",
        "\n",
        "                reps.append(cls.cpu())\n",
        "                labels.extend(batch[\"labels\"].tolist())\n",
        "\n",
        "        X = torch.cat(reps).numpy()\n",
        "        y = np.array(labels)\n",
        "\n",
        "        # Ajusta perplexity en funci√≥n de n_samples para estabilidad\n",
        "        n_samples   = X.shape[0]\n",
        "        perplexity  = max(5, min(40, n_samples // 10))\n",
        "        print(f\"‚Üí n_samples={n_samples} | perplexity={perplexity}\")\n",
        "\n",
        "        tsne = TSNE(n_components=2, perplexity=perplexity, init=\"random\",\n",
        "            learning_rate=\"auto\", random_state= SEED, n_iter=1000)\n",
        "        X_2d = tsne.fit_transform(X)\n",
        "\n",
        "        # Guarda la proyecci√≥n para futuras ejecuciones\n",
        "        if save_path:\n",
        "            np.save(save_path, np.c_[X_2d, y])\n",
        "            print(f\"Guardado en {save_path}\")\n",
        "\n",
        "    # Visualiza los puntos proyectados, uno por clase\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    for cls_id, cls_name in enumerate(class_names):\n",
        "        pts = X_2d[y == cls_id]\n",
        "        plt.scatter(pts[:, 0], pts[:, 1], alpha=0.6, label=cls_name, s=15)\n",
        "\n",
        "    plt.title(\"t-SNE de embeddings CLS\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "1jB6JKlLVoQG"
      },
      "id": "1jB6JKlLVoQG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tsne_cls(model       = models[\"bert-base-uncased\"] ,\n",
        "          test_loader = loaders[\"bert-base-uncased\"],\n",
        "          class_names = le.classes_.tolist(),\n",
        "          device      = DEVICE,\n",
        "          save_path   = Path(\"tsne_cls_bert.npy\"))"
      ],
      "metadata": {
        "id": "EWyptqdMhynP"
      },
      "id": "EWyptqdMhynP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tsne_cls(model       = models[\"roberta-base\"],\n",
        "          test_loader = loaders[\"roberta-base\"],\n",
        "          class_names = le.classes_.tolist(),\n",
        "          device      = DEVICE,\n",
        "          save_path   = Path(\"tsne_cls_roberta.npy\"))"
      ],
      "metadata": {
        "id": "Nd0y6qt7ZRqa"
      },
      "id": "Nd0y6qt7ZRqa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ambos modelos forman cinco *clusters* bien definidos para **business**, **entertainment**, **politics**, **sport** y **tech**. Con ambos modelos, se aprecia cierta sobre-posici√≥n entre **business** y **politics**, y un punto aislado de **tech** que sugiere mayor dispersi√≥n en esa clase. En el caso de **RoBERTa**, los *clusters* son m√°s compactos y mejor separados; especialmente **politics** y **tech** muestran mayor cohesi√≥n interna. En ambos modelos, **sport** y **entertainment** quedan claramente aislados, y como se mencion√≥ anteriomente a trav√©s de las diferentes corridas no se observan diferencias significativas entre ambos modelos."
      ],
      "metadata": {
        "id": "R9OsihFCOxI2"
      },
      "id": "R9OsihFCOxI2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "\n",
        "# 6. Conclusi√≥n\n",
        "\n",
        "El problema de clasificar art√≠culos de la **BBC** en cinco categor√≠as se abord√≥ con modelos *transformer* ‚Äî**`bert-base-uncased`** y **`roberta-base`**‚Äî entrenados con *fine-tuning* en GPU. Ambos convergieron  alrededor de las 2 √©pocas gracias a *early-stopping*, y obtienen m√©tricas similares de desempe√±o pero **RoBERTa** tienen un tiempo de procesamiento ligeramente mayor.\n",
        "\n",
        "En ambos modelos se observa:\n",
        "\n",
        "* **Errores**: la clase **`politics`** concentr√≥ la mayor√≠a de FN/FP.\n",
        "* **Confusion matrices**: **RoBERTa** logr√≥ 100 % en **`sport`** y **`tech`**, mostrando separabilidad casi perfecta.  \n",
        "* **t-SNE** de *embeddings* CLS: Ambos modelos generaron *clusters* compactos y con un nivel de solapamiento menor.\n",
        "\n",
        " Se recomienda, para este problema en particular adoptar **BERT** como modelo final por tiempo de procesamiento. Sin embargo, hay que priorizar la revisi√≥n de datos de **`politics`** / **`business`**  (posible ambig√ºedad tem√°tica) y para futuros trabajos considerar t√©cnicas de *data augmentation* para afinar esa categor√≠a."
      ],
      "metadata": {
        "id": "uDjo26cIk10k"
      },
      "id": "uDjo26cIk10k"
    },
    {
      "cell_type": "markdown",
      "id": "DwUWQIAE3O0o",
      "metadata": {
        "id": "DwUWQIAE3O0o"
      },
      "source": [
        "***\n",
        "\n",
        "\n",
        "# 7. Referencias"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BoLDjBS03xiQ",
      "metadata": {
        "id": "BoLDjBS03xiQ"
      },
      "source": [
        "[¬π] **BERT: Pre-training of Deep Bidirectional Transformers for\n",
        "Language Understanding  Google AI Language**  \n",
        "Disponible en: [arxiv.org](https://arxiv.org/abs/1810.04805)\n",
        "\n",
        "[¬≤] **Documents Classification using BERT on BBC Dataset**  \n",
        "Disponible en: [kaggle.com](https://www.kaggle.com/code/ouardasakram/documents-classification-using-bert-on-bbc-dataset)\n",
        "\n",
        "[¬≥] **Transfer Learning: Why We Freeze and Unfreeze Model Layers**  \n",
        "Disponible en: [medium.com](https://medium.com/data-science-collective/transfer-learning-why-we-freeze-and-unfreeze-model-layers-0e0b8f9837ec)\n",
        "\n",
        "[‚Å¥] **LayerNorm: A key component in parameter-efficient fine-tuning**  \n",
        "Disponible en: [arxiv.org](https://arxiv.org/html/2403.20284v1)\n",
        "\n",
        "[‚Åµ] **Transformers: Optimization**  \n",
        "Disponible en: [huggingface.co](https://huggingface.co/docs/transformers/en/main_classes/optimizer_schedules?utm_source=chatgpt.com)\n",
        "\n",
        "[‚Å∂] **Transformers: Auto Classes**  \n",
        "Disponible en: [huggingface.co](https://huggingface.co/docs/transformers/en/model_doc/auto?utm_source=chatgpt.com)\n",
        "\n",
        "[‚Å∑] **RoBERTa: A Robustly Optimized BERT Pretraining Approach**  \n",
        "Disponible en: [arxiv.org](https://arxiv.org/abs/1907.11692)\n",
        "\n",
        "[‚Å∏] **Bert-Classification-BBC-News**  \n",
        "Disponible en: [github.com](https://github.com/bymi15/Bert-Classification-BBC-News/blob/main/bert_classification_bbc_news.ipynb)\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0f0ce8e0159b45daa0814bd5f3982e42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5f16c71c7f7e44669633fd2d102c209f",
              "IPY_MODEL_4de8b2a548574e58a69fe7860802d615",
              "IPY_MODEL_969d0326e4c649d3bf480a254237ab8e"
            ],
            "layout": "IPY_MODEL_4de6a05bc47441328634592ee12c12d2"
          }
        },
        "5f16c71c7f7e44669633fd2d102c209f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be0f09b97bb040a299d06f6773b638ff",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_5c17754546904e3eb3b3a2e01bc14d02",
            "value": "config.json:‚Äá100%"
          }
        },
        "4de8b2a548574e58a69fe7860802d615": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92b12c1ec11445f09b5b3b673ebed576",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc09b46e1c844942be4e33c055274b65",
            "value": 570
          }
        },
        "969d0326e4c649d3bf480a254237ab8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b136352fe454db49316949983d8afe9",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_35446bd68bca47b4a71479ca8c969603",
            "value": "‚Äá570/570‚Äá[00:00&lt;00:00,‚Äá47.6kB/s]"
          }
        },
        "4de6a05bc47441328634592ee12c12d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be0f09b97bb040a299d06f6773b638ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c17754546904e3eb3b3a2e01bc14d02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92b12c1ec11445f09b5b3b673ebed576": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc09b46e1c844942be4e33c055274b65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2b136352fe454db49316949983d8afe9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35446bd68bca47b4a71479ca8c969603": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a003ac9c9f3d4af491447a2697689307": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3664d2d1d8824c23bc2724368dec2284",
              "IPY_MODEL_9d190941051d4564a3536da001e45695",
              "IPY_MODEL_ec8144f2296c41dca36f3610866af933"
            ],
            "layout": "IPY_MODEL_0239c36dee0c4117af2fda59f59a970d"
          }
        },
        "3664d2d1d8824c23bc2724368dec2284": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e12fa2ea1e924a0a8f7e6e8eb11b4147",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_3f9ecfb8da2b49a5901cdb5ddd3d322c",
            "value": "model.safetensors:‚Äá100%"
          }
        },
        "9d190941051d4564a3536da001e45695": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7661f20e7f4d4766b1377646f86bdbdd",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_addf26abfc234651b4511dc630835413",
            "value": 440449768
          }
        },
        "ec8144f2296c41dca36f3610866af933": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27257ae00d6a42a9be5cdf4a067f6b61",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0c0485a3b5454fbc8fd852d770e28fe3",
            "value": "‚Äá440M/440M‚Äá[00:02&lt;00:00,‚Äá205MB/s]"
          }
        },
        "0239c36dee0c4117af2fda59f59a970d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e12fa2ea1e924a0a8f7e6e8eb11b4147": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f9ecfb8da2b49a5901cdb5ddd3d322c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7661f20e7f4d4766b1377646f86bdbdd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "addf26abfc234651b4511dc630835413": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "27257ae00d6a42a9be5cdf4a067f6b61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c0485a3b5454fbc8fd852d770e28fe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d8e3932c1494d90b7e186334fb0d5b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9bb49b17d0cf4b9781e852021c4ebc4b",
              "IPY_MODEL_9a7094fed2af43a7a30dfda30a639a7e",
              "IPY_MODEL_fc8c5ee1f0df488cb250540bcdd5216f"
            ],
            "layout": "IPY_MODEL_6b4836fafac74bce948fc4ba2034c0e1"
          }
        },
        "9bb49b17d0cf4b9781e852021c4ebc4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7676c0c6d22b42ac9bcf9f681cfd12cc",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_416d52832cd0401bae88377fcaf4c66f",
            "value": "tokenizer_config.json:‚Äá100%"
          }
        },
        "9a7094fed2af43a7a30dfda30a639a7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea9b769f59b24315bf0f2b8855d56fb5",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ee6e3806094041a0a9fb3ccefc9415ff",
            "value": 48
          }
        },
        "fc8c5ee1f0df488cb250540bcdd5216f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_078efec8d309486e9f4140ebae5305d7",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_b3440950bbc94abfbf4a4184705d6485",
            "value": "‚Äá48.0/48.0‚Äá[00:00&lt;00:00,‚Äá4.27kB/s]"
          }
        },
        "6b4836fafac74bce948fc4ba2034c0e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7676c0c6d22b42ac9bcf9f681cfd12cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "416d52832cd0401bae88377fcaf4c66f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea9b769f59b24315bf0f2b8855d56fb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee6e3806094041a0a9fb3ccefc9415ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "078efec8d309486e9f4140ebae5305d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3440950bbc94abfbf4a4184705d6485": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64d69d89a9e446dd8bcd96b06e8200a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_33ef8923393143e58df5a626af23a84f",
              "IPY_MODEL_f6d8f2e1e8434d42999e99fa5cfaeea7",
              "IPY_MODEL_c7040529ff1e493e813a8da187d4f6d4"
            ],
            "layout": "IPY_MODEL_96e16d50b4b148b180eb46f5ed107538"
          }
        },
        "33ef8923393143e58df5a626af23a84f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0bf4e9453ae4c438ad1806a615b0bec",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_179bbd822f9a4cbf914c75f26694fe94",
            "value": "vocab.txt:‚Äá100%"
          }
        },
        "f6d8f2e1e8434d42999e99fa5cfaeea7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06e719aeabd3431991941482322dbe56",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1c9834e77cf142d9ab1144a8d007f1e9",
            "value": 231508
          }
        },
        "c7040529ff1e493e813a8da187d4f6d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c0a7cdce7b44a8bb316273840436119",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_6e048751ceb74ad1bbfccbfbd1280370",
            "value": "‚Äá232k/232k‚Äá[00:00&lt;00:00,‚Äá4.39MB/s]"
          }
        },
        "96e16d50b4b148b180eb46f5ed107538": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0bf4e9453ae4c438ad1806a615b0bec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "179bbd822f9a4cbf914c75f26694fe94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06e719aeabd3431991941482322dbe56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c9834e77cf142d9ab1144a8d007f1e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5c0a7cdce7b44a8bb316273840436119": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e048751ceb74ad1bbfccbfbd1280370": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8bf12dd8d29d4809a2157f60fc16d682": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cc015a2f45e44a479eababda9a1bad71",
              "IPY_MODEL_35c536718dca49cb87cdb6c938880074",
              "IPY_MODEL_edd785be52314f4eb45387a9bd2e1208"
            ],
            "layout": "IPY_MODEL_2847e47b0e2348d28c01122b9370f8a0"
          }
        },
        "cc015a2f45e44a479eababda9a1bad71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c592f9a4f994f558e5865975f1789c7",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_055cdbf6c8f842849f2ed0f0a7e1ecc7",
            "value": "tokenizer.json:‚Äá100%"
          }
        },
        "35c536718dca49cb87cdb6c938880074": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f8e22ac8f4245a3ac77dbae76de2faa",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_adcb450edf75446b8a8424848bf99384",
            "value": 466062
          }
        },
        "edd785be52314f4eb45387a9bd2e1208": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e23e85a29b364f3dab6690040fc1cff4",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_757722c814874fe490f089cbcee4fe32",
            "value": "‚Äá466k/466k‚Äá[00:00&lt;00:00,‚Äá11.5MB/s]"
          }
        },
        "2847e47b0e2348d28c01122b9370f8a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c592f9a4f994f558e5865975f1789c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "055cdbf6c8f842849f2ed0f0a7e1ecc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f8e22ac8f4245a3ac77dbae76de2faa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adcb450edf75446b8a8424848bf99384": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e23e85a29b364f3dab6690040fc1cff4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "757722c814874fe490f089cbcee4fe32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}